{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdbe460f",
   "metadata": {},
   "source": [
    "#### Import libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "077b6c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.utils import resample\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b11eaf",
   "metadata": {},
   "source": [
    "#### Show installed GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ae23115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:  /physical_device:GPU:0  Type:  GPU\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "for gpu in gpus :\n",
    "    print(\"Name: \", gpu.name, \" Type: \", gpu.device_type)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42175028",
   "metadata": {},
   "source": [
    "#### Load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b43ccbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv('../dataset/original-sam-dataset.csv', sep='|',\n",
    "                 dtype = {'recordNumber': 'int8',\n",
    "                          'CZ': 'float64', 'FZ': 'float64', 'Fp1': 'float64', 'F7': 'float64',\n",
    "                          'F3': 'float64', 'FC1': 'float64', 'C3': 'float64', 'FC5': 'float64', 'FT9': 'float64',\n",
    "                          'T7': 'float64', 'CP5': 'float64', 'CP1': 'float64', 'P3': 'float64', 'P7': 'float64',\n",
    "                          'PO9': 'float64', 'O1': 'float64', 'PZ': 'float64', 'OZ': 'float64', 'O2': 'float64',\n",
    "                          'PO10': 'float64', 'P8': 'float64', 'P4': 'float64', 'CP2': 'float64', 'CP6': 'float64',\n",
    "                          'T8': 'float64', 'FT10': 'float64', 'FC6': 'float64', 'C4': 'float64', 'FC2': 'float64',\n",
    "                          'F4': 'float64', 'F8': 'float64', 'Fp2': 'float64', \n",
    "                          'Scale': 'int8'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d03541",
   "metadata": {},
   "source": [
    "#### Display the dataset size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d243cc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1536000, 34)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3579e10b",
   "metadata": {},
   "source": [
    "#### Build a helper function to convert the set data to the required format to perform the undersampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "859f6e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_struct_for_undersamp(df):\n",
    "    # Splits the dataset into \"time windows\" to be used as a time series list.\n",
    "    # The function groups each 128 dataset records (CSV lines) into one record.\n",
    "    # Each record contains 128 steps and each step contains 32 feature values.\n",
    "    # Parameters:\n",
    "    #    df: Dataframe to be splitted.\n",
    "    # Return:\n",
    "    #    X_array (list): First list contains all time windows.\n",
    "    #    y_array (list): Second list contains all target values.\n",
    "    print(\"\\nStarting build_struct_for_undersamp function.\")\n",
    "    steps_number = 128\n",
    "    initial_line_number = 0\n",
    "    first_feat_index = 1\n",
    "    last_feat_index = 33\n",
    "    column_headers = list(df.columns.values)\n",
    "    X_array = []\n",
    "    y_array = []\n",
    "    while initial_line_number < len(df[\"Scale\"]):\n",
    "        scale_value = df[\"Scale\"][initial_line_number]\n",
    "        sub_matrix = df.iloc[initial_line_number : (initial_line_number + steps_number), first_feat_index : last_feat_index]\n",
    "        sub_matrix_values = sub_matrix.values\n",
    "        new_line = sub_matrix_values.flatten()\n",
    "        X_array.append(new_line)\n",
    "        y_array.append(scale_value)\n",
    "        initial_line_number += steps_number\n",
    "    print(\"Quantity of samples (features) => \", len(X_array))\n",
    "    print(\"Quantity os samples (labels) => \", len(y_array))\n",
    "    print(\"Finishing build_struct_for_undersamp function.\")\n",
    "    return X_array, y_array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03a01eb",
   "metadata": {},
   "source": [
    "#### Perform undersampling to balance the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd2e2c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting undersampling process.\n",
      "\n",
      "Starting build_struct_for_undersamp function.\n",
      "Quantity of samples (features) =>  12000\n",
      "Quantity os samples (labels) =>  12000\n",
      "Finishing build_struct_for_undersamp function.\n",
      "\n",
      "Quantity of resampled samples =>  1100\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Correct dataset imbalance through undersampling.\n",
    "print(\"\\nStarting undersampling process.\")\n",
    "X_list, y_list = build_struct_for_undersamp(df)\n",
    "rus = RandomUnderSampler(random_state = 42)\n",
    "X_arr = np.array(X_list)\n",
    "y_arr = np.array(y_list)\n",
    "X_resampled, y_resampled = rus.fit_resample(X_arr, y_arr)\n",
    "print(\"\\nQuantity of resampled samples => \", len(y_resampled))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258715ac",
   "metadata": {},
   "source": [
    "#### Train a Convolutional Neural Network model and evaluate the metrics.\n",
    "- Layer architecture => Conv1D (64) + Conv1D (32) + Conv1D (16) + MaxPooling1D + Dense (32) + Dense (11)\n",
    "- 1100 samples (no data augmentation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e887613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training at:  23:30:37\n",
      "\n",
      "Trainning fold 1\n",
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_90 (Conv1D)          (None, 126, 64)           6208      \n",
      "                                                                 \n",
      " conv1d_91 (Conv1D)          (None, 124, 32)           6176      \n",
      "                                                                 \n",
      " conv1d_92 (Conv1D)          (None, 122, 16)           1552      \n",
      "                                                                 \n",
      " max_pooling1d_30 (MaxPoolin  (None, 61, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_30 (Flatten)        (None, 976)               0         \n",
      "                                                                 \n",
      " dense_60 (Dense)            (None, 32)                31264     \n",
      "                                                                 \n",
      " dense_61 (Dense)            (None, 11)                363       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45,563\n",
      "Trainable params: 45,563\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "2/2 [==============================] - 1s 144ms/step - loss: 2.4438 - accuracy: 0.0862 - val_loss: 2.6362 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.3811 - accuracy: 0.1096 - val_loss: 2.7273 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.3678 - accuracy: 0.1436 - val_loss: 2.7613 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.3543 - accuracy: 0.1426 - val_loss: 2.7887 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.3373 - accuracy: 0.1681 - val_loss: 2.8471 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.3174 - accuracy: 0.1883 - val_loss: 2.9424 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.2955 - accuracy: 0.1904 - val_loss: 3.0474 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 2.2661 - accuracy: 0.1979 - val_loss: 3.1488 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.2361 - accuracy: 0.2149 - val_loss: 3.1777 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.2022 - accuracy: 0.2436 - val_loss: 3.3102 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/300\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 2.1621 - accuracy: 0.2649 - val_loss: 3.4381 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.1167 - accuracy: 0.2904 - val_loss: 3.6182 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.0695 - accuracy: 0.3053 - val_loss: 3.7245 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.0187 - accuracy: 0.3160 - val_loss: 3.9159 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.9576 - accuracy: 0.3447 - val_loss: 3.9868 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.9030 - accuracy: 0.3638 - val_loss: 3.7471 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.8334 - accuracy: 0.3947 - val_loss: 4.0894 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 1.7727 - accuracy: 0.4287 - val_loss: 3.9407 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.7036 - accuracy: 0.4500 - val_loss: 4.3573 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.6466 - accuracy: 0.4713 - val_loss: 3.9187 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.5768 - accuracy: 0.5043 - val_loss: 4.4066 - val_accuracy: 0.0000e+00\n",
      "Epoch 00021: early stopping\n",
      "\n",
      "Trainning fold 2\n",
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_93 (Conv1D)          (None, 126, 64)           6208      \n",
      "                                                                 \n",
      " conv1d_94 (Conv1D)          (None, 124, 32)           6176      \n",
      "                                                                 \n",
      " conv1d_95 (Conv1D)          (None, 122, 16)           1552      \n",
      "                                                                 \n",
      " max_pooling1d_31 (MaxPoolin  (None, 61, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_31 (Flatten)        (None, 976)               0         \n",
      "                                                                 \n",
      " dense_62 (Dense)            (None, 32)                31264     \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 11)                363       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45,563\n",
      "Trainable params: 45,563\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "2/2 [==============================] - 1s 144ms/step - loss: 2.4773 - accuracy: 0.0979 - val_loss: 2.7992 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.3794 - accuracy: 0.1074 - val_loss: 3.0282 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 2.3612 - accuracy: 0.1394 - val_loss: 3.1679 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 2.3470 - accuracy: 0.1383 - val_loss: 3.2556 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.3311 - accuracy: 0.1596 - val_loss: 3.3083 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.3117 - accuracy: 0.1872 - val_loss: 3.3585 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.2884 - accuracy: 0.1883 - val_loss: 3.4482 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 2.2611 - accuracy: 0.2000 - val_loss: 3.5519 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.2296 - accuracy: 0.2330 - val_loss: 3.6423 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.1931 - accuracy: 0.2713 - val_loss: 3.7103 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.1532 - accuracy: 0.2862 - val_loss: 3.8130 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.1073 - accuracy: 0.3074 - val_loss: 3.9862 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.0566 - accuracy: 0.3298 - val_loss: 4.0372 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.0003 - accuracy: 0.3404 - val_loss: 4.0239 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.9409 - accuracy: 0.3713 - val_loss: 4.2049 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.8709 - accuracy: 0.3968 - val_loss: 4.2755 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.8032 - accuracy: 0.4064 - val_loss: 4.3139 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 1.7334 - accuracy: 0.4362 - val_loss: 4.4987 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.6562 - accuracy: 0.4649 - val_loss: 4.4858 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.5820 - accuracy: 0.4936 - val_loss: 4.5762 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.5044 - accuracy: 0.5330 - val_loss: 4.7163 - val_accuracy: 0.0000e+00\n",
      "Epoch 00021: early stopping\n",
      "\n",
      "Trainning fold 3\n",
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_96 (Conv1D)          (None, 126, 64)           6208      \n",
      "                                                                 \n",
      " conv1d_97 (Conv1D)          (None, 124, 32)           6176      \n",
      "                                                                 \n",
      " conv1d_98 (Conv1D)          (None, 122, 16)           1552      \n",
      "                                                                 \n",
      " max_pooling1d_32 (MaxPoolin  (None, 61, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_32 (Flatten)        (None, 976)               0         \n",
      "                                                                 \n",
      " dense_64 (Dense)            (None, 32)                31264     \n",
      "                                                                 \n",
      " dense_65 (Dense)            (None, 11)                363       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45,563\n",
      "Trainable params: 45,563\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "2/2 [==============================] - 1s 151ms/step - loss: 2.5342 - accuracy: 0.0926 - val_loss: 2.3048 - val_accuracy: 0.1600\n",
      "Epoch 2/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.4119 - accuracy: 0.0883 - val_loss: 2.4648 - val_accuracy: 0.0600\n",
      "Epoch 3/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.3844 - accuracy: 0.1245 - val_loss: 2.5638 - val_accuracy: 0.0200\n",
      "Epoch 4/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 2.3743 - accuracy: 0.1181 - val_loss: 2.6701 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 2.3610 - accuracy: 0.1489 - val_loss: 2.7764 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.3474 - accuracy: 0.1596 - val_loss: 2.8666 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.3310 - accuracy: 0.1691 - val_loss: 2.9449 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.3147 - accuracy: 0.1904 - val_loss: 3.0119 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.2956 - accuracy: 0.2032 - val_loss: 3.0854 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.2751 - accuracy: 0.2128 - val_loss: 3.1666 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.2499 - accuracy: 0.2223 - val_loss: 3.2484 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.2220 - accuracy: 0.2638 - val_loss: 3.3316 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.1916 - accuracy: 0.2830 - val_loss: 3.4210 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.1584 - accuracy: 0.3117 - val_loss: 3.4857 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.1210 - accuracy: 0.3266 - val_loss: 3.5859 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.0781 - accuracy: 0.3426 - val_loss: 3.6799 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.0322 - accuracy: 0.3649 - val_loss: 3.8543 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.9851 - accuracy: 0.3915 - val_loss: 3.9558 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.9335 - accuracy: 0.3713 - val_loss: 3.9634 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.8787 - accuracy: 0.4149 - val_loss: 4.0304 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.8240 - accuracy: 0.4362 - val_loss: 3.9566 - val_accuracy: 0.0000e+00\n",
      "Epoch 00021: early stopping\n",
      "\n",
      "Trainning fold 4\n",
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_99 (Conv1D)          (None, 126, 64)           6208      \n",
      "                                                                 \n",
      " conv1d_100 (Conv1D)         (None, 124, 32)           6176      \n",
      "                                                                 \n",
      " conv1d_101 (Conv1D)         (None, 122, 16)           1552      \n",
      "                                                                 \n",
      " max_pooling1d_33 (MaxPoolin  (None, 61, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_33 (Flatten)        (None, 976)               0         \n",
      "                                                                 \n",
      " dense_66 (Dense)            (None, 32)                31264     \n",
      "                                                                 \n",
      " dense_67 (Dense)            (None, 11)                363       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45,563\n",
      "Trainable params: 45,563\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "2/2 [==============================] - 1s 149ms/step - loss: 2.4228 - accuracy: 0.1053 - val_loss: 2.6170 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.3696 - accuracy: 0.1223 - val_loss: 2.6997 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/300\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 2.3463 - accuracy: 0.1383 - val_loss: 2.8213 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.3195 - accuracy: 0.1936 - val_loss: 2.9738 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 2.2899 - accuracy: 0.2191 - val_loss: 3.0984 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.2581 - accuracy: 0.2351 - val_loss: 3.2171 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.2218 - accuracy: 0.2479 - val_loss: 3.3190 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.1805 - accuracy: 0.2851 - val_loss: 3.3962 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.1317 - accuracy: 0.3330 - val_loss: 3.4323 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.0827 - accuracy: 0.3596 - val_loss: 3.3650 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.0215 - accuracy: 0.3968 - val_loss: 3.2521 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.9646 - accuracy: 0.3947 - val_loss: 3.3177 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.8973 - accuracy: 0.4106 - val_loss: 3.4122 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/300\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 1.8273 - accuracy: 0.4415 - val_loss: 3.3082 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.7598 - accuracy: 0.4457 - val_loss: 3.6972 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/300\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 1.6810 - accuracy: 0.4883 - val_loss: 3.7454 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 1.6172 - accuracy: 0.5096 - val_loss: 3.6812 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.5355 - accuracy: 0.5404 - val_loss: 3.3640 - val_accuracy: 0.0200\n",
      "Epoch 19/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.4555 - accuracy: 0.5734 - val_loss: 3.6690 - val_accuracy: 0.0400\n",
      "Epoch 20/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 1.3915 - accuracy: 0.5840 - val_loss: 3.6191 - val_accuracy: 0.0200\n",
      "Epoch 21/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 1.3055 - accuracy: 0.6266 - val_loss: 3.8515 - val_accuracy: 0.0200\n",
      "Epoch 00021: early stopping\n",
      "\n",
      "Trainning fold 5\n",
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_102 (Conv1D)         (None, 126, 64)           6208      \n",
      "                                                                 \n",
      " conv1d_103 (Conv1D)         (None, 124, 32)           6176      \n",
      "                                                                 \n",
      " conv1d_104 (Conv1D)         (None, 122, 16)           1552      \n",
      "                                                                 \n",
      " max_pooling1d_34 (MaxPoolin  (None, 61, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_34 (Flatten)        (None, 976)               0         \n",
      "                                                                 \n",
      " dense_68 (Dense)            (None, 32)                31264     \n",
      "                                                                 \n",
      " dense_69 (Dense)            (None, 11)                363       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45,563\n",
      "Trainable params: 45,563\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "2/2 [==============================] - 1s 150ms/step - loss: 2.4417 - accuracy: 0.1021 - val_loss: 2.5057 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.3806 - accuracy: 0.1213 - val_loss: 2.6251 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 2.3617 - accuracy: 0.1362 - val_loss: 2.6994 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 2.3435 - accuracy: 0.1606 - val_loss: 2.7851 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 2.3222 - accuracy: 0.1883 - val_loss: 2.9193 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.2990 - accuracy: 0.2064 - val_loss: 3.0524 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 2.2740 - accuracy: 0.2160 - val_loss: 3.1715 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 2.2431 - accuracy: 0.2351 - val_loss: 3.2522 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.2102 - accuracy: 0.2745 - val_loss: 3.3270 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.1746 - accuracy: 0.2830 - val_loss: 3.3823 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.1323 - accuracy: 0.3053 - val_loss: 3.4166 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 2.0848 - accuracy: 0.3266 - val_loss: 3.5114 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.0358 - accuracy: 0.3489 - val_loss: 3.6327 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.9841 - accuracy: 0.3617 - val_loss: 3.6853 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.9275 - accuracy: 0.3915 - val_loss: 3.7446 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.8658 - accuracy: 0.4053 - val_loss: 3.7738 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 1.8085 - accuracy: 0.4372 - val_loss: 3.8853 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 1.7469 - accuracy: 0.4362 - val_loss: 3.9783 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/300\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 1.6798 - accuracy: 0.4617 - val_loss: 3.9599 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.6152 - accuracy: 0.4936 - val_loss: 3.9643 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/300\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 1.5554 - accuracy: 0.5011 - val_loss: 4.0055 - val_accuracy: 0.0000e+00\n",
      "Epoch 00021: early stopping\n",
      "\n",
      "Trainning fold 6\n",
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_105 (Conv1D)         (None, 126, 64)           6208      \n",
      "                                                                 \n",
      " conv1d_106 (Conv1D)         (None, 124, 32)           6176      \n",
      "                                                                 \n",
      " conv1d_107 (Conv1D)         (None, 122, 16)           1552      \n",
      "                                                                 \n",
      " max_pooling1d_35 (MaxPoolin  (None, 61, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_35 (Flatten)        (None, 976)               0         \n",
      "                                                                 \n",
      " dense_70 (Dense)            (None, 32)                31264     \n",
      "                                                                 \n",
      " dense_71 (Dense)            (None, 11)                363       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45,563\n",
      "Trainable params: 45,563\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "2/2 [==============================] - 1s 159ms/step - loss: 2.4241 - accuracy: 0.0947 - val_loss: 2.6224 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.3827 - accuracy: 0.1213 - val_loss: 2.7388 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 2.3646 - accuracy: 0.1489 - val_loss: 2.7616 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 2.3489 - accuracy: 0.1436 - val_loss: 2.7869 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.3318 - accuracy: 0.1691 - val_loss: 2.8514 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.3109 - accuracy: 0.1851 - val_loss: 2.9343 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.2849 - accuracy: 0.2170 - val_loss: 3.0504 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.2551 - accuracy: 0.2309 - val_loss: 3.1277 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.2218 - accuracy: 0.2511 - val_loss: 3.2305 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.1829 - accuracy: 0.2649 - val_loss: 3.3177 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.1388 - accuracy: 0.2840 - val_loss: 3.3596 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 2.0937 - accuracy: 0.3043 - val_loss: 3.3526 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.0409 - accuracy: 0.3309 - val_loss: 3.4128 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.9811 - accuracy: 0.3649 - val_loss: 3.4432 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.9165 - accuracy: 0.3830 - val_loss: 3.2911 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.8513 - accuracy: 0.4074 - val_loss: 3.3519 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/300\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 1.7770 - accuracy: 0.4277 - val_loss: 3.3959 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.7052 - accuracy: 0.4574 - val_loss: 3.3066 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.6275 - accuracy: 0.4745 - val_loss: 3.2421 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.5509 - accuracy: 0.5085 - val_loss: 3.3936 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.4728 - accuracy: 0.5404 - val_loss: 3.3236 - val_accuracy: 0.0000e+00\n",
      "Epoch 00021: early stopping\n",
      "\n",
      "Trainning fold 7\n",
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_108 (Conv1D)         (None, 126, 64)           6208      \n",
      "                                                                 \n",
      " conv1d_109 (Conv1D)         (None, 124, 32)           6176      \n",
      "                                                                 \n",
      " conv1d_110 (Conv1D)         (None, 122, 16)           1552      \n",
      "                                                                 \n",
      " max_pooling1d_36 (MaxPoolin  (None, 61, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_36 (Flatten)        (None, 976)               0         \n",
      "                                                                 \n",
      " dense_72 (Dense)            (None, 32)                31264     \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 11)                363       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45,563\n",
      "Trainable params: 45,563\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "2/2 [==============================] - 1s 157ms/step - loss: 2.4222 - accuracy: 0.1032 - val_loss: 2.8898 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.3727 - accuracy: 0.1191 - val_loss: 3.0191 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.3502 - accuracy: 0.1585 - val_loss: 3.0915 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/300\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 2.3307 - accuracy: 0.1819 - val_loss: 3.1589 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 2.3056 - accuracy: 0.2149 - val_loss: 3.2517 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.2822 - accuracy: 0.2032 - val_loss: 3.2913 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 2.2550 - accuracy: 0.2245 - val_loss: 3.3083 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 2.2237 - accuracy: 0.2543 - val_loss: 3.3056 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/300\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 2.1883 - accuracy: 0.2670 - val_loss: 3.3923 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/300\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 2.1466 - accuracy: 0.2894 - val_loss: 3.4707 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/300\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 2.1012 - accuracy: 0.3064 - val_loss: 3.4432 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/300\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 2.0451 - accuracy: 0.3351 - val_loss: 3.4258 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/300\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 1.9845 - accuracy: 0.3574 - val_loss: 3.5443 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.9207 - accuracy: 0.3851 - val_loss: 3.5338 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/300\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 1.8568 - accuracy: 0.4106 - val_loss: 3.4755 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/300\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.7878 - accuracy: 0.4234 - val_loss: 3.5948 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/300\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 1.7174 - accuracy: 0.4479 - val_loss: 3.5444 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/300\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 1.6426 - accuracy: 0.4734 - val_loss: 3.5769 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/300\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 1.5765 - accuracy: 0.5032 - val_loss: 3.5914 - val_accuracy: 0.0200\n",
      "Epoch 20/300\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 1.4964 - accuracy: 0.5298 - val_loss: 3.7491 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/300\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 1.4283 - accuracy: 0.5489 - val_loss: 3.7950 - val_accuracy: 0.0200\n",
      "Epoch 00021: early stopping\n",
      "\n",
      "Trainning fold 8\n",
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_111 (Conv1D)         (None, 126, 64)           6208      \n",
      "                                                                 \n",
      " conv1d_112 (Conv1D)         (None, 124, 32)           6176      \n",
      "                                                                 \n",
      " conv1d_113 (Conv1D)         (None, 122, 16)           1552      \n",
      "                                                                 \n",
      " max_pooling1d_37 (MaxPoolin  (None, 61, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_37 (Flatten)        (None, 976)               0         \n",
      "                                                                 \n",
      " dense_74 (Dense)            (None, 32)                31264     \n",
      "                                                                 \n",
      " dense_75 (Dense)            (None, 11)                363       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45,563\n",
      "Trainable params: 45,563\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 181ms/step - loss: 2.4345 - accuracy: 0.0894 - val_loss: 2.7898 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 2.3800 - accuracy: 0.1170 - val_loss: 2.7841 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 2.3586 - accuracy: 0.1362 - val_loss: 2.7155 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.3415 - accuracy: 0.1617 - val_loss: 2.7012 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 2.3216 - accuracy: 0.1840 - val_loss: 2.7809 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 2.2968 - accuracy: 0.2074 - val_loss: 2.9224 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 2.2659 - accuracy: 0.2160 - val_loss: 3.0114 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 2.2309 - accuracy: 0.2532 - val_loss: 3.0083 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 2.1912 - accuracy: 0.2894 - val_loss: 3.0333 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 2.1442 - accuracy: 0.2989 - val_loss: 3.1093 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.0934 - accuracy: 0.3138 - val_loss: 3.1200 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.0352 - accuracy: 0.3394 - val_loss: 3.3066 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.9725 - accuracy: 0.3691 - val_loss: 3.6122 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/300\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 1.9044 - accuracy: 0.3904 - val_loss: 3.4289 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.8442 - accuracy: 0.4117 - val_loss: 3.6462 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.7726 - accuracy: 0.4362 - val_loss: 3.8058 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.6998 - accuracy: 0.4553 - val_loss: 3.9936 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.6365 - accuracy: 0.4840 - val_loss: 3.8494 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.5722 - accuracy: 0.5043 - val_loss: 4.0511 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.5125 - accuracy: 0.5160 - val_loss: 3.8718 - val_accuracy: 0.0200\n",
      "Epoch 21/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.4407 - accuracy: 0.5596 - val_loss: 3.7274 - val_accuracy: 0.0200\n",
      "Epoch 22/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.3778 - accuracy: 0.5691 - val_loss: 3.9407 - val_accuracy: 0.0200\n",
      "Epoch 23/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.3221 - accuracy: 0.6181 - val_loss: 4.0512 - val_accuracy: 0.0200\n",
      "Epoch 24/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 1.2681 - accuracy: 0.6287 - val_loss: 4.0969 - val_accuracy: 0.0200\n",
      "Epoch 00024: early stopping\n",
      "\n",
      "Trainning fold 9\n",
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_114 (Conv1D)         (None, 126, 64)           6208      \n",
      "                                                                 \n",
      " conv1d_115 (Conv1D)         (None, 124, 32)           6176      \n",
      "                                                                 \n",
      " conv1d_116 (Conv1D)         (None, 122, 16)           1552      \n",
      "                                                                 \n",
      " max_pooling1d_38 (MaxPoolin  (None, 61, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_38 (Flatten)        (None, 976)               0         \n",
      "                                                                 \n",
      " dense_76 (Dense)            (None, 32)                31264     \n",
      "                                                                 \n",
      " dense_77 (Dense)            (None, 11)                363       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45,563\n",
      "Trainable params: 45,563\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "2/2 [==============================] - 1s 158ms/step - loss: 2.5325 - accuracy: 0.0979 - val_loss: 2.4226 - val_accuracy: 0.0400\n",
      "Epoch 2/300\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 2.4002 - accuracy: 0.0947 - val_loss: 2.3924 - val_accuracy: 0.0200\n",
      "Epoch 3/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 2.3893 - accuracy: 0.1011 - val_loss: 2.4376 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/300\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 2.3793 - accuracy: 0.1245 - val_loss: 2.5177 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/300\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 2.3723 - accuracy: 0.1372 - val_loss: 2.6014 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.3657 - accuracy: 0.1266 - val_loss: 2.6890 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 2.3563 - accuracy: 0.1340 - val_loss: 2.7425 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/300\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 2.3447 - accuracy: 0.1543 - val_loss: 2.7612 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/300\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 2.3303 - accuracy: 0.1734 - val_loss: 2.7836 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 2.3149 - accuracy: 0.1766 - val_loss: 2.8116 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.2967 - accuracy: 0.1979 - val_loss: 2.8606 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 2.2783 - accuracy: 0.2106 - val_loss: 2.9355 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/300\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 2.2552 - accuracy: 0.2160 - val_loss: 3.0073 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 2.2305 - accuracy: 0.2309 - val_loss: 3.0591 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 2.2040 - accuracy: 0.2383 - val_loss: 3.1055 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/300\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 2.1731 - accuracy: 0.2606 - val_loss: 3.1529 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/300\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 2.1379 - accuracy: 0.2787 - val_loss: 3.2393 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/300\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 2.1027 - accuracy: 0.2883 - val_loss: 3.2846 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 2.0619 - accuracy: 0.3043 - val_loss: 3.3323 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 2.0172 - accuracy: 0.3340 - val_loss: 3.4824 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/300\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.9645 - accuracy: 0.3500 - val_loss: 3.5085 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.9167 - accuracy: 0.3723 - val_loss: 3.6061 - val_accuracy: 0.0000e+00\n",
      "Epoch 00022: early stopping\n",
      "\n",
      "Trainning fold 10\n",
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_117 (Conv1D)         (None, 126, 64)           6208      \n",
      "                                                                 \n",
      " conv1d_118 (Conv1D)         (None, 124, 32)           6176      \n",
      "                                                                 \n",
      " conv1d_119 (Conv1D)         (None, 122, 16)           1552      \n",
      "                                                                 \n",
      " max_pooling1d_39 (MaxPoolin  (None, 61, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_39 (Flatten)        (None, 976)               0         \n",
      "                                                                 \n",
      " dense_78 (Dense)            (None, 32)                31264     \n",
      "                                                                 \n",
      " dense_79 (Dense)            (None, 11)                363       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45,563\n",
      "Trainable params: 45,563\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 185ms/step - loss: 2.5368 - accuracy: 0.1043 - val_loss: 2.8534 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 2.3851 - accuracy: 0.1170 - val_loss: 2.7821 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/300\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 2.3732 - accuracy: 0.1160 - val_loss: 2.6983 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/300\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 2.3680 - accuracy: 0.1511 - val_loss: 2.6633 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 2.3627 - accuracy: 0.1564 - val_loss: 2.6949 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/300\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 2.3551 - accuracy: 0.1691 - val_loss: 2.7350 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 2.3469 - accuracy: 0.1649 - val_loss: 2.7814 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 2.3351 - accuracy: 0.1713 - val_loss: 2.7872 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 2.3234 - accuracy: 0.1819 - val_loss: 2.7912 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/300\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 2.3086 - accuracy: 0.2096 - val_loss: 2.8259 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 2.2921 - accuracy: 0.2372 - val_loss: 2.8820 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/300\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 2.2735 - accuracy: 0.2617 - val_loss: 2.9594 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/300\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 2.2533 - accuracy: 0.2745 - val_loss: 3.0546 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 2.2316 - accuracy: 0.2894 - val_loss: 3.1495 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/300\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 2.2056 - accuracy: 0.2872 - val_loss: 3.2494 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 2.1763 - accuracy: 0.2936 - val_loss: 3.2847 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 2.1456 - accuracy: 0.3000 - val_loss: 3.3252 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 2.1070 - accuracy: 0.3106 - val_loss: 3.3358 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/300\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 2.0658 - accuracy: 0.3383 - val_loss: 3.3621 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 2.0245 - accuracy: 0.3532 - val_loss: 3.3540 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.9735 - accuracy: 0.3681 - val_loss: 3.3835 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.9272 - accuracy: 0.3713 - val_loss: 3.4679 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/300\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.8703 - accuracy: 0.3894 - val_loss: 3.7014 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/300\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.8179 - accuracy: 0.4106 - val_loss: 3.4289 - val_accuracy: 0.0200\n",
      "Epoch 00024: early stopping\n",
      "\n",
      "Time taken for training:  00:00:21\n",
      "\n",
      "\n",
      "Fold 1 - Train Accuracy 0.4970 - Test Accuracy 0.0636\n",
      "Fold 2 - Train Accuracy 0.5172 - Test Accuracy 0.0909\n",
      "Fold 3 - Train Accuracy 0.4182 - Test Accuracy 0.0909\n",
      "Fold 4 - Train Accuracy 0.6263 - Test Accuracy 0.1273\n",
      "Fold 5 - Train Accuracy 0.4929 - Test Accuracy 0.1091\n",
      "Fold 6 - Train Accuracy 0.5384 - Test Accuracy 0.1000\n",
      "Fold 7 - Train Accuracy 0.5535 - Test Accuracy 0.0545\n",
      "Fold 8 - Train Accuracy 0.6131 - Test Accuracy 0.0727\n",
      "Fold 9 - Train Accuracy 0.3707 - Test Accuracy 0.0909\n",
      "Fold 10 - Train Accuracy 0.4182 - Test Accuracy 0.1000\n",
      "\n",
      "Mean Train Accuracy: 0.5045 \n",
      "Mean Test Accuracy: 0.0900 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "number_of_features = 32\n",
    "\n",
    "def create_baseline():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters = 64, kernel_size = 3, activation = \"relu\", input_shape = (128, number_of_features)))\n",
    "    model.add(Conv1D(filters = 32, kernel_size = 3, activation = \"relu\"))\n",
    "    model.add(Conv1D(filters = 16, kernel_size = 3, activation = \"relu\"))\n",
    "    model.add(MaxPooling1D(pool_size = 2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(32, activation = \"relu\"))\n",
    "    model.add(Dense(11, activation = 'softmax'))\n",
    "    model.summary()\n",
    "    model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "# Defining the number of folds (10 k-Fold).\n",
    "skf = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "\n",
    "# Normalize data.\n",
    "scaler = RobustScaler()\n",
    "scaled_X = scaler.fit_transform(X_resampled)\n",
    "\n",
    "# Reshape the structure data to be compatible with pattern [samples, timesteps, features].\n",
    "X_train_reshaped = scaled_X.reshape((scaled_X.shape[0], 128, number_of_features))\n",
    "\n",
    "\n",
    "# Train the CNN model and evaluate it.\n",
    "start_time = time.time()\n",
    "print(\"\\nStarting training at: \", time.strftime(\"%H:%M:%S\", time.localtime()))\n",
    "es = EarlyStopping(monitor = \"val_loss\", mode = \"min\", verbose = 1, patience = 20)\n",
    "\n",
    "train_accuracy_by_fold = []\n",
    "test_accuracy_by_fold = []\n",
    "fold_number = 1\n",
    "for train_index, test_index in skf.split(X_train_reshaped, y_resampled):\n",
    "    print(\"\\nTrainning fold {}\".format(fold_number))\n",
    "    model = create_baseline()\n",
    "    history = model.fit(X_train_reshaped[train_index], y_resampled[train_index], validation_split = 0.05,\n",
    "                            epochs = 300, batch_size = 512, verbose = 1, callbacks = [es])\n",
    "    _, train_accuracy = model.evaluate(X_train_reshaped[train_index], y_resampled[train_index], verbose = 0)\n",
    "    _, test_accuracy = model.evaluate(X_train_reshaped[test_index], y_resampled[test_index], verbose = 0)\n",
    "    train_accuracy_by_fold.append(train_accuracy)\n",
    "    test_accuracy_by_fold.append(test_accuracy)\n",
    "    fold_number += 1\n",
    "\n",
    "elapsed_seconds = time.time() - start_time\n",
    "print(\"\\nTime taken for training: \", time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_seconds)))\n",
    "print(\"\\n\")\n",
    "\n",
    "# Show metrics.\n",
    "for i in range(len(train_accuracy_by_fold)):\n",
    "    print(\"Fold {} - Train Accuracy {:.4f} - Test Accuracy {:.4f}\".format((i + 1),\n",
    "                            train_accuracy_by_fold[i], test_accuracy_by_fold[i]))\n",
    "print(\"\\nMean Train Accuracy: {:.4f} \".format(np.mean(train_accuracy_by_fold)))\n",
    "print(\"Mean Test Accuracy: {:.4f} \".format(np.mean(test_accuracy_by_fold)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6471e80",
   "metadata": {},
   "source": [
    "#### Train a Convolutional Neural Network model and evaluate the metrics.\n",
    "- Layer architecture => Conv1D (64) + Conv1D (32) + Conv1D (16) + MaxPooling1D + Dense (32) + Dense (11)\n",
    "- 2200 samples (with data augmentation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f6c75df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting data augmentation.\n",
      "\n",
      "Quantity of samples generated by oversampling =>  2200\n",
      "\n",
      "Starting training at:  23:31:13\n",
      "\n",
      "Trainning fold 1\n",
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_120 (Conv1D)         (None, 126, 64)           6208      \n",
      "                                                                 \n",
      " conv1d_121 (Conv1D)         (None, 124, 32)           6176      \n",
      "                                                                 \n",
      " conv1d_122 (Conv1D)         (None, 122, 16)           1552      \n",
      "                                                                 \n",
      " max_pooling1d_40 (MaxPoolin  (None, 61, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_40 (Flatten)        (None, 976)               0         \n",
      "                                                                 \n",
      " dense_80 (Dense)            (None, 32)                31264     \n",
      "                                                                 \n",
      " dense_81 (Dense)            (None, 11)                363       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45,563\n",
      "Trainable params: 45,563\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "4/4 [==============================] - 2s 299ms/step - loss: 2.4339 - accuracy: 0.0968 - val_loss: 2.6486 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 2.3680 - accuracy: 0.1318 - val_loss: 2.6270 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 2.3425 - accuracy: 0.1691 - val_loss: 2.6752 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 2.3054 - accuracy: 0.2041 - val_loss: 2.8246 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 2.2564 - accuracy: 0.2483 - val_loss: 2.9962 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 2.1962 - accuracy: 0.2844 - val_loss: 3.2863 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 2.1287 - accuracy: 0.3137 - val_loss: 3.5569 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 2.0477 - accuracy: 0.3610 - val_loss: 3.3659 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.9585 - accuracy: 0.3982 - val_loss: 3.7430 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.8533 - accuracy: 0.4466 - val_loss: 3.4521 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.7420 - accuracy: 0.4987 - val_loss: 3.5122 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.6353 - accuracy: 0.5189 - val_loss: 3.8361 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.5268 - accuracy: 0.5683 - val_loss: 3.0456 - val_accuracy: 0.1111\n",
      "Epoch 14/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.4084 - accuracy: 0.5917 - val_loss: 3.7775 - val_accuracy: 0.0505\n",
      "Epoch 15/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.3125 - accuracy: 0.6146 - val_loss: 3.2726 - val_accuracy: 0.1515\n",
      "Epoch 16/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.2237 - accuracy: 0.6539 - val_loss: 3.4429 - val_accuracy: 0.1515\n",
      "Epoch 17/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.0983 - accuracy: 0.6954 - val_loss: 3.1367 - val_accuracy: 0.2222\n",
      "Epoch 18/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.9986 - accuracy: 0.7368 - val_loss: 3.6648 - val_accuracy: 0.1919\n",
      "Epoch 19/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.9090 - accuracy: 0.7496 - val_loss: 3.0408 - val_accuracy: 0.2626\n",
      "Epoch 20/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.8231 - accuracy: 0.7847 - val_loss: 3.2042 - val_accuracy: 0.2828\n",
      "Epoch 21/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.7444 - accuracy: 0.8107 - val_loss: 3.3425 - val_accuracy: 0.2929\n",
      "Epoch 22/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.6726 - accuracy: 0.8299 - val_loss: 3.1729 - val_accuracy: 0.3131\n",
      "Epoch 00022: early stopping\n",
      "\n",
      "Trainning fold 2\n",
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_123 (Conv1D)         (None, 126, 64)           6208      \n",
      "                                                                 \n",
      " conv1d_124 (Conv1D)         (None, 124, 32)           6176      \n",
      "                                                                 \n",
      " conv1d_125 (Conv1D)         (None, 122, 16)           1552      \n",
      "                                                                 \n",
      " max_pooling1d_41 (MaxPoolin  (None, 61, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_41 (Flatten)        (None, 976)               0         \n",
      "                                                                 \n",
      " dense_82 (Dense)            (None, 32)                31264     \n",
      "                                                                 \n",
      " dense_83 (Dense)            (None, 11)                363       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45,563\n",
      "Trainable params: 45,563\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "4/4 [==============================] - 1s 67ms/step - loss: 2.4238 - accuracy: 0.0898 - val_loss: 2.7139 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 2.3568 - accuracy: 0.1568 - val_loss: 2.8240 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 2.3262 - accuracy: 0.1701 - val_loss: 2.9994 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 2.2784 - accuracy: 0.2318 - val_loss: 3.0581 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 2.2152 - accuracy: 0.2908 - val_loss: 3.0336 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 2.1333 - accuracy: 0.3477 - val_loss: 3.0926 - val_accuracy: 0.0101\n",
      "Epoch 7/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 2.0295 - accuracy: 0.3822 - val_loss: 3.3977 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.9043 - accuracy: 0.4418 - val_loss: 3.0704 - val_accuracy: 0.0404\n",
      "Epoch 9/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.7697 - accuracy: 0.4657 - val_loss: 3.4940 - val_accuracy: 0.0303\n",
      "Epoch 10/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.6378 - accuracy: 0.5061 - val_loss: 3.1655 - val_accuracy: 0.1313\n",
      "Epoch 11/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.5087 - accuracy: 0.5603 - val_loss: 3.3220 - val_accuracy: 0.1212\n",
      "Epoch 12/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.3676 - accuracy: 0.6093 - val_loss: 3.3253 - val_accuracy: 0.1313\n",
      "Epoch 13/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.2239 - accuracy: 0.6518 - val_loss: 3.3080 - val_accuracy: 0.1919\n",
      "Epoch 14/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.1080 - accuracy: 0.6927 - val_loss: 3.5411 - val_accuracy: 0.1919\n",
      "Epoch 15/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.9867 - accuracy: 0.7347 - val_loss: 3.2571 - val_accuracy: 0.2525\n",
      "Epoch 16/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.8802 - accuracy: 0.7682 - val_loss: 3.2989 - val_accuracy: 0.2626\n",
      "Epoch 17/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.7834 - accuracy: 0.8012 - val_loss: 3.2947 - val_accuracy: 0.2525\n",
      "Epoch 18/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.6901 - accuracy: 0.8299 - val_loss: 3.6761 - val_accuracy: 0.2929\n",
      "Epoch 19/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.6092 - accuracy: 0.8538 - val_loss: 3.1439 - val_accuracy: 0.3030\n",
      "Epoch 20/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.5461 - accuracy: 0.8729 - val_loss: 3.7101 - val_accuracy: 0.2828\n",
      "Epoch 21/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.4769 - accuracy: 0.8884 - val_loss: 3.2682 - val_accuracy: 0.3131\n",
      "Epoch 00021: early stopping\n",
      "\n",
      "Trainning fold 3\n",
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_126 (Conv1D)         (None, 126, 64)           6208      \n",
      "                                                                 \n",
      " conv1d_127 (Conv1D)         (None, 124, 32)           6176      \n",
      "                                                                 \n",
      " conv1d_128 (Conv1D)         (None, 122, 16)           1552      \n",
      "                                                                 \n",
      " max_pooling1d_42 (MaxPoolin  (None, 61, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_42 (Flatten)        (None, 976)               0         \n",
      "                                                                 \n",
      " dense_84 (Dense)            (None, 32)                31264     \n",
      "                                                                 \n",
      " dense_85 (Dense)            (None, 11)                363       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45,563\n",
      "Trainable params: 45,563\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "4/4 [==============================] - 1s 67ms/step - loss: 2.4012 - accuracy: 0.1063 - val_loss: 2.9115 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 2.3267 - accuracy: 0.1568 - val_loss: 2.9528 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 2.2677 - accuracy: 0.2010 - val_loss: 3.2302 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 2.2004 - accuracy: 0.2594 - val_loss: 3.3722 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 2.1126 - accuracy: 0.3083 - val_loss: 3.3246 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 2.0200 - accuracy: 0.3541 - val_loss: 3.6333 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.9128 - accuracy: 0.3955 - val_loss: 3.1648 - val_accuracy: 0.0101\n",
      "Epoch 8/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.7800 - accuracy: 0.4524 - val_loss: 3.2471 - val_accuracy: 0.0202\n",
      "Epoch 9/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.6391 - accuracy: 0.5237 - val_loss: 3.0695 - val_accuracy: 0.0909\n",
      "Epoch 10/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.5070 - accuracy: 0.5635 - val_loss: 2.7212 - val_accuracy: 0.2323\n",
      "Epoch 11/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.3595 - accuracy: 0.6231 - val_loss: 2.8753 - val_accuracy: 0.2525\n",
      "Epoch 12/300\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.2319 - accuracy: 0.6539 - val_loss: 2.6400 - val_accuracy: 0.3030\n",
      "Epoch 13/300\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 1.1104 - accuracy: 0.6996 - val_loss: 3.2933 - val_accuracy: 0.1818\n",
      "Epoch 14/300\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.0226 - accuracy: 0.7166 - val_loss: 2.3703 - val_accuracy: 0.4444\n",
      "Epoch 15/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.9106 - accuracy: 0.7714 - val_loss: 3.0820 - val_accuracy: 0.3333\n",
      "Epoch 16/300\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.7934 - accuracy: 0.8012 - val_loss: 2.6771 - val_accuracy: 0.4242\n",
      "Epoch 17/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.7152 - accuracy: 0.8203 - val_loss: 3.0411 - val_accuracy: 0.3838\n",
      "Epoch 18/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.6353 - accuracy: 0.8394 - val_loss: 2.9179 - val_accuracy: 0.4949\n",
      "Epoch 19/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.5632 - accuracy: 0.8586 - val_loss: 2.9907 - val_accuracy: 0.4545\n",
      "Epoch 20/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.4858 - accuracy: 0.8878 - val_loss: 3.2929 - val_accuracy: 0.4141\n",
      "Epoch 21/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.4358 - accuracy: 0.9022 - val_loss: 2.9406 - val_accuracy: 0.4949\n",
      "Epoch 22/300\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.3837 - accuracy: 0.9176 - val_loss: 3.3787 - val_accuracy: 0.4444\n",
      "Epoch 23/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.3328 - accuracy: 0.9320 - val_loss: 3.0264 - val_accuracy: 0.4949\n",
      "Epoch 24/300\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.2912 - accuracy: 0.9405 - val_loss: 3.4747 - val_accuracy: 0.4646\n",
      "Epoch 25/300\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.2462 - accuracy: 0.9479 - val_loss: 3.2901 - val_accuracy: 0.4848\n",
      "Epoch 26/300\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.2128 - accuracy: 0.9559 - val_loss: 3.5854 - val_accuracy: 0.5051\n",
      "Epoch 27/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.1836 - accuracy: 0.9670 - val_loss: 3.4855 - val_accuracy: 0.5152\n",
      "Epoch 28/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.1524 - accuracy: 0.9777 - val_loss: 3.4767 - val_accuracy: 0.5152\n",
      "Epoch 29/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.1290 - accuracy: 0.9841 - val_loss: 3.9097 - val_accuracy: 0.5253\n",
      "Epoch 30/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.1096 - accuracy: 0.9862 - val_loss: 3.6660 - val_accuracy: 0.5253\n",
      "Epoch 31/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0936 - accuracy: 0.9899 - val_loss: 4.1159 - val_accuracy: 0.5253\n",
      "Epoch 32/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0801 - accuracy: 0.9942 - val_loss: 3.9871 - val_accuracy: 0.5253\n",
      "Epoch 33/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0684 - accuracy: 0.9957 - val_loss: 4.0772 - val_accuracy: 0.5253\n",
      "Epoch 34/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0560 - accuracy: 0.9968 - val_loss: 4.3977 - val_accuracy: 0.5253\n",
      "Epoch 00034: early stopping\n",
      "\n",
      "Trainning fold 4\n",
      "Model: \"sequential_43\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_129 (Conv1D)         (None, 126, 64)           6208      \n",
      "                                                                 \n",
      " conv1d_130 (Conv1D)         (None, 124, 32)           6176      \n",
      "                                                                 \n",
      " conv1d_131 (Conv1D)         (None, 122, 16)           1552      \n",
      "                                                                 \n",
      " max_pooling1d_43 (MaxPoolin  (None, 61, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_43 (Flatten)        (None, 976)               0         \n",
      "                                                                 \n",
      " dense_86 (Dense)            (None, 32)                31264     \n",
      "                                                                 \n",
      " dense_87 (Dense)            (None, 11)                363       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45,563\n",
      "Trainable params: 45,563\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 74ms/step - loss: 2.4113 - accuracy: 0.1069 - val_loss: 2.6670 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 2.3379 - accuracy: 0.1669 - val_loss: 2.8399 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 2.2849 - accuracy: 0.2275 - val_loss: 3.1925 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 2.2136 - accuracy: 0.2924 - val_loss: 3.2123 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 2.1330 - accuracy: 0.3317 - val_loss: 3.3607 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 2.0454 - accuracy: 0.3604 - val_loss: 3.3754 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.9447 - accuracy: 0.3939 - val_loss: 3.6015 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.8295 - accuracy: 0.4285 - val_loss: 3.4821 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.7135 - accuracy: 0.4747 - val_loss: 3.4086 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.6061 - accuracy: 0.4971 - val_loss: 3.4755 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.4961 - accuracy: 0.5476 - val_loss: 3.5504 - val_accuracy: 0.0101\n",
      "Epoch 12/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.3802 - accuracy: 0.5859 - val_loss: 3.1088 - val_accuracy: 0.0606\n",
      "Epoch 13/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.2743 - accuracy: 0.6321 - val_loss: 3.3193 - val_accuracy: 0.0606\n",
      "Epoch 14/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.1617 - accuracy: 0.6693 - val_loss: 3.1647 - val_accuracy: 0.0808\n",
      "Epoch 15/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.0666 - accuracy: 0.6895 - val_loss: 2.9508 - val_accuracy: 0.1212\n",
      "Epoch 16/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.9711 - accuracy: 0.7347 - val_loss: 2.9187 - val_accuracy: 0.1717\n",
      "Epoch 17/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.8872 - accuracy: 0.7565 - val_loss: 2.8990 - val_accuracy: 0.2626\n",
      "Epoch 18/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.7943 - accuracy: 0.7905 - val_loss: 2.7881 - val_accuracy: 0.2020\n",
      "Epoch 19/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.7237 - accuracy: 0.8129 - val_loss: 2.3241 - val_accuracy: 0.4040\n",
      "Epoch 20/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.6555 - accuracy: 0.8389 - val_loss: 2.9416 - val_accuracy: 0.2323\n",
      "Epoch 21/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.5860 - accuracy: 0.8469 - val_loss: 2.6658 - val_accuracy: 0.3535\n",
      "Epoch 22/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.5232 - accuracy: 0.8799 - val_loss: 2.8828 - val_accuracy: 0.2929\n",
      "Epoch 23/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.4723 - accuracy: 0.8846 - val_loss: 2.6648 - val_accuracy: 0.3737\n",
      "Epoch 24/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.4160 - accuracy: 0.9064 - val_loss: 2.4777 - val_accuracy: 0.4040\n",
      "Epoch 25/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.3730 - accuracy: 0.9139 - val_loss: 2.8572 - val_accuracy: 0.3535\n",
      "Epoch 26/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.3284 - accuracy: 0.9245 - val_loss: 2.5917 - val_accuracy: 0.4343\n",
      "Epoch 27/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.2843 - accuracy: 0.9426 - val_loss: 2.7483 - val_accuracy: 0.4040\n",
      "Epoch 28/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.2620 - accuracy: 0.9516 - val_loss: 2.6417 - val_accuracy: 0.4646\n",
      "Epoch 29/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.2254 - accuracy: 0.9623 - val_loss: 2.6724 - val_accuracy: 0.4343\n",
      "Epoch 30/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.1963 - accuracy: 0.9676 - val_loss: 2.9766 - val_accuracy: 0.4343\n",
      "Epoch 31/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.1687 - accuracy: 0.9729 - val_loss: 2.4343 - val_accuracy: 0.5455\n",
      "Epoch 32/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.1499 - accuracy: 0.9761 - val_loss: 3.1014 - val_accuracy: 0.4343\n",
      "Epoch 33/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.1305 - accuracy: 0.9825 - val_loss: 2.4692 - val_accuracy: 0.5253\n",
      "Epoch 34/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.1118 - accuracy: 0.9872 - val_loss: 3.2906 - val_accuracy: 0.4646\n",
      "Epoch 35/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0972 - accuracy: 0.9894 - val_loss: 2.7374 - val_accuracy: 0.5455\n",
      "Epoch 36/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0840 - accuracy: 0.9952 - val_loss: 2.7331 - val_accuracy: 0.5354\n",
      "Epoch 37/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0721 - accuracy: 0.9963 - val_loss: 3.0899 - val_accuracy: 0.5253\n",
      "Epoch 38/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0619 - accuracy: 0.9979 - val_loss: 2.9240 - val_accuracy: 0.5556\n",
      "Epoch 39/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0544 - accuracy: 0.9984 - val_loss: 2.9493 - val_accuracy: 0.5556\n",
      "Epoch 00039: early stopping\n",
      "\n",
      "Trainning fold 5\n",
      "Model: \"sequential_44\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_132 (Conv1D)         (None, 126, 64)           6208      \n",
      "                                                                 \n",
      " conv1d_133 (Conv1D)         (None, 124, 32)           6176      \n",
      "                                                                 \n",
      " conv1d_134 (Conv1D)         (None, 122, 16)           1552      \n",
      "                                                                 \n",
      " max_pooling1d_44 (MaxPoolin  (None, 61, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_44 (Flatten)        (None, 976)               0         \n",
      "                                                                 \n",
      " dense_88 (Dense)            (None, 32)                31264     \n",
      "                                                                 \n",
      " dense_89 (Dense)            (None, 11)                363       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45,563\n",
      "Trainable params: 45,563\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "4/4 [==============================] - 1s 71ms/step - loss: 2.4516 - accuracy: 0.0973 - val_loss: 2.5694 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 2.3780 - accuracy: 0.1053 - val_loss: 2.5804 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 2.3577 - accuracy: 0.1148 - val_loss: 2.6057 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 2.3342 - accuracy: 0.1441 - val_loss: 2.6620 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 2.3025 - accuracy: 0.1579 - val_loss: 2.7218 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 2.2612 - accuracy: 0.1887 - val_loss: 2.8147 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 2.2027 - accuracy: 0.2637 - val_loss: 2.9953 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 2.1314 - accuracy: 0.2935 - val_loss: 3.1405 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 2.0436 - accuracy: 0.3371 - val_loss: 3.2766 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.9383 - accuracy: 0.3998 - val_loss: 3.2899 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.8172 - accuracy: 0.4572 - val_loss: 3.3574 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.6882 - accuracy: 0.4971 - val_loss: 3.2577 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.5653 - accuracy: 0.5327 - val_loss: 3.1718 - val_accuracy: 0.0303\n",
      "Epoch 14/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.4366 - accuracy: 0.5991 - val_loss: 3.3011 - val_accuracy: 0.0101\n",
      "Epoch 15/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.3163 - accuracy: 0.6332 - val_loss: 2.9837 - val_accuracy: 0.0707\n",
      "Epoch 16/300\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 1.2078 - accuracy: 0.6629 - val_loss: 3.1155 - val_accuracy: 0.0606\n",
      "Epoch 17/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.0835 - accuracy: 0.6996 - val_loss: 2.9854 - val_accuracy: 0.1111\n",
      "Epoch 18/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.9892 - accuracy: 0.7363 - val_loss: 2.7334 - val_accuracy: 0.1616\n",
      "Epoch 19/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.8759 - accuracy: 0.7687 - val_loss: 2.8785 - val_accuracy: 0.1616\n",
      "Epoch 20/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.7912 - accuracy: 0.8012 - val_loss: 2.7125 - val_accuracy: 0.2626\n",
      "Epoch 21/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.7030 - accuracy: 0.8198 - val_loss: 2.8259 - val_accuracy: 0.2020\n",
      "Epoch 00021: early stopping\n",
      "\n",
      "Trainning fold 6\n",
      "Model: \"sequential_45\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_135 (Conv1D)         (None, 126, 64)           6208      \n",
      "                                                                 \n",
      " conv1d_136 (Conv1D)         (None, 124, 32)           6176      \n",
      "                                                                 \n",
      " conv1d_137 (Conv1D)         (None, 122, 16)           1552      \n",
      "                                                                 \n",
      " max_pooling1d_45 (MaxPoolin  (None, 61, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_45 (Flatten)        (None, 976)               0         \n",
      "                                                                 \n",
      " dense_90 (Dense)            (None, 32)                31264     \n",
      "                                                                 \n",
      " dense_91 (Dense)            (None, 11)                363       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45,563\n",
      "Trainable params: 45,563\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "4/4 [==============================] - 1s 68ms/step - loss: 2.4311 - accuracy: 0.1005 - val_loss: 2.8307 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 2.3621 - accuracy: 0.1260 - val_loss: 2.7731 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 2.3240 - accuracy: 0.1754 - val_loss: 2.8842 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 2.2705 - accuracy: 0.2275 - val_loss: 3.1061 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 2.1984 - accuracy: 0.2690 - val_loss: 3.1214 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 2.1101 - accuracy: 0.2892 - val_loss: 3.2822 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 2.0063 - accuracy: 0.3546 - val_loss: 3.0492 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.8845 - accuracy: 0.4349 - val_loss: 3.2507 - val_accuracy: 0.0101\n",
      "Epoch 9/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.7564 - accuracy: 0.4545 - val_loss: 3.3957 - val_accuracy: 0.0101\n",
      "Epoch 10/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.6205 - accuracy: 0.5120 - val_loss: 3.0110 - val_accuracy: 0.0505\n",
      "Epoch 11/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.4797 - accuracy: 0.5875 - val_loss: 2.9718 - val_accuracy: 0.1111\n",
      "Epoch 12/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.3460 - accuracy: 0.6188 - val_loss: 3.1587 - val_accuracy: 0.0808\n",
      "Epoch 13/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.2414 - accuracy: 0.6528 - val_loss: 2.9217 - val_accuracy: 0.1616\n",
      "Epoch 14/300\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 1.1080 - accuracy: 0.7044 - val_loss: 3.0780 - val_accuracy: 0.1818\n",
      "Epoch 15/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.9953 - accuracy: 0.7422 - val_loss: 3.2281 - val_accuracy: 0.1717\n",
      "Epoch 16/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.8923 - accuracy: 0.7778 - val_loss: 2.6310 - val_accuracy: 0.2727\n",
      "Epoch 17/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.8010 - accuracy: 0.8038 - val_loss: 3.1248 - val_accuracy: 0.2323\n",
      "Epoch 18/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.7153 - accuracy: 0.8363 - val_loss: 2.6008 - val_accuracy: 0.3131\n",
      "Epoch 19/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.6369 - accuracy: 0.8458 - val_loss: 2.9555 - val_accuracy: 0.2929\n",
      "Epoch 20/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.5743 - accuracy: 0.8671 - val_loss: 3.1961 - val_accuracy: 0.2828\n",
      "Epoch 21/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.4992 - accuracy: 0.8862 - val_loss: 2.7555 - val_accuracy: 0.3232\n",
      "Epoch 22/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.4452 - accuracy: 0.8963 - val_loss: 3.0119 - val_accuracy: 0.4141\n",
      "Epoch 23/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.3949 - accuracy: 0.9139 - val_loss: 2.7456 - val_accuracy: 0.4747\n",
      "Epoch 24/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.3472 - accuracy: 0.9213 - val_loss: 3.4635 - val_accuracy: 0.3434\n",
      "Epoch 25/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.3093 - accuracy: 0.9335 - val_loss: 2.8336 - val_accuracy: 0.4747\n",
      "Epoch 26/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.2649 - accuracy: 0.9468 - val_loss: 3.1025 - val_accuracy: 0.4646\n",
      "Epoch 27/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.2382 - accuracy: 0.9537 - val_loss: 2.9173 - val_accuracy: 0.4747\n",
      "Epoch 28/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.2103 - accuracy: 0.9617 - val_loss: 3.1961 - val_accuracy: 0.4747\n",
      "Epoch 29/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.1749 - accuracy: 0.9708 - val_loss: 3.4377 - val_accuracy: 0.4747\n",
      "Epoch 30/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.1531 - accuracy: 0.9777 - val_loss: 3.0757 - val_accuracy: 0.4848\n",
      "Epoch 31/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.1308 - accuracy: 0.9878 - val_loss: 3.5192 - val_accuracy: 0.4747\n",
      "Epoch 32/300\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.1166 - accuracy: 0.9899 - val_loss: 3.3737 - val_accuracy: 0.4848\n",
      "Epoch 33/300\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0977 - accuracy: 0.9904 - val_loss: 3.4080 - val_accuracy: 0.4949\n",
      "Epoch 34/300\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0871 - accuracy: 0.9942 - val_loss: 4.0619 - val_accuracy: 0.4646\n",
      "Epoch 35/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 33ms/step - loss: 0.0788 - accuracy: 0.9942 - val_loss: 3.3111 - val_accuracy: 0.4949\n",
      "Epoch 36/300\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0646 - accuracy: 0.9973 - val_loss: 3.9972 - val_accuracy: 0.4646\n",
      "Epoch 37/300\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0554 - accuracy: 0.9979 - val_loss: 3.6274 - val_accuracy: 0.4949\n",
      "Epoch 38/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0468 - accuracy: 0.9984 - val_loss: 3.9500 - val_accuracy: 0.4949\n",
      "Epoch 00038: early stopping\n",
      "\n",
      "Trainning fold 7\n",
      "Model: \"sequential_46\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_138 (Conv1D)         (None, 126, 64)           6208      \n",
      "                                                                 \n",
      " conv1d_139 (Conv1D)         (None, 124, 32)           6176      \n",
      "                                                                 \n",
      " conv1d_140 (Conv1D)         (None, 122, 16)           1552      \n",
      "                                                                 \n",
      " max_pooling1d_46 (MaxPoolin  (None, 61, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_46 (Flatten)        (None, 976)               0         \n",
      "                                                                 \n",
      " dense_92 (Dense)            (None, 32)                31264     \n",
      "                                                                 \n",
      " dense_93 (Dense)            (None, 11)                363       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45,563\n",
      "Trainable params: 45,563\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "4/4 [==============================] - 1s 71ms/step - loss: 2.3974 - accuracy: 0.1201 - val_loss: 2.5705 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 2.3365 - accuracy: 0.1770 - val_loss: 2.7238 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 2.2777 - accuracy: 0.1962 - val_loss: 2.7175 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 2.2077 - accuracy: 0.2552 - val_loss: 2.8101 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 2.1174 - accuracy: 0.3179 - val_loss: 2.8527 - val_accuracy: 0.0303\n",
      "Epoch 6/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 2.0098 - accuracy: 0.3594 - val_loss: 2.7884 - val_accuracy: 0.0606\n",
      "Epoch 7/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.8826 - accuracy: 0.4072 - val_loss: 3.0445 - val_accuracy: 0.0303\n",
      "Epoch 8/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.7503 - accuracy: 0.4561 - val_loss: 2.6122 - val_accuracy: 0.1515\n",
      "Epoch 9/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.6081 - accuracy: 0.4992 - val_loss: 3.0840 - val_accuracy: 0.0707\n",
      "Epoch 10/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.4894 - accuracy: 0.5444 - val_loss: 2.8863 - val_accuracy: 0.1717\n",
      "Epoch 11/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.3528 - accuracy: 0.5944 - val_loss: 2.6868 - val_accuracy: 0.2424\n",
      "Epoch 12/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.2277 - accuracy: 0.6316 - val_loss: 2.5728 - val_accuracy: 0.2424\n",
      "Epoch 13/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.1063 - accuracy: 0.6789 - val_loss: 2.7231 - val_accuracy: 0.2727\n",
      "Epoch 14/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.9944 - accuracy: 0.7225 - val_loss: 2.9131 - val_accuracy: 0.2626\n",
      "Epoch 15/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.8887 - accuracy: 0.7618 - val_loss: 2.3455 - val_accuracy: 0.3434\n",
      "Epoch 16/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.7990 - accuracy: 0.7858 - val_loss: 2.7192 - val_accuracy: 0.3232\n",
      "Epoch 17/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.7005 - accuracy: 0.8145 - val_loss: 2.8306 - val_accuracy: 0.3434\n",
      "Epoch 18/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.6259 - accuracy: 0.8453 - val_loss: 2.6475 - val_accuracy: 0.3636\n",
      "Epoch 19/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.5438 - accuracy: 0.8671 - val_loss: 2.4941 - val_accuracy: 0.4040\n",
      "Epoch 20/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.4747 - accuracy: 0.8884 - val_loss: 2.7476 - val_accuracy: 0.3939\n",
      "Epoch 21/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.4200 - accuracy: 0.9048 - val_loss: 2.6109 - val_accuracy: 0.4646\n",
      "Epoch 22/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.3653 - accuracy: 0.9187 - val_loss: 2.5659 - val_accuracy: 0.3939\n",
      "Epoch 23/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.3125 - accuracy: 0.9346 - val_loss: 2.6203 - val_accuracy: 0.5051\n",
      "Epoch 24/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.2698 - accuracy: 0.9516 - val_loss: 2.9410 - val_accuracy: 0.5051\n",
      "Epoch 25/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.2275 - accuracy: 0.9596 - val_loss: 2.3916 - val_accuracy: 0.5253\n",
      "Epoch 26/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.1964 - accuracy: 0.9654 - val_loss: 2.8845 - val_accuracy: 0.5152\n",
      "Epoch 27/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.1635 - accuracy: 0.9771 - val_loss: 3.0606 - val_accuracy: 0.5253\n",
      "Epoch 28/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.1352 - accuracy: 0.9856 - val_loss: 2.6623 - val_accuracy: 0.5253\n",
      "Epoch 29/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.1147 - accuracy: 0.9894 - val_loss: 3.0821 - val_accuracy: 0.5253\n",
      "Epoch 30/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0923 - accuracy: 0.9920 - val_loss: 3.3609 - val_accuracy: 0.5556\n",
      "Epoch 31/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0768 - accuracy: 0.9947 - val_loss: 2.8010 - val_accuracy: 0.5556\n",
      "Epoch 32/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0639 - accuracy: 0.9963 - val_loss: 3.3884 - val_accuracy: 0.5556\n",
      "Epoch 33/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0529 - accuracy: 0.9984 - val_loss: 3.3237 - val_accuracy: 0.5556\n",
      "Epoch 34/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0443 - accuracy: 0.9989 - val_loss: 3.1766 - val_accuracy: 0.5556\n",
      "Epoch 35/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0376 - accuracy: 0.9995 - val_loss: 3.6654 - val_accuracy: 0.5556\n",
      "Epoch 00035: early stopping\n",
      "\n",
      "Trainning fold 8\n",
      "Model: \"sequential_47\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_141 (Conv1D)         (None, 126, 64)           6208      \n",
      "                                                                 \n",
      " conv1d_142 (Conv1D)         (None, 124, 32)           6176      \n",
      "                                                                 \n",
      " conv1d_143 (Conv1D)         (None, 122, 16)           1552      \n",
      "                                                                 \n",
      " max_pooling1d_47 (MaxPoolin  (None, 61, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_47 (Flatten)        (None, 976)               0         \n",
      "                                                                 \n",
      " dense_94 (Dense)            (None, 32)                31264     \n",
      "                                                                 \n",
      " dense_95 (Dense)            (None, 11)                363       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45,563\n",
      "Trainable params: 45,563\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 78ms/step - loss: 2.4165 - accuracy: 0.0946 - val_loss: 2.8714 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 2.3427 - accuracy: 0.1388 - val_loss: 2.8501 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 2.2975 - accuracy: 0.2111 - val_loss: 3.0836 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 2.2327 - accuracy: 0.2350 - val_loss: 3.0359 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 2.1461 - accuracy: 0.3099 - val_loss: 3.2412 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/300\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 2.0478 - accuracy: 0.3557 - val_loss: 3.0411 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/300\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 1.9314 - accuracy: 0.3998 - val_loss: 3.2945 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/300\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.8252 - accuracy: 0.4264 - val_loss: 3.5275 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/300\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 1.7072 - accuracy: 0.4790 - val_loss: 3.1591 - val_accuracy: 0.0202\n",
      "Epoch 10/300\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 1.5920 - accuracy: 0.5221 - val_loss: 3.5551 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 1.4715 - accuracy: 0.5572 - val_loss: 3.1020 - val_accuracy: 0.0404\n",
      "Epoch 12/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 1.3698 - accuracy: 0.6061 - val_loss: 2.8822 - val_accuracy: 0.1010\n",
      "Epoch 13/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 1.2431 - accuracy: 0.6512 - val_loss: 2.9608 - val_accuracy: 0.1414\n",
      "Epoch 14/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.1447 - accuracy: 0.6789 - val_loss: 3.2137 - val_accuracy: 0.1313\n",
      "Epoch 15/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.0617 - accuracy: 0.7124 - val_loss: 3.2991 - val_accuracy: 0.1212\n",
      "Epoch 16/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.9621 - accuracy: 0.7496 - val_loss: 3.1451 - val_accuracy: 0.1818\n",
      "Epoch 17/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.8729 - accuracy: 0.7650 - val_loss: 3.0632 - val_accuracy: 0.2424\n",
      "Epoch 18/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.7834 - accuracy: 0.8017 - val_loss: 2.7771 - val_accuracy: 0.3131\n",
      "Epoch 19/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.6954 - accuracy: 0.8208 - val_loss: 2.8395 - val_accuracy: 0.3333\n",
      "Epoch 20/300\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.6277 - accuracy: 0.8474 - val_loss: 2.9767 - val_accuracy: 0.3232\n",
      "Epoch 21/300\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.5689 - accuracy: 0.8602 - val_loss: 2.7632 - val_accuracy: 0.3636\n",
      "Epoch 22/300\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.5024 - accuracy: 0.8793 - val_loss: 2.8272 - val_accuracy: 0.3636\n",
      "Epoch 23/300\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.4488 - accuracy: 0.8974 - val_loss: 3.2436 - val_accuracy: 0.3434\n",
      "Epoch 24/300\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.3986 - accuracy: 0.9102 - val_loss: 2.8144 - val_accuracy: 0.3838\n",
      "Epoch 25/300\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.3511 - accuracy: 0.9277 - val_loss: 2.9584 - val_accuracy: 0.3636\n",
      "Epoch 26/300\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.3085 - accuracy: 0.9410 - val_loss: 2.5509 - val_accuracy: 0.3838\n",
      "Epoch 27/300\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2724 - accuracy: 0.9495 - val_loss: 3.2251 - val_accuracy: 0.4040\n",
      "Epoch 28/300\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2383 - accuracy: 0.9585 - val_loss: 3.5900 - val_accuracy: 0.4141\n",
      "Epoch 29/300\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.2106 - accuracy: 0.9654 - val_loss: 3.0933 - val_accuracy: 0.4444\n",
      "Epoch 30/300\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.1827 - accuracy: 0.9734 - val_loss: 3.1735 - val_accuracy: 0.4646\n",
      "Epoch 31/300\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1536 - accuracy: 0.9819 - val_loss: 3.3894 - val_accuracy: 0.4848\n",
      "Epoch 32/300\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.1364 - accuracy: 0.9830 - val_loss: 3.0586 - val_accuracy: 0.4848\n",
      "Epoch 33/300\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.1167 - accuracy: 0.9851 - val_loss: 3.1514 - val_accuracy: 0.5152\n",
      "Epoch 34/300\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.1031 - accuracy: 0.9894 - val_loss: 3.2220 - val_accuracy: 0.5253\n",
      "Epoch 35/300\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.0887 - accuracy: 0.9920 - val_loss: 3.5691 - val_accuracy: 0.5152\n",
      "Epoch 36/300\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.0778 - accuracy: 0.9931 - val_loss: 3.5634 - val_accuracy: 0.5253\n",
      "Epoch 37/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.0663 - accuracy: 0.9952 - val_loss: 3.6044 - val_accuracy: 0.5253\n",
      "Epoch 38/300\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.0578 - accuracy: 0.9963 - val_loss: 3.5481 - val_accuracy: 0.5253\n",
      "Epoch 39/300\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.0492 - accuracy: 0.9968 - val_loss: 3.6338 - val_accuracy: 0.5253\n",
      "Epoch 40/300\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.0420 - accuracy: 0.9979 - val_loss: 3.6868 - val_accuracy: 0.5253\n",
      "Epoch 41/300\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.0373 - accuracy: 0.9989 - val_loss: 3.9342 - val_accuracy: 0.5253\n",
      "Epoch 42/300\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.0331 - accuracy: 0.9995 - val_loss: 3.9062 - val_accuracy: 0.5253\n",
      "Epoch 43/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.0291 - accuracy: 1.0000 - val_loss: 3.7841 - val_accuracy: 0.5253\n",
      "Epoch 44/300\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.0264 - accuracy: 1.0000 - val_loss: 4.2417 - val_accuracy: 0.5253\n",
      "Epoch 45/300\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.0237 - accuracy: 1.0000 - val_loss: 3.8745 - val_accuracy: 0.5253\n",
      "Epoch 46/300\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 4.2888 - val_accuracy: 0.5253\n",
      "Epoch 00046: early stopping\n",
      "\n",
      "Trainning fold 9\n",
      "Model: \"sequential_48\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_144 (Conv1D)         (None, 126, 64)           6208      \n",
      "                                                                 \n",
      " conv1d_145 (Conv1D)         (None, 124, 32)           6176      \n",
      "                                                                 \n",
      " conv1d_146 (Conv1D)         (None, 122, 16)           1552      \n",
      "                                                                 \n",
      " max_pooling1d_48 (MaxPoolin  (None, 61, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_48 (Flatten)        (None, 976)               0         \n",
      "                                                                 \n",
      " dense_96 (Dense)            (None, 32)                31264     \n",
      "                                                                 \n",
      " dense_97 (Dense)            (None, 11)                363       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45,563\n",
      "Trainable params: 45,563\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "4/4 [==============================] - 2s 139ms/step - loss: 2.4201 - accuracy: 0.1132 - val_loss: 2.5532 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 2.3637 - accuracy: 0.1419 - val_loss: 2.7026 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/300\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 2.3339 - accuracy: 0.1760 - val_loss: 2.7850 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/300\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 2.2885 - accuracy: 0.2004 - val_loss: 2.7278 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/300\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 2.2258 - accuracy: 0.2791 - val_loss: 2.6909 - val_accuracy: 0.0101\n",
      "Epoch 6/300\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 2.1376 - accuracy: 0.3349 - val_loss: 2.8129 - val_accuracy: 0.0202\n",
      "Epoch 7/300\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 2.0201 - accuracy: 0.3987 - val_loss: 2.6927 - val_accuracy: 0.0707\n",
      "Epoch 8/300\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 1.8822 - accuracy: 0.4439 - val_loss: 2.9476 - val_accuracy: 0.0707\n",
      "Epoch 9/300\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.7442 - accuracy: 0.4774 - val_loss: 3.0888 - val_accuracy: 0.1010\n",
      "Epoch 10/300\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 1.5984 - accuracy: 0.5311 - val_loss: 3.0131 - val_accuracy: 0.1515\n",
      "Epoch 11/300\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 1.4515 - accuracy: 0.5827 - val_loss: 2.8658 - val_accuracy: 0.1212\n",
      "Epoch 12/300\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.3235 - accuracy: 0.6130 - val_loss: 3.0043 - val_accuracy: 0.1919\n",
      "Epoch 13/300\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.1994 - accuracy: 0.6539 - val_loss: 2.7866 - val_accuracy: 0.2222\n",
      "Epoch 14/300\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.0711 - accuracy: 0.6991 - val_loss: 2.5012 - val_accuracy: 0.3232\n",
      "Epoch 15/300\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.9682 - accuracy: 0.7315 - val_loss: 2.8600 - val_accuracy: 0.2929\n",
      "Epoch 16/300\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.8690 - accuracy: 0.7661 - val_loss: 2.8572 - val_accuracy: 0.3030\n",
      "Epoch 17/300\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7714 - accuracy: 0.7990 - val_loss: 2.8523 - val_accuracy: 0.3636\n",
      "Epoch 18/300\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.6862 - accuracy: 0.8187 - val_loss: 2.8173 - val_accuracy: 0.3636\n",
      "Epoch 19/300\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.5990 - accuracy: 0.8522 - val_loss: 2.6497 - val_accuracy: 0.4242\n",
      "Epoch 20/300\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.5262 - accuracy: 0.8788 - val_loss: 2.8541 - val_accuracy: 0.4141\n",
      "Epoch 21/300\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.4691 - accuracy: 0.8926 - val_loss: 2.9713 - val_accuracy: 0.4040\n",
      "Epoch 22/300\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.4081 - accuracy: 0.9123 - val_loss: 3.0665 - val_accuracy: 0.3737\n",
      "Epoch 23/300\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.3572 - accuracy: 0.9229 - val_loss: 2.8085 - val_accuracy: 0.4848\n",
      "Epoch 24/300\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.3137 - accuracy: 0.9330 - val_loss: 2.9653 - val_accuracy: 0.4848\n",
      "Epoch 25/300\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.2743 - accuracy: 0.9463 - val_loss: 2.9916 - val_accuracy: 0.4545\n",
      "Epoch 26/300\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.2357 - accuracy: 0.9511 - val_loss: 3.3078 - val_accuracy: 0.4646\n",
      "Epoch 27/300\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1981 - accuracy: 0.9633 - val_loss: 2.8690 - val_accuracy: 0.5152\n",
      "Epoch 28/300\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.1660 - accuracy: 0.9750 - val_loss: 3.2856 - val_accuracy: 0.4848\n",
      "Epoch 29/300\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.1414 - accuracy: 0.9830 - val_loss: 2.6538 - val_accuracy: 0.5455\n",
      "Epoch 30/300\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.1285 - accuracy: 0.9856 - val_loss: 3.3107 - val_accuracy: 0.5152\n",
      "Epoch 31/300\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1046 - accuracy: 0.9894 - val_loss: 3.1850 - val_accuracy: 0.5354\n",
      "Epoch 32/300\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.0849 - accuracy: 0.9931 - val_loss: 3.2043 - val_accuracy: 0.5556\n",
      "Epoch 33/300\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.0716 - accuracy: 0.9963 - val_loss: 3.2588 - val_accuracy: 0.5556\n",
      "Epoch 34/300\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.0606 - accuracy: 0.9973 - val_loss: 3.3755 - val_accuracy: 0.5556\n",
      "Epoch 00034: early stopping\n",
      "\n",
      "Trainning fold 10\n",
      "Model: \"sequential_49\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_147 (Conv1D)         (None, 126, 64)           6208      \n",
      "                                                                 \n",
      " conv1d_148 (Conv1D)         (None, 124, 32)           6176      \n",
      "                                                                 \n",
      " conv1d_149 (Conv1D)         (None, 122, 16)           1552      \n",
      "                                                                 \n",
      " max_pooling1d_49 (MaxPoolin  (None, 61, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_49 (Flatten)        (None, 976)               0         \n",
      "                                                                 \n",
      " dense_98 (Dense)            (None, 32)                31264     \n",
      "                                                                 \n",
      " dense_99 (Dense)            (None, 11)                363       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45,563\n",
      "Trainable params: 45,563\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "4/4 [==============================] - 1s 116ms/step - loss: 2.4371 - accuracy: 0.1005 - val_loss: 2.9017 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 2.3486 - accuracy: 0.1265 - val_loss: 2.8680 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/300\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 2.3108 - accuracy: 0.1808 - val_loss: 2.9643 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 2.2584 - accuracy: 0.2307 - val_loss: 3.0865 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/300\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 2.1818 - accuracy: 0.2717 - val_loss: 3.0807 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/300\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 2.1036 - accuracy: 0.3222 - val_loss: 3.0249 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/300\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 2.0034 - accuracy: 0.3631 - val_loss: 3.1724 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/300\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 1.8955 - accuracy: 0.4125 - val_loss: 3.1679 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/300\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 1.7654 - accuracy: 0.4790 - val_loss: 3.0644 - val_accuracy: 0.0101\n",
      "Epoch 10/300\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 1.6482 - accuracy: 0.5077 - val_loss: 2.9526 - val_accuracy: 0.0707\n",
      "Epoch 11/300\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 1.5354 - accuracy: 0.5481 - val_loss: 2.8358 - val_accuracy: 0.0808\n",
      "Epoch 12/300\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 1.4035 - accuracy: 0.6013 - val_loss: 3.1950 - val_accuracy: 0.1313\n",
      "Epoch 13/300\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 1.3017 - accuracy: 0.6305 - val_loss: 3.0178 - val_accuracy: 0.1515\n",
      "Epoch 14/300\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 1.2083 - accuracy: 0.6645 - val_loss: 2.7879 - val_accuracy: 0.1717\n",
      "Epoch 15/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 38ms/step - loss: 1.1063 - accuracy: 0.7033 - val_loss: 3.0439 - val_accuracy: 0.1818\n",
      "Epoch 16/300\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 1.0084 - accuracy: 0.7358 - val_loss: 3.0386 - val_accuracy: 0.1818\n",
      "Epoch 17/300\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.9177 - accuracy: 0.7661 - val_loss: 3.0039 - val_accuracy: 0.1919\n",
      "Epoch 18/300\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.8398 - accuracy: 0.7905 - val_loss: 2.7003 - val_accuracy: 0.2222\n",
      "Epoch 19/300\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.7590 - accuracy: 0.8192 - val_loss: 2.9559 - val_accuracy: 0.2222\n",
      "Epoch 20/300\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.6953 - accuracy: 0.8299 - val_loss: 2.8496 - val_accuracy: 0.2727\n",
      "Epoch 21/300\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.6282 - accuracy: 0.8527 - val_loss: 2.9285 - val_accuracy: 0.2929\n",
      "Epoch 22/300\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.5643 - accuracy: 0.8740 - val_loss: 2.7736 - val_accuracy: 0.2828\n",
      "Epoch 23/300\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.4993 - accuracy: 0.8921 - val_loss: 2.8962 - val_accuracy: 0.3030\n",
      "Epoch 24/300\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.4532 - accuracy: 0.9032 - val_loss: 2.7367 - val_accuracy: 0.3333\n",
      "Epoch 25/300\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.4136 - accuracy: 0.9102 - val_loss: 2.9223 - val_accuracy: 0.3131\n",
      "Epoch 26/300\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.3763 - accuracy: 0.9197 - val_loss: 2.6801 - val_accuracy: 0.3737\n",
      "Epoch 27/300\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.3345 - accuracy: 0.9298 - val_loss: 2.8638 - val_accuracy: 0.3838\n",
      "Epoch 28/300\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.2901 - accuracy: 0.9442 - val_loss: 2.9196 - val_accuracy: 0.3939\n",
      "Epoch 29/300\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.2583 - accuracy: 0.9532 - val_loss: 3.0017 - val_accuracy: 0.4040\n",
      "Epoch 30/300\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.2283 - accuracy: 0.9612 - val_loss: 2.6350 - val_accuracy: 0.4949\n",
      "Epoch 31/300\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.2032 - accuracy: 0.9660 - val_loss: 3.0527 - val_accuracy: 0.3939\n",
      "Epoch 32/300\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.1765 - accuracy: 0.9718 - val_loss: 2.9940 - val_accuracy: 0.4747\n",
      "Epoch 33/300\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.1556 - accuracy: 0.9766 - val_loss: 2.8739 - val_accuracy: 0.5152\n",
      "Epoch 34/300\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.1325 - accuracy: 0.9830 - val_loss: 3.2484 - val_accuracy: 0.5051\n",
      "Epoch 35/300\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.1162 - accuracy: 0.9862 - val_loss: 3.0424 - val_accuracy: 0.5152\n",
      "Epoch 36/300\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.1036 - accuracy: 0.9894 - val_loss: 3.1320 - val_accuracy: 0.5152\n",
      "Epoch 37/300\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.0898 - accuracy: 0.9936 - val_loss: 3.2828 - val_accuracy: 0.5051\n",
      "Epoch 38/300\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.0780 - accuracy: 0.9947 - val_loss: 3.3644 - val_accuracy: 0.5152\n",
      "Epoch 39/300\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.0669 - accuracy: 0.9957 - val_loss: 3.2597 - val_accuracy: 0.5253\n",
      "Epoch 40/300\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.0583 - accuracy: 0.9973 - val_loss: 3.4546 - val_accuracy: 0.5253\n",
      "Epoch 41/300\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.0505 - accuracy: 0.9979 - val_loss: 3.6720 - val_accuracy: 0.5152\n",
      "Epoch 42/300\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.0442 - accuracy: 0.9979 - val_loss: 3.4024 - val_accuracy: 0.5253\n",
      "Epoch 43/300\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.0383 - accuracy: 0.9995 - val_loss: 3.7049 - val_accuracy: 0.5253\n",
      "Epoch 44/300\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.0335 - accuracy: 1.0000 - val_loss: 3.7198 - val_accuracy: 0.5253\n",
      "Epoch 45/300\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.0295 - accuracy: 1.0000 - val_loss: 3.7251 - val_accuracy: 0.5253\n",
      "Epoch 46/300\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.0264 - accuracy: 1.0000 - val_loss: 3.8541 - val_accuracy: 0.5253\n",
      "Epoch 47/300\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.0239 - accuracy: 1.0000 - val_loss: 3.8299 - val_accuracy: 0.5354\n",
      "Epoch 48/300\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.0215 - accuracy: 1.0000 - val_loss: 3.9547 - val_accuracy: 0.5253\n",
      "Epoch 49/300\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 4.0327 - val_accuracy: 0.5253\n",
      "Epoch 50/300\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 3.9846 - val_accuracy: 0.5354\n",
      "Epoch 00050: early stopping\n",
      "\n",
      "Time taken for training:  00:00:56\n",
      "\n",
      "\n",
      "Fold 1 - Train Accuracy 0.8247 - Test Accuracy 0.5818\n",
      "Fold 2 - Train Accuracy 0.8652 - Test Accuracy 0.6864\n",
      "Fold 3 - Train Accuracy 0.9737 - Test Accuracy 0.8000\n",
      "Fold 4 - Train Accuracy 0.9773 - Test Accuracy 0.8091\n",
      "Fold 5 - Train Accuracy 0.8091 - Test Accuracy 0.6727\n",
      "Fold 6 - Train Accuracy 0.9737 - Test Accuracy 0.8318\n",
      "Fold 7 - Train Accuracy 0.9773 - Test Accuracy 0.8000\n",
      "Fold 8 - Train Accuracy 0.9763 - Test Accuracy 0.8136\n",
      "Fold 9 - Train Accuracy 0.9763 - Test Accuracy 0.7818\n",
      "Fold 10 - Train Accuracy 0.9768 - Test Accuracy 0.8591\n",
      "\n",
      "Mean Train Accuracy: 0.9330 \n",
      "Mean Test Accuracy: 0.7636 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "number_of_features = 32\n",
    "\n",
    "def create_v1():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters = 64, kernel_size = 3, activation = \"relu\", input_shape = (128, number_of_features)))\n",
    "    model.add(Conv1D(filters = 32, kernel_size = 3, activation = \"relu\"))\n",
    "    model.add(Conv1D(filters = 16, kernel_size = 3, activation = \"relu\"))\n",
    "    model.add(MaxPooling1D(pool_size = 2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(32, activation = \"relu\"))\n",
    "    model.add(Dense(11, activation = 'softmax'))\n",
    "    model.summary()\n",
    "    model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "# Data augmentation (2x).\n",
    "print(\"\\nStarting data augmentation.\")\n",
    "X_all_oversampled = []\n",
    "y_all_oversampled = []\n",
    "for count in range(0, 11):\n",
    "    X_oversampled, y_oversampled = resample(X_resampled[y_resampled == count],\n",
    "                                            y_resampled[y_resampled == count],\n",
    "                                            replace = True,\n",
    "                                            n_samples = 200,\n",
    "                                            random_state = 4)\n",
    "    X_all_oversampled.extend(X_oversampled)\n",
    "    y_all_oversampled.extend(y_oversampled)\n",
    "X_resampled_arr = np.array(X_all_oversampled)\n",
    "y_resampled_arr = np.array(y_all_oversampled)\n",
    "print(\"\\nQuantity of samples generated by oversampling => \", len(y_resampled_arr))\n",
    "\n",
    "\n",
    "# Defining the number of folds (10 k-Fold).\n",
    "skf = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "\n",
    "# Normalize data.\n",
    "scaler = RobustScaler()\n",
    "scaled_X = scaler.fit_transform(X_resampled_arr)\n",
    "\n",
    "# Reshape the structure data to be compatible with pattern [samples, timesteps, features].\n",
    "X_train_reshaped = scaled_X.reshape((scaled_X.shape[0], 128, number_of_features))\n",
    "\n",
    "# Train the CNN model and evaluate it.\n",
    "start_time = time.time()\n",
    "print(\"\\nStarting training at: \", time.strftime(\"%H:%M:%S\", time.localtime()))\n",
    "es = EarlyStopping(monitor = \"val_loss\", mode = \"min\", verbose = 1, patience = 20)\n",
    "\n",
    "train_accuracy_by_fold = []\n",
    "test_accuracy_by_fold = []\n",
    "fold_number = 1\n",
    "for train_index, test_index in skf.split(X_train_reshaped, y_resampled_arr):\n",
    "    print(\"\\nTrainning fold {}\".format(fold_number))\n",
    "    model = create_v1()\n",
    "    history = model.fit(X_train_reshaped[train_index], y_resampled_arr[train_index], validation_split = 0.05,\n",
    "                            epochs = 300, batch_size = 512, verbose = 1, callbacks = [es])\n",
    "    _, train_accuracy = model.evaluate(X_train_reshaped[train_index], y_resampled_arr[train_index], verbose = 0)\n",
    "    _, test_accuracy = model.evaluate(X_train_reshaped[test_index], y_resampled_arr[test_index], verbose = 0)\n",
    "    train_accuracy_by_fold.append(train_accuracy)\n",
    "    test_accuracy_by_fold.append(test_accuracy)\n",
    "    fold_number += 1\n",
    "\n",
    "elapsed_seconds = time.time() - start_time\n",
    "print(\"\\nTime taken for training: \", time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_seconds)))\n",
    "print(\"\\n\")\n",
    "\n",
    "# Show metrics.\n",
    "for i in range(len(train_accuracy_by_fold)):\n",
    "    print(\"Fold {} - Train Accuracy {:.4f} - Test Accuracy {:.4f}\".format((i + 1),\n",
    "                            train_accuracy_by_fold[i], test_accuracy_by_fold[i]))\n",
    "print(\"\\nMean Train Accuracy: {:.4f} \".format(np.mean(train_accuracy_by_fold)))\n",
    "print(\"Mean Test Accuracy: {:.4f} \".format(np.mean(test_accuracy_by_fold)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ad099f",
   "metadata": {},
   "source": [
    "#### Train a Convolutional Neural Network model and evaluate the metrics.\n",
    "- Layer architecture => Conv1D (64) + Conv1D (32) + Conv1D (16) + MaxPooling1D + Dense (32) + Dense (11)\n",
    "- 6600 samples (with data augmentation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aaf55fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting data augmentation.\n",
      "\n",
      "Quantity of samples generated by oversampling =>  6600\n",
      "\n",
      "Starting training at:  23:45:14\n",
      "\n",
      "Trainning fold 1\n",
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_90 (Conv1D)          (None, 126, 64)           6208      \n",
      "                                                                 \n",
      " conv1d_91 (Conv1D)          (None, 124, 32)           6176      \n",
      "                                                                 \n",
      " conv1d_92 (Conv1D)          (None, 122, 16)           1552      \n",
      "                                                                 \n",
      " max_pooling1d_30 (MaxPoolin  (None, 61, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_30 (Flatten)        (None, 976)               0         \n",
      "                                                                 \n",
      " dense_60 (Dense)            (None, 32)                31264     \n",
      "                                                                 \n",
      " dense_61 (Dense)            (None, 11)                363       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45,563\n",
      "Trainable params: 45,563\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "177/177 [==============================] - 1s 5ms/step - loss: 2.0904 - accuracy: 0.2701 - val_loss: 3.3521 - val_accuracy: 0.0471\n",
      "Epoch 2/300\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.8193 - accuracy: 0.7723 - val_loss: 1.4411 - val_accuracy: 0.5253\n",
      "Epoch 3/300\n",
      "177/177 [==============================] - 1s 4ms/step - loss: 0.1832 - accuracy: 0.9621 - val_loss: 0.3098 - val_accuracy: 0.9731\n",
      "Epoch 4/300\n",
      "177/177 [==============================] - 1s 5ms/step - loss: 0.0319 - accuracy: 0.9961 - val_loss: 0.3964 - val_accuracy: 0.9731\n",
      "Epoch 5/300\n",
      "177/177 [==============================] - 2s 9ms/step - loss: 0.0069 - accuracy: 0.9998 - val_loss: 0.4704 - val_accuracy: 0.9596\n",
      "Epoch 6/300\n",
      "177/177 [==============================] - 2s 11ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.5043 - val_accuracy: 0.9731\n",
      "Epoch 7/300\n",
      "177/177 [==============================] - 2s 9ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5284 - val_accuracy: 0.9731\n",
      "Epoch 8/300\n",
      "177/177 [==============================] - 2s 9ms/step - loss: 8.9041e-04 - accuracy: 1.0000 - val_loss: 0.5460 - val_accuracy: 0.9731\n",
      "Epoch 9/300\n",
      "177/177 [==============================] - 2s 9ms/step - loss: 6.7166e-04 - accuracy: 1.0000 - val_loss: 0.5643 - val_accuracy: 0.9731\n",
      "Epoch 10/300\n",
      "177/177 [==============================] - 2s 10ms/step - loss: 5.2218e-04 - accuracy: 1.0000 - val_loss: 0.5709 - val_accuracy: 0.9731\n",
      "Epoch 11/300\n",
      "177/177 [==============================] - 2s 9ms/step - loss: 4.1583e-04 - accuracy: 1.0000 - val_loss: 0.5837 - val_accuracy: 0.9731\n",
      "Epoch 12/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 3.3724e-04 - accuracy: 1.0000 - val_loss: 0.5918 - val_accuracy: 0.9731\n",
      "Epoch 13/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 2.7777e-04 - accuracy: 1.0000 - val_loss: 0.5992 - val_accuracy: 0.9731\n",
      "Epoch 14/300\n",
      "177/177 [==============================] - 2s 9ms/step - loss: 2.3191e-04 - accuracy: 1.0000 - val_loss: 0.6127 - val_accuracy: 0.9731\n",
      "Epoch 15/300\n",
      "177/177 [==============================] - 2s 9ms/step - loss: 1.9558e-04 - accuracy: 1.0000 - val_loss: 0.6287 - val_accuracy: 0.9731\n",
      "Epoch 16/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 1.6679e-04 - accuracy: 1.0000 - val_loss: 0.6323 - val_accuracy: 0.9731\n",
      "Epoch 17/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 1.4257e-04 - accuracy: 1.0000 - val_loss: 0.6339 - val_accuracy: 0.9731\n",
      "Epoch 18/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 1.2321e-04 - accuracy: 1.0000 - val_loss: 0.6493 - val_accuracy: 0.9731\n",
      "Epoch 19/300\n",
      "177/177 [==============================] - 2s 8ms/step - loss: 1.0646e-04 - accuracy: 1.0000 - val_loss: 0.6550 - val_accuracy: 0.9731\n",
      "Epoch 20/300\n",
      "177/177 [==============================] - 2s 9ms/step - loss: 9.2643e-05 - accuracy: 1.0000 - val_loss: 0.6672 - val_accuracy: 0.9731\n",
      "Epoch 21/300\n",
      "177/177 [==============================] - 2s 10ms/step - loss: 8.0955e-05 - accuracy: 1.0000 - val_loss: 0.6716 - val_accuracy: 0.9731\n",
      "Epoch 22/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 7.0855e-05 - accuracy: 1.0000 - val_loss: 0.6807 - val_accuracy: 0.9731\n",
      "Epoch 23/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 6.2229e-05 - accuracy: 1.0000 - val_loss: 0.6872 - val_accuracy: 0.9731\n",
      "Epoch 24/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 5.4850e-05 - accuracy: 1.0000 - val_loss: 0.6939 - val_accuracy: 0.9731\n",
      "Epoch 25/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 4.8380e-05 - accuracy: 1.0000 - val_loss: 0.6960 - val_accuracy: 0.9731\n",
      "Epoch 26/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 4.2872e-05 - accuracy: 1.0000 - val_loss: 0.7097 - val_accuracy: 0.9731\n",
      "Epoch 27/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 3.8082e-05 - accuracy: 1.0000 - val_loss: 0.7107 - val_accuracy: 0.9731\n",
      "Epoch 28/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 3.3819e-05 - accuracy: 1.0000 - val_loss: 0.7210 - val_accuracy: 0.9731\n",
      "Epoch 29/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 3.0112e-05 - accuracy: 1.0000 - val_loss: 0.7267 - val_accuracy: 0.9731\n",
      "Epoch 30/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 2.6768e-05 - accuracy: 1.0000 - val_loss: 0.7299 - val_accuracy: 0.9731\n",
      "Epoch 31/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 2.3903e-05 - accuracy: 1.0000 - val_loss: 0.7410 - val_accuracy: 0.9731\n",
      "Epoch 32/300\n",
      "177/177 [==============================] - 2s 10ms/step - loss: 2.1359e-05 - accuracy: 1.0000 - val_loss: 0.7464 - val_accuracy: 0.9731\n",
      "Epoch 33/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 1.9090e-05 - accuracy: 1.0000 - val_loss: 0.7512 - val_accuracy: 0.9731\n",
      "Epoch 00033: early stopping\n",
      "\n",
      "Trainning fold 2\n",
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_93 (Conv1D)          (None, 126, 64)           6208      \n",
      "                                                                 \n",
      " conv1d_94 (Conv1D)          (None, 124, 32)           6176      \n",
      "                                                                 \n",
      " conv1d_95 (Conv1D)          (None, 122, 16)           1552      \n",
      "                                                                 \n",
      " max_pooling1d_31 (MaxPoolin  (None, 61, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_31 (Flatten)        (None, 976)               0         \n",
      "                                                                 \n",
      " dense_62 (Dense)            (None, 32)                31264     \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 11)                363       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45,563\n",
      "Trainable params: 45,563\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "177/177 [==============================] - 2s 8ms/step - loss: 2.0564 - accuracy: 0.3080 - val_loss: 3.7688 - val_accuracy: 0.0572\n",
      "Epoch 2/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 0.9440 - accuracy: 0.7338 - val_loss: 1.9040 - val_accuracy: 0.4276\n",
      "Epoch 3/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177/177 [==============================] - 1s 7ms/step - loss: 0.2946 - accuracy: 0.9343 - val_loss: 2.0573 - val_accuracy: 0.5455\n",
      "Epoch 4/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 0.0835 - accuracy: 0.9876 - val_loss: 0.4381 - val_accuracy: 0.9226\n",
      "Epoch 5/300\n",
      "177/177 [==============================] - 2s 9ms/step - loss: 0.0234 - accuracy: 0.9975 - val_loss: 0.4637 - val_accuracy: 0.9495\n",
      "Epoch 6/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 0.0079 - accuracy: 0.9995 - val_loss: 0.5491 - val_accuracy: 0.9495\n",
      "Epoch 7/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.5336 - val_accuracy: 0.9495\n",
      "Epoch 8/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5697 - val_accuracy: 0.9495\n",
      "Epoch 9/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6302 - val_accuracy: 0.9495\n",
      "Epoch 10/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 8.2331e-04 - accuracy: 1.0000 - val_loss: 0.6230 - val_accuracy: 0.9495\n",
      "Epoch 11/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 6.4967e-04 - accuracy: 1.0000 - val_loss: 0.6429 - val_accuracy: 0.9495\n",
      "Epoch 12/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 5.2604e-04 - accuracy: 1.0000 - val_loss: 0.6547 - val_accuracy: 0.9495\n",
      "Epoch 13/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 4.3172e-04 - accuracy: 1.0000 - val_loss: 0.6843 - val_accuracy: 0.9495\n",
      "Epoch 14/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 3.5876e-04 - accuracy: 1.0000 - val_loss: 0.6998 - val_accuracy: 0.9495\n",
      "Epoch 15/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 3.0241e-04 - accuracy: 1.0000 - val_loss: 0.7187 - val_accuracy: 0.9495\n",
      "Epoch 16/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 2.5695e-04 - accuracy: 1.0000 - val_loss: 0.7260 - val_accuracy: 0.9495\n",
      "Epoch 17/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 2.1940e-04 - accuracy: 1.0000 - val_loss: 0.7383 - val_accuracy: 0.9495\n",
      "Epoch 18/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 1.8865e-04 - accuracy: 1.0000 - val_loss: 0.7456 - val_accuracy: 0.9495\n",
      "Epoch 19/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 1.6286e-04 - accuracy: 1.0000 - val_loss: 0.7450 - val_accuracy: 0.9495\n",
      "Epoch 20/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 1.4143e-04 - accuracy: 1.0000 - val_loss: 0.7774 - val_accuracy: 0.9495\n",
      "Epoch 21/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 1.2353e-04 - accuracy: 1.0000 - val_loss: 0.7851 - val_accuracy: 0.9495\n",
      "Epoch 22/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 1.0812e-04 - accuracy: 1.0000 - val_loss: 0.7880 - val_accuracy: 0.9495\n",
      "Epoch 23/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 9.4556e-05 - accuracy: 1.0000 - val_loss: 0.8043 - val_accuracy: 0.9495\n",
      "Epoch 24/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 8.3378e-05 - accuracy: 1.0000 - val_loss: 0.8055 - val_accuracy: 0.9495\n",
      "Epoch 25/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 7.3286e-05 - accuracy: 1.0000 - val_loss: 0.8196 - val_accuracy: 0.9495\n",
      "Epoch 26/300\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 6.4983e-05 - accuracy: 1.0000 - val_loss: 0.8365 - val_accuracy: 0.9495\n",
      "Epoch 27/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 5.7468e-05 - accuracy: 1.0000 - val_loss: 0.8406 - val_accuracy: 0.9495\n",
      "Epoch 28/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 5.1124e-05 - accuracy: 1.0000 - val_loss: 0.8493 - val_accuracy: 0.9495\n",
      "Epoch 29/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 4.5402e-05 - accuracy: 1.0000 - val_loss: 0.8520 - val_accuracy: 0.9495\n",
      "Epoch 30/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 4.0172e-05 - accuracy: 1.0000 - val_loss: 0.8723 - val_accuracy: 0.9495\n",
      "Epoch 31/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 3.5994e-05 - accuracy: 1.0000 - val_loss: 0.8595 - val_accuracy: 0.9495\n",
      "Epoch 32/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 3.2100e-05 - accuracy: 1.0000 - val_loss: 0.8849 - val_accuracy: 0.9495\n",
      "Epoch 33/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 2.8579e-05 - accuracy: 1.0000 - val_loss: 0.8964 - val_accuracy: 0.9495\n",
      "Epoch 34/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 2.5554e-05 - accuracy: 1.0000 - val_loss: 0.8933 - val_accuracy: 0.9495\n",
      "Epoch 00034: early stopping\n",
      "\n",
      "Trainning fold 3\n",
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_96 (Conv1D)          (None, 126, 64)           6208      \n",
      "                                                                 \n",
      " conv1d_97 (Conv1D)          (None, 124, 32)           6176      \n",
      "                                                                 \n",
      " conv1d_98 (Conv1D)          (None, 122, 16)           1552      \n",
      "                                                                 \n",
      " max_pooling1d_32 (MaxPoolin  (None, 61, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_32 (Flatten)        (None, 976)               0         \n",
      "                                                                 \n",
      " dense_64 (Dense)            (None, 32)                31264     \n",
      "                                                                 \n",
      " dense_65 (Dense)            (None, 11)                363       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45,563\n",
      "Trainable params: 45,563\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "177/177 [==============================] - 2s 9ms/step - loss: 2.0842 - accuracy: 0.2933 - val_loss: 3.0138 - val_accuracy: 0.0673\n",
      "Epoch 2/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 0.9949 - accuracy: 0.7209 - val_loss: 1.4934 - val_accuracy: 0.5354\n",
      "Epoch 3/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 0.2973 - accuracy: 0.9309 - val_loss: 1.3145 - val_accuracy: 0.7609\n",
      "Epoch 4/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 0.0905 - accuracy: 0.9842 - val_loss: 0.5506 - val_accuracy: 0.9125\n",
      "Epoch 5/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 0.0276 - accuracy: 0.9965 - val_loss: 0.9107 - val_accuracy: 0.9057\n",
      "Epoch 6/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 0.0067 - accuracy: 0.9996 - val_loss: 0.9406 - val_accuracy: 0.9057\n",
      "Epoch 7/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.9344 - val_accuracy: 0.9057\n",
      "Epoch 8/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.9911 - val_accuracy: 0.9057\n",
      "Epoch 9/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.9821 - val_accuracy: 0.9057\n",
      "Epoch 10/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 8.0152e-04 - accuracy: 1.0000 - val_loss: 1.0270 - val_accuracy: 0.9057\n",
      "Epoch 11/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 6.3504e-04 - accuracy: 1.0000 - val_loss: 1.0720 - val_accuracy: 0.9057\n",
      "Epoch 12/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 5.1235e-04 - accuracy: 1.0000 - val_loss: 1.0486 - val_accuracy: 0.9057\n",
      "Epoch 13/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 4.2183e-04 - accuracy: 1.0000 - val_loss: 1.0994 - val_accuracy: 0.9057\n",
      "Epoch 14/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 3.4946e-04 - accuracy: 1.0000 - val_loss: 1.1119 - val_accuracy: 0.9057\n",
      "Epoch 15/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177/177 [==============================] - 1s 6ms/step - loss: 2.9443e-04 - accuracy: 1.0000 - val_loss: 1.1244 - val_accuracy: 0.9057\n",
      "Epoch 16/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 2.4933e-04 - accuracy: 1.0000 - val_loss: 1.1184 - val_accuracy: 0.9057\n",
      "Epoch 17/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 2.1417e-04 - accuracy: 1.0000 - val_loss: 1.1713 - val_accuracy: 0.9057\n",
      "Epoch 18/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 1.8405e-04 - accuracy: 1.0000 - val_loss: 1.1865 - val_accuracy: 0.9057\n",
      "Epoch 19/300\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.5889e-04 - accuracy: 1.0000 - val_loss: 1.2074 - val_accuracy: 0.9057\n",
      "Epoch 20/300\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.3771e-04 - accuracy: 1.0000 - val_loss: 1.2226 - val_accuracy: 0.9057\n",
      "Epoch 21/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 1.1969e-04 - accuracy: 1.0000 - val_loss: 1.2085 - val_accuracy: 0.9057\n",
      "Epoch 22/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 1.0514e-04 - accuracy: 1.0000 - val_loss: 1.2478 - val_accuracy: 0.9057\n",
      "Epoch 23/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 9.2440e-05 - accuracy: 1.0000 - val_loss: 1.2529 - val_accuracy: 0.9057\n",
      "Epoch 24/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 8.1127e-05 - accuracy: 1.0000 - val_loss: 1.2812 - val_accuracy: 0.9057\n",
      "Epoch 25/300\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 7.1536e-05 - accuracy: 1.0000 - val_loss: 1.2585 - val_accuracy: 0.9057\n",
      "Epoch 26/300\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 6.3189e-05 - accuracy: 1.0000 - val_loss: 1.3052 - val_accuracy: 0.9057\n",
      "Epoch 27/300\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 5.6083e-05 - accuracy: 1.0000 - val_loss: 1.3145 - val_accuracy: 0.9057\n",
      "Epoch 28/300\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 4.9708e-05 - accuracy: 1.0000 - val_loss: 1.3235 - val_accuracy: 0.9057\n",
      "Epoch 29/300\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 4.4140e-05 - accuracy: 1.0000 - val_loss: 1.3431 - val_accuracy: 0.9057\n",
      "Epoch 30/300\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 3.9297e-05 - accuracy: 1.0000 - val_loss: 1.3598 - val_accuracy: 0.9057\n",
      "Epoch 31/300\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 3.5125e-05 - accuracy: 1.0000 - val_loss: 1.3558 - val_accuracy: 0.9057\n",
      "Epoch 32/300\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 3.1309e-05 - accuracy: 1.0000 - val_loss: 1.3705 - val_accuracy: 0.9057\n",
      "Epoch 33/300\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 2.7948e-05 - accuracy: 1.0000 - val_loss: 1.4012 - val_accuracy: 0.9057\n",
      "Epoch 34/300\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 2.4963e-05 - accuracy: 1.0000 - val_loss: 1.3857 - val_accuracy: 0.9057\n",
      "Epoch 00034: early stopping\n",
      "\n",
      "Trainning fold 4\n",
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_99 (Conv1D)          (None, 126, 64)           6208      \n",
      "                                                                 \n",
      " conv1d_100 (Conv1D)         (None, 124, 32)           6176      \n",
      "                                                                 \n",
      " conv1d_101 (Conv1D)         (None, 122, 16)           1552      \n",
      "                                                                 \n",
      " max_pooling1d_33 (MaxPoolin  (None, 61, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_33 (Flatten)        (None, 976)               0         \n",
      "                                                                 \n",
      " dense_66 (Dense)            (None, 32)                31264     \n",
      "                                                                 \n",
      " dense_67 (Dense)            (None, 11)                363       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45,563\n",
      "Trainable params: 45,563\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "177/177 [==============================] - 2s 7ms/step - loss: 2.0934 - accuracy: 0.2853 - val_loss: 2.8338 - val_accuracy: 0.1380\n",
      "Epoch 2/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 0.9935 - accuracy: 0.7211 - val_loss: 1.8096 - val_accuracy: 0.4579\n",
      "Epoch 3/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 0.3034 - accuracy: 0.9362 - val_loss: 0.6649 - val_accuracy: 0.8114\n",
      "Epoch 4/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 0.0901 - accuracy: 0.9830 - val_loss: 0.3429 - val_accuracy: 0.9259\n",
      "Epoch 5/300\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 0.0270 - accuracy: 0.9973 - val_loss: 0.2446 - val_accuracy: 0.9562\n",
      "Epoch 6/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.2788 - val_accuracy: 0.9562\n",
      "Epoch 7/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3121 - val_accuracy: 0.9562\n",
      "Epoch 8/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3189 - val_accuracy: 0.9562\n",
      "Epoch 9/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3268 - val_accuracy: 0.9562\n",
      "Epoch 10/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 7.8688e-04 - accuracy: 1.0000 - val_loss: 0.3498 - val_accuracy: 0.9562\n",
      "Epoch 11/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 6.2136e-04 - accuracy: 1.0000 - val_loss: 0.3567 - val_accuracy: 0.9562\n",
      "Epoch 12/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 4.9828e-04 - accuracy: 1.0000 - val_loss: 0.3571 - val_accuracy: 0.9562\n",
      "Epoch 13/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 4.1043e-04 - accuracy: 1.0000 - val_loss: 0.3676 - val_accuracy: 0.9562\n",
      "Epoch 14/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 3.3958e-04 - accuracy: 1.0000 - val_loss: 0.3693 - val_accuracy: 0.9562\n",
      "Epoch 15/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 2.8546e-04 - accuracy: 1.0000 - val_loss: 0.3813 - val_accuracy: 0.9562\n",
      "Epoch 16/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 2.4157e-04 - accuracy: 1.0000 - val_loss: 0.3852 - val_accuracy: 0.9562\n",
      "Epoch 17/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 2.0654e-04 - accuracy: 1.0000 - val_loss: 0.3907 - val_accuracy: 0.9562\n",
      "Epoch 18/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 1.7755e-04 - accuracy: 1.0000 - val_loss: 0.4023 - val_accuracy: 0.9562\n",
      "Epoch 19/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 1.5303e-04 - accuracy: 1.0000 - val_loss: 0.4019 - val_accuracy: 0.9562\n",
      "Epoch 20/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 1.3279e-04 - accuracy: 1.0000 - val_loss: 0.4129 - val_accuracy: 0.9562\n",
      "Epoch 21/300\n",
      "177/177 [==============================] - 2s 9ms/step - loss: 1.1545e-04 - accuracy: 1.0000 - val_loss: 0.4256 - val_accuracy: 0.9562\n",
      "Epoch 22/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 1.0071e-04 - accuracy: 1.0000 - val_loss: 0.4298 - val_accuracy: 0.9562\n",
      "Epoch 23/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 8.8480e-05 - accuracy: 1.0000 - val_loss: 0.4313 - val_accuracy: 0.9562\n",
      "Epoch 24/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 7.7539e-05 - accuracy: 1.0000 - val_loss: 0.4432 - val_accuracy: 0.9562\n",
      "Epoch 25/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 6.8367e-05 - accuracy: 1.0000 - val_loss: 0.4456 - val_accuracy: 0.9562\n",
      "Epoch 26/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 6.0481e-05 - accuracy: 1.0000 - val_loss: 0.4495 - val_accuracy: 0.9562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/300\n",
      "177/177 [==============================] - 2s 9ms/step - loss: 5.3422e-05 - accuracy: 1.0000 - val_loss: 0.4594 - val_accuracy: 0.9562\n",
      "Epoch 28/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 4.7601e-05 - accuracy: 1.0000 - val_loss: 0.4564 - val_accuracy: 0.9562\n",
      "Epoch 29/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 4.2163e-05 - accuracy: 1.0000 - val_loss: 0.4712 - val_accuracy: 0.9562\n",
      "Epoch 30/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 3.7435e-05 - accuracy: 1.0000 - val_loss: 0.4765 - val_accuracy: 0.9562\n",
      "Epoch 31/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 3.3478e-05 - accuracy: 1.0000 - val_loss: 0.4727 - val_accuracy: 0.9562\n",
      "Epoch 32/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 2.9745e-05 - accuracy: 1.0000 - val_loss: 0.4805 - val_accuracy: 0.9562\n",
      "Epoch 33/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 2.6610e-05 - accuracy: 1.0000 - val_loss: 0.4913 - val_accuracy: 0.9562\n",
      "Epoch 34/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 2.3764e-05 - accuracy: 1.0000 - val_loss: 0.4889 - val_accuracy: 0.9562\n",
      "Epoch 35/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 2.1268e-05 - accuracy: 1.0000 - val_loss: 0.4915 - val_accuracy: 0.9562\n",
      "Epoch 00035: early stopping\n",
      "\n",
      "Trainning fold 5\n",
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_102 (Conv1D)         (None, 126, 64)           6208      \n",
      "                                                                 \n",
      " conv1d_103 (Conv1D)         (None, 124, 32)           6176      \n",
      "                                                                 \n",
      " conv1d_104 (Conv1D)         (None, 122, 16)           1552      \n",
      "                                                                 \n",
      " max_pooling1d_34 (MaxPoolin  (None, 61, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_34 (Flatten)        (None, 976)               0         \n",
      "                                                                 \n",
      " dense_68 (Dense)            (None, 32)                31264     \n",
      "                                                                 \n",
      " dense_69 (Dense)            (None, 11)                363       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45,563\n",
      "Trainable params: 45,563\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "177/177 [==============================] - 2s 7ms/step - loss: 2.1498 - accuracy: 0.2584 - val_loss: 2.7722 - val_accuracy: 0.0572\n",
      "Epoch 2/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 1.1039 - accuracy: 0.6755 - val_loss: 1.9453 - val_accuracy: 0.4579\n",
      "Epoch 3/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 0.3623 - accuracy: 0.9169 - val_loss: 1.2731 - val_accuracy: 0.7441\n",
      "Epoch 4/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 0.0900 - accuracy: 0.9848 - val_loss: 0.5754 - val_accuracy: 0.8653\n",
      "Epoch 5/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 0.0195 - accuracy: 0.9981 - val_loss: 0.4897 - val_accuracy: 0.9461\n",
      "Epoch 6/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.5638 - val_accuracy: 0.9461\n",
      "Epoch 7/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.5705 - val_accuracy: 0.9461\n",
      "Epoch 8/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5921 - val_accuracy: 0.9461\n",
      "Epoch 9/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6235 - val_accuracy: 0.9461\n",
      "Epoch 10/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 9.6205e-04 - accuracy: 1.0000 - val_loss: 0.6410 - val_accuracy: 0.9461\n",
      "Epoch 11/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 7.4981e-04 - accuracy: 1.0000 - val_loss: 0.6619 - val_accuracy: 0.9461\n",
      "Epoch 12/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 5.9922e-04 - accuracy: 1.0000 - val_loss: 0.6724 - val_accuracy: 0.9461\n",
      "Epoch 13/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 4.8758e-04 - accuracy: 1.0000 - val_loss: 0.6817 - val_accuracy: 0.9461\n",
      "Epoch 14/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 4.0203e-04 - accuracy: 1.0000 - val_loss: 0.7014 - val_accuracy: 0.9461\n",
      "Epoch 15/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 3.3529e-04 - accuracy: 1.0000 - val_loss: 0.7227 - val_accuracy: 0.9461\n",
      "Epoch 16/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 2.8331e-04 - accuracy: 1.0000 - val_loss: 0.7203 - val_accuracy: 0.9461\n",
      "Epoch 17/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 2.3934e-04 - accuracy: 1.0000 - val_loss: 0.7459 - val_accuracy: 0.9461\n",
      "Epoch 18/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 2.0448e-04 - accuracy: 1.0000 - val_loss: 0.7636 - val_accuracy: 0.9461\n",
      "Epoch 19/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 1.7589e-04 - accuracy: 1.0000 - val_loss: 0.7693 - val_accuracy: 0.9461\n",
      "Epoch 20/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 1.5211e-04 - accuracy: 1.0000 - val_loss: 0.7820 - val_accuracy: 0.9461\n",
      "Epoch 21/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 1.3201e-04 - accuracy: 1.0000 - val_loss: 0.7908 - val_accuracy: 0.9461\n",
      "Epoch 22/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 1.1497e-04 - accuracy: 1.0000 - val_loss: 0.7946 - val_accuracy: 0.9461\n",
      "Epoch 23/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 1.0045e-04 - accuracy: 1.0000 - val_loss: 0.8137 - val_accuracy: 0.9461\n",
      "Epoch 24/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 8.8180e-05 - accuracy: 1.0000 - val_loss: 0.8245 - val_accuracy: 0.9461\n",
      "Epoch 25/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 7.7431e-05 - accuracy: 1.0000 - val_loss: 0.8291 - val_accuracy: 0.9461\n",
      "Epoch 26/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 6.8282e-05 - accuracy: 1.0000 - val_loss: 0.8357 - val_accuracy: 0.9461\n",
      "Epoch 27/300\n",
      "177/177 [==============================] - 2s 10ms/step - loss: 6.0252e-05 - accuracy: 1.0000 - val_loss: 0.8563 - val_accuracy: 0.9461\n",
      "Epoch 28/300\n",
      "177/177 [==============================] - 2s 9ms/step - loss: 5.3236e-05 - accuracy: 1.0000 - val_loss: 0.8583 - val_accuracy: 0.9461\n",
      "Epoch 29/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 4.7054e-05 - accuracy: 1.0000 - val_loss: 0.8729 - val_accuracy: 0.9461\n",
      "Epoch 30/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 4.1889e-05 - accuracy: 1.0000 - val_loss: 0.8813 - val_accuracy: 0.9461\n",
      "Epoch 31/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 3.7303e-05 - accuracy: 1.0000 - val_loss: 0.8829 - val_accuracy: 0.9461\n",
      "Epoch 32/300\n",
      "177/177 [==============================] - 2s 9ms/step - loss: 3.3150e-05 - accuracy: 1.0000 - val_loss: 0.8984 - val_accuracy: 0.9461\n",
      "Epoch 33/300\n",
      "177/177 [==============================] - 2s 9ms/step - loss: 2.9538e-05 - accuracy: 1.0000 - val_loss: 0.9040 - val_accuracy: 0.9461\n",
      "Epoch 34/300\n",
      "177/177 [==============================] - 2s 9ms/step - loss: 2.6366e-05 - accuracy: 1.0000 - val_loss: 0.9102 - val_accuracy: 0.9461\n",
      "Epoch 35/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 2.3537e-05 - accuracy: 1.0000 - val_loss: 0.9241 - val_accuracy: 0.9461\n",
      "Epoch 00035: early stopping\n",
      "\n",
      "Trainning fold 6\n",
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_105 (Conv1D)         (None, 126, 64)           6208      \n",
      "                                                                 \n",
      " conv1d_106 (Conv1D)         (None, 124, 32)           6176      \n",
      "                                                                 \n",
      " conv1d_107 (Conv1D)         (None, 122, 16)           1552      \n",
      "                                                                 \n",
      " max_pooling1d_35 (MaxPoolin  (None, 61, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_35 (Flatten)        (None, 976)               0         \n",
      "                                                                 \n",
      " dense_70 (Dense)            (None, 32)                31264     \n",
      "                                                                 \n",
      " dense_71 (Dense)            (None, 11)                363       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45,563\n",
      "Trainable params: 45,563\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "177/177 [==============================] - 4s 10ms/step - loss: 2.1588 - accuracy: 0.2566 - val_loss: 2.7931 - val_accuracy: 0.0505\n",
      "Epoch 2/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 1.2129 - accuracy: 0.6376 - val_loss: 2.2800 - val_accuracy: 0.3098\n",
      "Epoch 3/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 0.4908 - accuracy: 0.8721 - val_loss: 1.1094 - val_accuracy: 0.6700\n",
      "Epoch 4/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 0.1545 - accuracy: 0.9722 - val_loss: 1.1165 - val_accuracy: 0.6599\n",
      "Epoch 5/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 0.0615 - accuracy: 0.9906 - val_loss: 0.2607 - val_accuracy: 0.9394\n",
      "Epoch 6/300\n",
      "177/177 [==============================] - 2s 9ms/step - loss: 0.0156 - accuracy: 0.9989 - val_loss: 0.2474 - val_accuracy: 0.9529\n",
      "Epoch 7/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 0.0051 - accuracy: 0.9998 - val_loss: 0.2038 - val_accuracy: 0.9663\n",
      "Epoch 8/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2101 - val_accuracy: 0.9663\n",
      "Epoch 9/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2238 - val_accuracy: 0.9663\n",
      "Epoch 10/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2188 - val_accuracy: 0.9663\n",
      "Epoch 11/300\n",
      "177/177 [==============================] - 2s 9ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2187 - val_accuracy: 0.9663\n",
      "Epoch 12/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 8.1053e-04 - accuracy: 1.0000 - val_loss: 0.2331 - val_accuracy: 0.9663\n",
      "Epoch 13/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 6.5765e-04 - accuracy: 1.0000 - val_loss: 0.2381 - val_accuracy: 0.9663\n",
      "Epoch 14/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 5.4065e-04 - accuracy: 1.0000 - val_loss: 0.2384 - val_accuracy: 0.9663\n",
      "Epoch 15/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 4.5422e-04 - accuracy: 1.0000 - val_loss: 0.2440 - val_accuracy: 0.9663\n",
      "Epoch 16/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 3.8228e-04 - accuracy: 1.0000 - val_loss: 0.2407 - val_accuracy: 0.9663\n",
      "Epoch 17/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 3.2499e-04 - accuracy: 1.0000 - val_loss: 0.2490 - val_accuracy: 0.9663\n",
      "Epoch 18/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 2.7838e-04 - accuracy: 1.0000 - val_loss: 0.2450 - val_accuracy: 0.9663\n",
      "Epoch 19/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 2.3988e-04 - accuracy: 1.0000 - val_loss: 0.2565 - val_accuracy: 0.9663\n",
      "Epoch 20/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 2.0684e-04 - accuracy: 1.0000 - val_loss: 0.2632 - val_accuracy: 0.9663\n",
      "Epoch 21/300\n",
      "177/177 [==============================] - 2s 9ms/step - loss: 1.8046e-04 - accuracy: 1.0000 - val_loss: 0.2723 - val_accuracy: 0.9663\n",
      "Epoch 22/300\n",
      "177/177 [==============================] - 2s 9ms/step - loss: 1.5666e-04 - accuracy: 1.0000 - val_loss: 0.2659 - val_accuracy: 0.9663\n",
      "Epoch 23/300\n",
      "177/177 [==============================] - 2s 9ms/step - loss: 1.3720e-04 - accuracy: 1.0000 - val_loss: 0.2740 - val_accuracy: 0.9663\n",
      "Epoch 24/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 1.2049e-04 - accuracy: 1.0000 - val_loss: 0.2748 - val_accuracy: 0.9663\n",
      "Epoch 25/300\n",
      "177/177 [==============================] - 2s 9ms/step - loss: 1.0579e-04 - accuracy: 1.0000 - val_loss: 0.2708 - val_accuracy: 0.9663\n",
      "Epoch 26/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 9.3386e-05 - accuracy: 1.0000 - val_loss: 0.2788 - val_accuracy: 0.9663\n",
      "Epoch 27/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 8.2693e-05 - accuracy: 1.0000 - val_loss: 0.2790 - val_accuracy: 0.9663\n",
      "Epoch 28/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 7.2970e-05 - accuracy: 1.0000 - val_loss: 0.2775 - val_accuracy: 0.9663\n",
      "Epoch 29/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 6.4667e-05 - accuracy: 1.0000 - val_loss: 0.2887 - val_accuracy: 0.9663\n",
      "Epoch 30/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 5.7379e-05 - accuracy: 1.0000 - val_loss: 0.2905 - val_accuracy: 0.9663\n",
      "Epoch 31/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 5.1138e-05 - accuracy: 1.0000 - val_loss: 0.2942 - val_accuracy: 0.9663\n",
      "Epoch 32/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 4.5503e-05 - accuracy: 1.0000 - val_loss: 0.2978 - val_accuracy: 0.9663\n",
      "Epoch 33/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 4.0580e-05 - accuracy: 1.0000 - val_loss: 0.3052 - val_accuracy: 0.9663\n",
      "Epoch 34/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 3.6258e-05 - accuracy: 1.0000 - val_loss: 0.3041 - val_accuracy: 0.9663\n",
      "Epoch 35/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 3.2340e-05 - accuracy: 1.0000 - val_loss: 0.3130 - val_accuracy: 0.9663\n",
      "Epoch 36/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 2.9094e-05 - accuracy: 1.0000 - val_loss: 0.3071 - val_accuracy: 0.9663\n",
      "Epoch 37/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 2.5935e-05 - accuracy: 1.0000 - val_loss: 0.3146 - val_accuracy: 0.9663\n",
      "Epoch 00037: early stopping\n",
      "\n",
      "Trainning fold 7\n",
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_108 (Conv1D)         (None, 126, 64)           6208      \n",
      "                                                                 \n",
      " conv1d_109 (Conv1D)         (None, 124, 32)           6176      \n",
      "                                                                 \n",
      " conv1d_110 (Conv1D)         (None, 122, 16)           1552      \n",
      "                                                                 \n",
      " max_pooling1d_36 (MaxPoolin  (None, 61, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_36 (Flatten)        (None, 976)               0         \n",
      "                                                                 \n",
      " dense_72 (Dense)            (None, 32)                31264     \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 11)                363       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45,563\n",
      "Trainable params: 45,563\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "177/177 [==============================] - 2s 9ms/step - loss: 2.1088 - accuracy: 0.2789 - val_loss: 2.7907 - val_accuracy: 0.0976\n",
      "Epoch 2/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 0.9338 - accuracy: 0.7290 - val_loss: 1.5286 - val_accuracy: 0.4343\n",
      "Epoch 3/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 0.2704 - accuracy: 0.9343 - val_loss: 0.6669 - val_accuracy: 0.8215\n",
      "Epoch 4/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 0.0591 - accuracy: 0.9901 - val_loss: 0.3425 - val_accuracy: 0.9428\n",
      "Epoch 5/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 0.0122 - accuracy: 0.9993 - val_loss: 0.4929 - val_accuracy: 0.9428\n",
      "Epoch 6/300\n",
      "177/177 [==============================] - 2s 10ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.5128 - val_accuracy: 0.9428\n",
      "Epoch 7/300\n",
      "177/177 [==============================] - 2s 9ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5355 - val_accuracy: 0.9428\n",
      "Epoch 8/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5817 - val_accuracy: 0.9394\n",
      "Epoch 9/300\n",
      "177/177 [==============================] - 2s 9ms/step - loss: 7.7684e-04 - accuracy: 1.0000 - val_loss: 0.5892 - val_accuracy: 0.9394\n",
      "Epoch 10/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177/177 [==============================] - 1s 8ms/step - loss: 5.9701e-04 - accuracy: 1.0000 - val_loss: 0.6111 - val_accuracy: 0.9394\n",
      "Epoch 11/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 4.6956e-04 - accuracy: 1.0000 - val_loss: 0.6364 - val_accuracy: 0.9394\n",
      "Epoch 12/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 3.7880e-04 - accuracy: 1.0000 - val_loss: 0.6368 - val_accuracy: 0.9394\n",
      "Epoch 13/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 3.1114e-04 - accuracy: 1.0000 - val_loss: 0.6645 - val_accuracy: 0.9394\n",
      "Epoch 14/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 2.5631e-04 - accuracy: 1.0000 - val_loss: 0.6728 - val_accuracy: 0.9394\n",
      "Epoch 15/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 2.1528e-04 - accuracy: 1.0000 - val_loss: 0.6944 - val_accuracy: 0.9394\n",
      "Epoch 16/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 1.8204e-04 - accuracy: 1.0000 - val_loss: 0.7015 - val_accuracy: 0.9394\n",
      "Epoch 17/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 1.5497e-04 - accuracy: 1.0000 - val_loss: 0.7278 - val_accuracy: 0.9394\n",
      "Epoch 18/300\n",
      "177/177 [==============================] - 2s 9ms/step - loss: 1.3342e-04 - accuracy: 1.0000 - val_loss: 0.7137 - val_accuracy: 0.9394\n",
      "Epoch 19/300\n",
      "177/177 [==============================] - 2s 11ms/step - loss: 1.1507e-04 - accuracy: 1.0000 - val_loss: 0.7321 - val_accuracy: 0.9394\n",
      "Epoch 20/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 9.9502e-05 - accuracy: 1.0000 - val_loss: 0.7475 - val_accuracy: 0.9394\n",
      "Epoch 21/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 8.6719e-05 - accuracy: 1.0000 - val_loss: 0.7530 - val_accuracy: 0.9394\n",
      "Epoch 22/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 7.5559e-05 - accuracy: 1.0000 - val_loss: 0.7824 - val_accuracy: 0.9394\n",
      "Epoch 23/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 6.6489e-05 - accuracy: 1.0000 - val_loss: 0.7778 - val_accuracy: 0.9394\n",
      "Epoch 24/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 5.8256e-05 - accuracy: 1.0000 - val_loss: 0.7857 - val_accuracy: 0.9394\n",
      "Epoch 25/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 5.1263e-05 - accuracy: 1.0000 - val_loss: 0.7992 - val_accuracy: 0.9394\n",
      "Epoch 26/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 4.5269e-05 - accuracy: 1.0000 - val_loss: 0.8139 - val_accuracy: 0.9394\n",
      "Epoch 27/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 4.0146e-05 - accuracy: 1.0000 - val_loss: 0.8202 - val_accuracy: 0.9394\n",
      "Epoch 28/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 3.5557e-05 - accuracy: 1.0000 - val_loss: 0.8332 - val_accuracy: 0.9394\n",
      "Epoch 29/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 3.1556e-05 - accuracy: 1.0000 - val_loss: 0.8483 - val_accuracy: 0.9394\n",
      "Epoch 30/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 2.8083e-05 - accuracy: 1.0000 - val_loss: 0.8592 - val_accuracy: 0.9394\n",
      "Epoch 31/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 2.5040e-05 - accuracy: 1.0000 - val_loss: 0.8611 - val_accuracy: 0.9394\n",
      "Epoch 32/300\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 2.2330e-05 - accuracy: 1.0000 - val_loss: 0.8714 - val_accuracy: 0.9394\n",
      "Epoch 33/300\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.9960e-05 - accuracy: 1.0000 - val_loss: 0.8775 - val_accuracy: 0.9394\n",
      "Epoch 34/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 1.7805e-05 - accuracy: 1.0000 - val_loss: 0.8897 - val_accuracy: 0.9394\n",
      "Epoch 00034: early stopping\n",
      "\n",
      "Trainning fold 8\n",
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_111 (Conv1D)         (None, 126, 64)           6208      \n",
      "                                                                 \n",
      " conv1d_112 (Conv1D)         (None, 124, 32)           6176      \n",
      "                                                                 \n",
      " conv1d_113 (Conv1D)         (None, 122, 16)           1552      \n",
      "                                                                 \n",
      " max_pooling1d_37 (MaxPoolin  (None, 61, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_37 (Flatten)        (None, 976)               0         \n",
      "                                                                 \n",
      " dense_74 (Dense)            (None, 32)                31264     \n",
      "                                                                 \n",
      " dense_75 (Dense)            (None, 11)                363       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45,563\n",
      "Trainable params: 45,563\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "177/177 [==============================] - 2s 7ms/step - loss: 2.1957 - accuracy: 0.2295 - val_loss: 3.0661 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.2280 - accuracy: 0.6284 - val_loss: 2.0844 - val_accuracy: 0.2997\n",
      "Epoch 3/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 0.4280 - accuracy: 0.8862 - val_loss: 0.6528 - val_accuracy: 0.8114\n",
      "Epoch 4/300\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 0.1226 - accuracy: 0.9761 - val_loss: 0.3672 - val_accuracy: 0.9158\n",
      "Epoch 5/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 0.0355 - accuracy: 0.9950 - val_loss: 0.3294 - val_accuracy: 0.9461\n",
      "Epoch 6/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 0.0100 - accuracy: 0.9996 - val_loss: 0.2313 - val_accuracy: 0.9461\n",
      "Epoch 7/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2605 - val_accuracy: 0.9461\n",
      "Epoch 8/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2898 - val_accuracy: 0.9461\n",
      "Epoch 9/300\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2831 - val_accuracy: 0.9596\n",
      "Epoch 10/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 7.9189e-04 - accuracy: 1.0000 - val_loss: 0.2949 - val_accuracy: 0.9461\n",
      "Epoch 11/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 6.1273e-04 - accuracy: 1.0000 - val_loss: 0.3021 - val_accuracy: 0.9461\n",
      "Epoch 12/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 4.9112e-04 - accuracy: 1.0000 - val_loss: 0.3052 - val_accuracy: 0.9596\n",
      "Epoch 13/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 3.9900e-04 - accuracy: 1.0000 - val_loss: 0.3106 - val_accuracy: 0.9596\n",
      "Epoch 14/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 3.2968e-04 - accuracy: 1.0000 - val_loss: 0.3150 - val_accuracy: 0.9596\n",
      "Epoch 15/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 2.7631e-04 - accuracy: 1.0000 - val_loss: 0.3140 - val_accuracy: 0.9596\n",
      "Epoch 16/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 2.3273e-04 - accuracy: 1.0000 - val_loss: 0.3203 - val_accuracy: 0.9596\n",
      "Epoch 17/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 1.9906e-04 - accuracy: 1.0000 - val_loss: 0.3179 - val_accuracy: 0.9596\n",
      "Epoch 18/300\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.7041e-04 - accuracy: 1.0000 - val_loss: 0.3237 - val_accuracy: 0.9596\n",
      "Epoch 19/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 1.4719e-04 - accuracy: 1.0000 - val_loss: 0.3316 - val_accuracy: 0.9596\n",
      "Epoch 20/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 1.2738e-04 - accuracy: 1.0000 - val_loss: 0.3341 - val_accuracy: 0.9596\n",
      "Epoch 21/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 1.1095e-04 - accuracy: 1.0000 - val_loss: 0.3257 - val_accuracy: 0.9596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 9.6747e-05 - accuracy: 1.0000 - val_loss: 0.3395 - val_accuracy: 0.9596\n",
      "Epoch 23/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 8.4598e-05 - accuracy: 1.0000 - val_loss: 0.3440 - val_accuracy: 0.9596\n",
      "Epoch 24/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 7.4391e-05 - accuracy: 1.0000 - val_loss: 0.3474 - val_accuracy: 0.9596\n",
      "Epoch 25/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 6.5636e-05 - accuracy: 1.0000 - val_loss: 0.3468 - val_accuracy: 0.9596\n",
      "Epoch 26/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 5.7969e-05 - accuracy: 1.0000 - val_loss: 0.3534 - val_accuracy: 0.9596\n",
      "Epoch 27/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 5.1300e-05 - accuracy: 1.0000 - val_loss: 0.3511 - val_accuracy: 0.9596\n",
      "Epoch 28/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 4.5527e-05 - accuracy: 1.0000 - val_loss: 0.3503 - val_accuracy: 0.9596\n",
      "Epoch 29/300\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 4.0373e-05 - accuracy: 1.0000 - val_loss: 0.3576 - val_accuracy: 0.9596\n",
      "Epoch 30/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 3.5901e-05 - accuracy: 1.0000 - val_loss: 0.3595 - val_accuracy: 0.9596\n",
      "Epoch 31/300\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 3.1908e-05 - accuracy: 1.0000 - val_loss: 0.3645 - val_accuracy: 0.9596\n",
      "Epoch 32/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 2.8503e-05 - accuracy: 1.0000 - val_loss: 0.3556 - val_accuracy: 0.9596\n",
      "Epoch 33/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 2.5472e-05 - accuracy: 1.0000 - val_loss: 0.3656 - val_accuracy: 0.9596\n",
      "Epoch 34/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 2.2687e-05 - accuracy: 1.0000 - val_loss: 0.3646 - val_accuracy: 0.9596\n",
      "Epoch 35/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 2.0271e-05 - accuracy: 1.0000 - val_loss: 0.3640 - val_accuracy: 0.9596\n",
      "Epoch 36/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 1.8167e-05 - accuracy: 1.0000 - val_loss: 0.3772 - val_accuracy: 0.9461\n",
      "Epoch 00036: early stopping\n",
      "\n",
      "Trainning fold 9\n",
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_114 (Conv1D)         (None, 126, 64)           6208      \n",
      "                                                                 \n",
      " conv1d_115 (Conv1D)         (None, 124, 32)           6176      \n",
      "                                                                 \n",
      " conv1d_116 (Conv1D)         (None, 122, 16)           1552      \n",
      "                                                                 \n",
      " max_pooling1d_38 (MaxPoolin  (None, 61, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_38 (Flatten)        (None, 976)               0         \n",
      "                                                                 \n",
      " dense_76 (Dense)            (None, 32)                31264     \n",
      "                                                                 \n",
      " dense_77 (Dense)            (None, 11)                363       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45,563\n",
      "Trainable params: 45,563\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "177/177 [==============================] - 2s 6ms/step - loss: 2.1222 - accuracy: 0.2704 - val_loss: 2.6276 - val_accuracy: 0.1717\n",
      "Epoch 2/300\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.0319 - accuracy: 0.7051 - val_loss: 2.0146 - val_accuracy: 0.3535\n",
      "Epoch 3/300\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 0.3109 - accuracy: 0.9270 - val_loss: 1.1713 - val_accuracy: 0.7374\n",
      "Epoch 4/300\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 0.0842 - accuracy: 0.9833 - val_loss: 1.1290 - val_accuracy: 0.8350\n",
      "Epoch 5/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 0.0268 - accuracy: 0.9957 - val_loss: 1.0569 - val_accuracy: 0.9192\n",
      "Epoch 6/300\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.0322 - val_accuracy: 0.9293\n",
      "Epoch 7/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.1300 - val_accuracy: 0.9293\n",
      "Epoch 8/300\n",
      "177/177 [==============================] - 2s 9ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.1841 - val_accuracy: 0.9293\n",
      "Epoch 9/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 8.1458e-04 - accuracy: 1.0000 - val_loss: 1.2336 - val_accuracy: 0.9293\n",
      "Epoch 10/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 6.2480e-04 - accuracy: 1.0000 - val_loss: 1.2476 - val_accuracy: 0.9293\n",
      "Epoch 11/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 4.9523e-04 - accuracy: 1.0000 - val_loss: 1.2816 - val_accuracy: 0.9293\n",
      "Epoch 12/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 4.0128e-04 - accuracy: 1.0000 - val_loss: 1.3000 - val_accuracy: 0.9293\n",
      "Epoch 13/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 3.3065e-04 - accuracy: 1.0000 - val_loss: 1.3434 - val_accuracy: 0.9293\n",
      "Epoch 14/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 2.7475e-04 - accuracy: 1.0000 - val_loss: 1.3634 - val_accuracy: 0.9293\n",
      "Epoch 15/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 2.3245e-04 - accuracy: 1.0000 - val_loss: 1.4021 - val_accuracy: 0.9293\n",
      "Epoch 16/300\n",
      "177/177 [==============================] - 2s 9ms/step - loss: 1.9619e-04 - accuracy: 1.0000 - val_loss: 1.4183 - val_accuracy: 0.9293\n",
      "Epoch 17/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 1.6812e-04 - accuracy: 1.0000 - val_loss: 1.4452 - val_accuracy: 0.9293\n",
      "Epoch 18/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 1.4479e-04 - accuracy: 1.0000 - val_loss: 1.4581 - val_accuracy: 0.9293\n",
      "Epoch 19/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 1.2500e-04 - accuracy: 1.0000 - val_loss: 1.4786 - val_accuracy: 0.9293\n",
      "Epoch 20/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 1.0840e-04 - accuracy: 1.0000 - val_loss: 1.5044 - val_accuracy: 0.9293\n",
      "Epoch 21/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 9.4853e-05 - accuracy: 1.0000 - val_loss: 1.5252 - val_accuracy: 0.9293\n",
      "Epoch 22/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 8.2671e-05 - accuracy: 1.0000 - val_loss: 1.5316 - val_accuracy: 0.9293\n",
      "Epoch 23/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 7.2794e-05 - accuracy: 1.0000 - val_loss: 1.5603 - val_accuracy: 0.9293\n",
      "Epoch 24/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 6.4118e-05 - accuracy: 1.0000 - val_loss: 1.5839 - val_accuracy: 0.9293\n",
      "Epoch 25/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 5.6442e-05 - accuracy: 1.0000 - val_loss: 1.5943 - val_accuracy: 0.9293\n",
      "Epoch 26/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 5.0065e-05 - accuracy: 1.0000 - val_loss: 1.6209 - val_accuracy: 0.9293\n",
      "Epoch 27/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 4.4272e-05 - accuracy: 1.0000 - val_loss: 1.6380 - val_accuracy: 0.9293\n",
      "Epoch 28/300\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 3.9330e-05 - accuracy: 1.0000 - val_loss: 1.6541 - val_accuracy: 0.9293\n",
      "Epoch 29/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 3.4892e-05 - accuracy: 1.0000 - val_loss: 1.6765 - val_accuracy: 0.9293\n",
      "Epoch 30/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 3.1057e-05 - accuracy: 1.0000 - val_loss: 1.6918 - val_accuracy: 0.9293\n",
      "Epoch 31/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 2.7732e-05 - accuracy: 1.0000 - val_loss: 1.7106 - val_accuracy: 0.9293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 2.4686e-05 - accuracy: 1.0000 - val_loss: 1.7316 - val_accuracy: 0.9293\n",
      "Epoch 33/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 2.2066e-05 - accuracy: 1.0000 - val_loss: 1.7504 - val_accuracy: 0.9293\n",
      "Epoch 34/300\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.9732e-05 - accuracy: 1.0000 - val_loss: 1.7626 - val_accuracy: 0.9293\n",
      "Epoch 35/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 1.7668e-05 - accuracy: 1.0000 - val_loss: 1.7795 - val_accuracy: 0.9293\n",
      "Epoch 36/300\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.5846e-05 - accuracy: 1.0000 - val_loss: 1.7969 - val_accuracy: 0.9293\n",
      "Epoch 00036: early stopping\n",
      "\n",
      "Trainning fold 10\n",
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_117 (Conv1D)         (None, 126, 64)           6208      \n",
      "                                                                 \n",
      " conv1d_118 (Conv1D)         (None, 124, 32)           6176      \n",
      "                                                                 \n",
      " conv1d_119 (Conv1D)         (None, 122, 16)           1552      \n",
      "                                                                 \n",
      " max_pooling1d_39 (MaxPoolin  (None, 61, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_39 (Flatten)        (None, 976)               0         \n",
      "                                                                 \n",
      " dense_78 (Dense)            (None, 32)                31264     \n",
      "                                                                 \n",
      " dense_79 (Dense)            (None, 11)                363       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45,563\n",
      "Trainable params: 45,563\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "177/177 [==============================] - 2s 7ms/step - loss: 2.2100 - accuracy: 0.2272 - val_loss: 3.5475 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.2804 - accuracy: 0.6174 - val_loss: 2.1766 - val_accuracy: 0.2492\n",
      "Epoch 3/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 0.4945 - accuracy: 0.8710 - val_loss: 1.2194 - val_accuracy: 0.6061\n",
      "Epoch 4/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 0.1629 - accuracy: 0.9653 - val_loss: 0.6252 - val_accuracy: 0.9158\n",
      "Epoch 5/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 0.0578 - accuracy: 0.9913 - val_loss: 0.4800 - val_accuracy: 0.9461\n",
      "Epoch 6/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 0.0164 - accuracy: 0.9988 - val_loss: 0.4902 - val_accuracy: 0.9495\n",
      "Epoch 7/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 0.0056 - accuracy: 0.9998 - val_loss: 0.5016 - val_accuracy: 0.9495\n",
      "Epoch 8/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.5290 - val_accuracy: 0.9495\n",
      "Epoch 9/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5753 - val_accuracy: 0.9495\n",
      "Epoch 10/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5790 - val_accuracy: 0.9495\n",
      "Epoch 11/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.5942 - val_accuracy: 0.9495\n",
      "Epoch 12/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 8.2235e-04 - accuracy: 1.0000 - val_loss: 0.6139 - val_accuracy: 0.9495\n",
      "Epoch 13/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 6.6948e-04 - accuracy: 1.0000 - val_loss: 0.6272 - val_accuracy: 0.9495\n",
      "Epoch 14/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 5.5024e-04 - accuracy: 1.0000 - val_loss: 0.6375 - val_accuracy: 0.9495\n",
      "Epoch 15/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 4.5400e-04 - accuracy: 1.0000 - val_loss: 0.6679 - val_accuracy: 0.9495\n",
      "Epoch 16/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 3.8426e-04 - accuracy: 1.0000 - val_loss: 0.6700 - val_accuracy: 0.9495\n",
      "Epoch 17/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 3.2401e-04 - accuracy: 1.0000 - val_loss: 0.6944 - val_accuracy: 0.9495\n",
      "Epoch 18/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 2.7942e-04 - accuracy: 1.0000 - val_loss: 0.7024 - val_accuracy: 0.9495\n",
      "Epoch 19/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 2.3843e-04 - accuracy: 1.0000 - val_loss: 0.7113 - val_accuracy: 0.9495\n",
      "Epoch 20/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 2.0515e-04 - accuracy: 1.0000 - val_loss: 0.7152 - val_accuracy: 0.9495\n",
      "Epoch 21/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 1.7967e-04 - accuracy: 1.0000 - val_loss: 0.7314 - val_accuracy: 0.9495\n",
      "Epoch 22/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 1.5577e-04 - accuracy: 1.0000 - val_loss: 0.7399 - val_accuracy: 0.9495\n",
      "Epoch 23/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 1.3606e-04 - accuracy: 1.0000 - val_loss: 0.7488 - val_accuracy: 0.9495\n",
      "Epoch 24/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 1.1944e-04 - accuracy: 1.0000 - val_loss: 0.7737 - val_accuracy: 0.9495\n",
      "Epoch 25/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 1.0500e-04 - accuracy: 1.0000 - val_loss: 0.7695 - val_accuracy: 0.9495\n",
      "Epoch 26/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 9.2188e-05 - accuracy: 1.0000 - val_loss: 0.7746 - val_accuracy: 0.9495\n",
      "Epoch 27/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 8.1369e-05 - accuracy: 1.0000 - val_loss: 0.7879 - val_accuracy: 0.9495\n",
      "Epoch 28/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 7.2183e-05 - accuracy: 1.0000 - val_loss: 0.8016 - val_accuracy: 0.9495\n",
      "Epoch 29/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 6.4066e-05 - accuracy: 1.0000 - val_loss: 0.8118 - val_accuracy: 0.9495\n",
      "Epoch 30/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 5.6506e-05 - accuracy: 1.0000 - val_loss: 0.8238 - val_accuracy: 0.9495\n",
      "Epoch 31/300\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 5.0333e-05 - accuracy: 1.0000 - val_loss: 0.8360 - val_accuracy: 0.9495\n",
      "Epoch 32/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 4.4754e-05 - accuracy: 1.0000 - val_loss: 0.8363 - val_accuracy: 0.9495\n",
      "Epoch 33/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 3.9818e-05 - accuracy: 1.0000 - val_loss: 0.8465 - val_accuracy: 0.9495\n",
      "Epoch 34/300\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 3.5478e-05 - accuracy: 1.0000 - val_loss: 0.8634 - val_accuracy: 0.9495\n",
      "Epoch 35/300\n",
      "177/177 [==============================] - 2s 9ms/step - loss: 3.1723e-05 - accuracy: 1.0000 - val_loss: 0.8653 - val_accuracy: 0.9495\n",
      "Epoch 00035: early stopping\n",
      "\n",
      "Time taken for training:  00:08:03\n",
      "\n",
      "\n",
      "Fold 1 - Train Accuracy 0.9987 - Test Accuracy 0.9864\n",
      "Fold 2 - Train Accuracy 0.9975 - Test Accuracy 0.9909\n",
      "Fold 3 - Train Accuracy 0.9953 - Test Accuracy 0.9848\n",
      "Fold 4 - Train Accuracy 0.9978 - Test Accuracy 0.9939\n",
      "Fold 5 - Train Accuracy 0.9973 - Test Accuracy 0.9879\n",
      "Fold 6 - Train Accuracy 0.9983 - Test Accuracy 0.9985\n",
      "Fold 7 - Train Accuracy 0.9970 - Test Accuracy 0.9864\n",
      "Fold 8 - Train Accuracy 0.9973 - Test Accuracy 0.9924\n",
      "Fold 9 - Train Accuracy 0.9965 - Test Accuracy 0.9879\n",
      "Fold 10 - Train Accuracy 0.9975 - Test Accuracy 0.9864\n",
      "\n",
      "Mean Train Accuracy: 0.9973 - Std: 0.0009 \n",
      "Mean Test Accuracy: 0.9895 - Std: 0.0041 \n",
      "\n",
      "Evaluate other metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       600\n",
      "           1       0.99      1.00      0.99       600\n",
      "           2       1.00      1.00      1.00       600\n",
      "           3       0.99      1.00      0.99       600\n",
      "           4       0.99      0.99      0.99       600\n",
      "           5       0.99      1.00      1.00       600\n",
      "           6       0.98      1.00      0.99       600\n",
      "           7       0.99      0.99      0.99       600\n",
      "           8       0.99      0.99      0.99       600\n",
      "           9       0.99      1.00      0.99       600\n",
      "          10       1.00      0.93      0.96       600\n",
      "\n",
      "    accuracy                           0.99      6600\n",
      "   macro avg       0.99      0.99      0.99      6600\n",
      "weighted avg       0.99      0.99      0.99      6600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "number_of_features = 32\n",
    "\n",
    "def create_v2():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters = 64, kernel_size = 3, activation = \"relu\", input_shape = (128, number_of_features)))\n",
    "    model.add(Conv1D(filters = 32, kernel_size = 3, activation = \"relu\"))\n",
    "    model.add(Conv1D(filters = 16, kernel_size = 3, activation = \"relu\"))\n",
    "    model.add(MaxPooling1D(pool_size = 2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(32, activation = \"relu\"))\n",
    "    model.add(Dense(11, activation = 'softmax'))\n",
    "    model.summary()\n",
    "    model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "# Data augmentation (6x).\n",
    "print(\"\\nStarting data augmentation.\")\n",
    "X_all_oversampled = []\n",
    "y_all_oversampled = []\n",
    "for count in range(0, 11):\n",
    "    X_oversampled, y_oversampled = resample(X_resampled[y_resampled == count],\n",
    "                                            y_resampled[y_resampled == count],\n",
    "                                            replace = True,\n",
    "                                            n_samples = 600,\n",
    "                                            random_state = 42)\n",
    "    X_all_oversampled.extend(X_oversampled)\n",
    "    y_all_oversampled.extend(y_oversampled)\n",
    "X_resampled_arr = np.array(X_all_oversampled)\n",
    "y_resampled_arr = np.array(y_all_oversampled)\n",
    "print(\"\\nQuantity of samples generated by oversampling => \", len(y_resampled_arr))\n",
    "\n",
    "\n",
    "# Defining the number of folds (10 k-Fold).\n",
    "skf = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "\n",
    "# Normalize data.\n",
    "scaler = RobustScaler()\n",
    "scaled_X = scaler.fit_transform(X_resampled_arr)\n",
    "\n",
    "# Reshape the structure data to be compatible with pattern [samples, timesteps, features].\n",
    "X_train_reshaped = scaled_X.reshape((scaled_X.shape[0], 128, number_of_features))\n",
    "\n",
    "\n",
    "# Train the CNN model and evaluate it.\n",
    "start_time = time.time()\n",
    "print(\"\\nStarting training at: \", time.strftime(\"%H:%M:%S\", time.localtime()))\n",
    "es = EarlyStopping(monitor = \"val_loss\", mode = \"min\", verbose = 1, patience = 30)\n",
    "\n",
    "train_accuracy_by_fold = []\n",
    "test_accuracy_by_fold = []\n",
    "history_by_fold = []\n",
    "y_predclass_for_report = []\n",
    "y_testclass_for_report = []\n",
    "predictedclass = []\n",
    "fold_number = 1\n",
    "for train_index, test_index in skf.split(X_train_reshaped, y_resampled_arr):\n",
    "    print(\"\\nTrainning fold {}\".format(fold_number))\n",
    "    model = create_v2()\n",
    "    history = model.fit(X_train_reshaped[train_index], y_resampled_arr[train_index], validation_split = 0.05,\n",
    "                            epochs = 300, batch_size = 32, verbose = 1, callbacks = [es])\n",
    "    _, train_accuracy = model.evaluate(X_train_reshaped[train_index], y_resampled_arr[train_index], verbose = 0)\n",
    "    _, test_accuracy = model.evaluate(X_train_reshaped[test_index], y_resampled_arr[test_index], verbose = 0)\n",
    "    train_accuracy_by_fold.append(train_accuracy)\n",
    "    test_accuracy_by_fold.append(test_accuracy)\n",
    "    history_by_fold.append(history)\n",
    "    y_predclass_for_report.extend(np.argmax(model.predict(X_train_reshaped[test_index]), axis = 1))\n",
    "    y_testclass_for_report.extend(y_resampled_arr[test_index])\n",
    "    fold_number += 1\n",
    "\n",
    "elapsed_seconds = time.time() - start_time\n",
    "print(\"\\nTime taken for training: \", time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_seconds)))\n",
    "print(\"\\n\")\n",
    "\n",
    "# Show metrics.\n",
    "for i in range(len(train_accuracy_by_fold)):\n",
    "    print(\"Fold {} - Train Accuracy {:.4f} - Test Accuracy {:.4f}\".format((i + 1),\n",
    "                            train_accuracy_by_fold[i], test_accuracy_by_fold[i]))\n",
    "print(\"\\nMean Train Accuracy: {:.4f} - Std: {:.4f} \".format(np.mean(train_accuracy_by_fold), np.std(train_accuracy_by_fold)))\n",
    "print(\"Mean Test Accuracy: {:.4f} - Std: {:.4f} \".format(np.mean(test_accuracy_by_fold), np.std(test_accuracy_by_fold)))\n",
    "\n",
    "print(\"\\nEvaluate other metrics:\")\n",
    "print(classification_report(y_testclass_for_report, y_predclass_for_report))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48119eaf",
   "metadata": {},
   "source": [
    "#### Show loss history by epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89a10b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Plot loss history\n",
    "for i in range(len(history_by_fold)):\n",
    "    plt.plot(history_by_fold[i].history[\"val_loss\"], label = \"Fold {}\".format(i + 1))\n",
    "plt.title(\"Validation Loss vs Number of epochs\", fontsize = 12)\n",
    "plt.xlabel(\"Epochs\", fontsize = 12)\n",
    "plt.ylabel(\"Loss\", fontsize = 12)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26847b22",
   "metadata": {},
   "source": [
    "#### Show accuracy history by epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a7e0aca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Plot accuracy history\n",
    "for i in range(len(history_by_fold)):\n",
    "    plt.plot(history_by_fold[i].history[\"val_accuracy\"], label = \"Fold {}\".format(i + 1))\n",
    "plt.title(\"Validation Accuracy vs Number of epochs\", fontsize = 12)\n",
    "plt.xlabel('Epochs', fontsize = 12)\n",
    "plt.ylabel('Accuracy', fontsize = 12)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1cb61e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
