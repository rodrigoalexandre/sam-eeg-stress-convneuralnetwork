{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdbe460f",
   "metadata": {},
   "source": [
    "#### Import libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "077b6c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Input\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras.optimizers import AdamW\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.utils import resample\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42175028",
   "metadata": {},
   "source": [
    "#### Load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b43ccbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv('../dataset/original-sam-dataset.csv', sep='|',\n",
    "                 dtype = {'recordNumber': 'int8',\n",
    "                          'CZ': 'float64', 'FZ': 'float64', 'Fp1': 'float64', 'F7': 'float64',\n",
    "                          'F3': 'float64', 'FC1': 'float64', 'C3': 'float64', 'FC5': 'float64', 'FT9': 'float64',\n",
    "                          'T7': 'float64', 'CP5': 'float64', 'CP1': 'float64', 'P3': 'float64', 'P7': 'float64',\n",
    "                          'PO9': 'float64', 'O1': 'float64', 'PZ': 'float64', 'OZ': 'float64', 'O2': 'float64',\n",
    "                          'PO10': 'float64', 'P8': 'float64', 'P4': 'float64', 'CP2': 'float64', 'CP6': 'float64',\n",
    "                          'T8': 'float64', 'FT10': 'float64', 'FC6': 'float64', 'C4': 'float64', 'FC2': 'float64',\n",
    "                          'F4': 'float64', 'F8': 'float64', 'Fp2': 'float64', \n",
    "                          'Scale': 'int8'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d03541",
   "metadata": {},
   "source": [
    "#### Display the dataset size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d243cc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1536000, 34)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3579e10b",
   "metadata": {},
   "source": [
    "#### Build a helper function to convert the set data to the required format to perform the undersampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "859f6e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_time_window_structure(df):\n",
    "    # Splits the dataset into \"time windows\" to be used as a time series list.\n",
    "    # The function groups each 3200 dataset records (CSV lines) into one record.\n",
    "    # Each record contains 3200 steps and each step contains 32 feature values.\n",
    "    # Parameters:\n",
    "    #    df: Dataframe to be splitted.\n",
    "    # Return:\n",
    "    #    X_array (list): First list contains all time windows.\n",
    "    #    y_array (list): Second list contains all target values.\n",
    "    print(\"\\nStarting build_time_window_structure function...\")\n",
    "    steps_number = 128 * 25\n",
    "    first_feat_index = 1\n",
    "    last_feat_index = 33\n",
    "    df_values = df.iloc[:, first_feat_index:last_feat_index].values\n",
    "    scale_values = df[\"Scale\"].values\n",
    "    num_segments = len(scale_values) // steps_number  \n",
    "    X_array = np.empty((num_segments, steps_number * (last_feat_index - first_feat_index)), dtype = df_values.dtype)\n",
    "    y_array = np.empty(num_segments, dtype = scale_values.dtype)\n",
    "    for i in range(num_segments):\n",
    "        start_idx = i * steps_number\n",
    "        end_idx = start_idx + steps_number\n",
    "        sub_matrix_values = df_values[start_idx:end_idx].flatten()\n",
    "        X_array[i] = sub_matrix_values\n",
    "        y_array[i] = scale_values[start_idx]\n",
    "    X_array = X_array.tolist()\n",
    "    y_array = y_array.tolist()\n",
    "    print(\"Quantity of samples (features) => \", len(X_array))\n",
    "    print(\"Quantity os samples (labels) => \", len(y_array))\n",
    "    print(\"Finishing build_time_window_structure function.\")\n",
    "    return X_array, y_array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09daa21c",
   "metadata": {},
   "source": [
    "#### Define a function to performe SMOTE to balance the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd2e2c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def apply_smote_resample(X_array, y_array, quantity_of_resample = 0):\n",
    "    # Apply SMOTE to balance the dataset and resample for data augmentation.\n",
    "    # Parameters:\n",
    "    #    X_array (np.array): array of features values.\n",
    "    #    y_array (np.array): array of target values.\n",
    "    #    quantity_of_resample (int): number of samples generated by resample.\n",
    "    # Return:\n",
    "    #    X_oversampled (np.array): array of features values.\n",
    "    #    y_oversampled (np.array): array of target values.\n",
    "    print(\"\\nGenerating upsampling and SMOTE...\")\n",
    "    X_oversampled, y_oversampled = resample(X_array,\n",
    "                                            y_array,\n",
    "                                            replace = True,\n",
    "                                            n_samples = quantity_of_resample,\n",
    "                                            stratify = y_array,\n",
    "                                            random_state = 42)\n",
    "    smote = SMOTE(sampling_strategy = \"auto\", k_neighbors = 5, random_state = 42)\n",
    "    X_array_res, y_array_res = smote.fit_resample(X_oversampled, y_oversampled)\n",
    "    print(\"{} samples after upsampling.\".format(len(y_array_res)))\n",
    "    print(f\"Class distribution for training after upsampling: {Counter(y_array_res)}\")\n",
    "    print(\"Finishing upsampling.\\n\")\n",
    "    return X_array_res, y_array_res\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020af4fd",
   "metadata": {},
   "source": [
    "#### Define a function to train a CNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b7ce9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "number_of_steps = 128 * 25\n",
    "number_of_features = 32\n",
    "\n",
    "# Define the number of folds (10 k-Fold).\n",
    "skf = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "# Normalize data using RobustScaler.\n",
    "pt = RobustScaler()\n",
    "\n",
    "es = EarlyStopping(monitor = \"val_loss\", mode = \"min\", verbose = 1, patience = 30, restore_best_weights = True)\n",
    "\n",
    "def train_cnn_model(cnn_model, X_arr, y_arr, quantity_of_resample = 0):\n",
    "    # Train a CNN model.\n",
    "    # Parameters:\n",
    "    #    cnn_model (Sequential): model to be trained.\n",
    "    #    X_arr (np.array): array of features values.\n",
    "    #    y_arr (np.array): array of target values.\n",
    "    #    quantity_of_resample (int): number of samples generated by resample.\n",
    "    # Returns:\n",
    "    #    history (History object): history of training metrics.\n",
    "    train_accuracy_by_fold = []\n",
    "    test_accuracy_by_fold = []\n",
    "    history_by_fold = []\n",
    "    y_predclass_for_report = []\n",
    "    y_testclass_for_report = []\n",
    "    fold_number = 1\n",
    "    start_time = time.time()\n",
    "    print(\"\\nStarting training...\")\n",
    "    for train_index, test_index in skf.split(X_arr, y_arr):\n",
    "        print(\"\\nTraining fold {}\".format(fold_number))\n",
    "        X_oversampled, y_oversampled = apply_smote_resample(X_arr[train_index],\n",
    "                                                            y_arr[train_index],\n",
    "                                                            quantity_of_resample)\n",
    "        X_train_scaled = pt.fit_transform(X_oversampled)\n",
    "        X_test_scaled = pt.transform(X_arr[test_index])\n",
    "        # Reshape the structure data to be compatible with pattern [samples, timesteps, features].\n",
    "        X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], number_of_steps, number_of_features))\n",
    "        X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], number_of_steps, number_of_features))\n",
    "        history = cnn_model.fit(X_train_reshaped, y_oversampled, validation_split = 0.01,\n",
    "                                epochs = 300, batch_size = 32, verbose = 1, callbacks = [es])\n",
    "        _, train_accuracy = cnn_model.evaluate(X_train_reshaped, y_oversampled, verbose = 0)\n",
    "        _, test_accuracy = cnn_model.evaluate(X_test_reshaped, y_arr[test_index], verbose = 0)\n",
    "        train_accuracy_by_fold.append(train_accuracy)\n",
    "        test_accuracy_by_fold.append(test_accuracy)\n",
    "        history_by_fold.append(history)\n",
    "        y_predclass_for_report.extend(np.argmax(cnn_model.predict(X_test_reshaped), axis = 1))\n",
    "        y_testclass_for_report.extend(y_arr[test_index])\n",
    "        fold_number += 1\n",
    "    elapsed_seconds = time.time() - start_time\n",
    "    print(\"\\nTime taken for training: \", time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_seconds)))\n",
    "    print(\"\\n\")\n",
    "    # Show metrics.\n",
    "    for i in range(len(history_by_fold)):\n",
    "        print(\"Fold {} - Train Accuracy {:.4f} - Test Accuracy {:.4f}\".format((i + 1),\n",
    "              train_accuracy_by_fold[i], test_accuracy_by_fold[i]))\n",
    "    print(\"\\nMean Train Accuracy: {:.4f} \".format(np.mean(train_accuracy_by_fold)))\n",
    "    print(\"Mean Test Accuracy: {:.4f} \".format(np.mean(test_accuracy_by_fold)))\n",
    "    print(\"\\nEvaluate other metrics:\")\n",
    "    print(classification_report(y_testclass_for_report, y_predclass_for_report, zero_division = 0))\n",
    "    return history_by_fold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258715ac",
   "metadata": {},
   "source": [
    "#### Train a Convolutional Neural Network model and evaluate the metrics.\n",
    "- Layer architecture => Conv1D (64) + Conv1D (32) + Conv1D (16) + MaxPooling1D + Dense (32) + Dense (11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e887613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting build_time_window_structure function...\n",
      "Quantity of samples (features) =>  480\n",
      "Quantity os samples (labels) =>  480\n",
      "Finishing build_time_window_structure function.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3198</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3196</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,176</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3194</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,552</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1597</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25552</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">817,696</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">363</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_9 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3198\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │         \u001b[38;5;34m6,208\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_10 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3196\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │         \u001b[38;5;34m6,176\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_11 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3194\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │         \u001b[38;5;34m1,552\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_3 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1597\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_3 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25552\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │       \u001b[38;5;34m817,696\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m)             │           \u001b[38;5;34m363\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">831,995</span> (3.17 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m831,995\u001b[0m (3.17 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">831,995</span> (3.17 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m831,995\u001b[0m (3.17 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training...\n",
      "\n",
      "Training fold 1\n",
      "\n",
      "Generating upsampling and SMOTE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\DeveloperTools\\python\\3.11.0\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2640 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({np.int64(3): 240, np.int64(4): 240, np.int64(0): 240, np.int64(6): 240, np.int64(7): 240, np.int64(9): 240, np.int64(5): 240, np.int64(1): 240, np.int64(2): 240, np.int64(8): 240, np.int64(10): 240})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 73ms/step - accuracy: 0.3683 - loss: 1.8793 - val_accuracy: 1.0000 - val_loss: 5.5764e-05\n",
      "Epoch 2/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 64ms/step - accuracy: 0.8487 - loss: 0.4918 - val_accuracy: 1.0000 - val_loss: 4.3783e-04\n",
      "Epoch 3/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 78ms/step - accuracy: 0.9201 - loss: 0.1924 - val_accuracy: 1.0000 - val_loss: 7.5878e-05\n",
      "Epoch 4/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 72ms/step - accuracy: 0.9945 - loss: 0.0190 - val_accuracy: 1.0000 - val_loss: 7.7281e-04\n",
      "Epoch 5/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 9.3246e-04 - val_accuracy: 1.0000 - val_loss: 2.3777e-04\n",
      "Epoch 6/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 3.1127e-04 - val_accuracy: 1.0000 - val_loss: 1.1902e-04\n",
      "Epoch 7/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 2.2231e-04 - val_accuracy: 1.0000 - val_loss: 7.2873e-05\n",
      "Epoch 8/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 1.6080e-04 - val_accuracy: 1.0000 - val_loss: 5.1046e-05\n",
      "Epoch 9/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 1.1415e-04 - val_accuracy: 1.0000 - val_loss: 3.6031e-05\n",
      "Epoch 10/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 9.3304e-05 - val_accuracy: 1.0000 - val_loss: 2.8429e-05\n",
      "Epoch 11/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 8.2600e-05 - val_accuracy: 1.0000 - val_loss: 2.2195e-05\n",
      "Epoch 12/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 6.5842e-05 - val_accuracy: 1.0000 - val_loss: 1.8389e-05\n",
      "Epoch 13/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 6.3714e-05 - val_accuracy: 1.0000 - val_loss: 1.5581e-05\n",
      "Epoch 14/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 5.2184e-05 - val_accuracy: 1.0000 - val_loss: 1.3051e-05\n",
      "Epoch 15/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 4.2619e-05 - val_accuracy: 1.0000 - val_loss: 1.1139e-05\n",
      "Epoch 16/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 4.1930e-05 - val_accuracy: 1.0000 - val_loss: 9.5543e-06\n",
      "Epoch 17/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 3.6536e-05 - val_accuracy: 1.0000 - val_loss: 8.3888e-06\n",
      "Epoch 18/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 3.4500e-05 - val_accuracy: 1.0000 - val_loss: 7.3070e-06\n",
      "Epoch 19/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 3.1805e-05 - val_accuracy: 1.0000 - val_loss: 6.3269e-06\n",
      "Epoch 20/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 2.4114e-05 - val_accuracy: 1.0000 - val_loss: 5.7044e-06\n",
      "Epoch 21/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 2.3785e-05 - val_accuracy: 1.0000 - val_loss: 5.0333e-06\n",
      "Epoch 22/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 2.2990e-05 - val_accuracy: 1.0000 - val_loss: 4.5520e-06\n",
      "Epoch 23/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 1.9515e-05 - val_accuracy: 1.0000 - val_loss: 4.1017e-06\n",
      "Epoch 24/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 1.8563e-05 - val_accuracy: 1.0000 - val_loss: 3.6690e-06\n",
      "Epoch 25/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 1.6964e-05 - val_accuracy: 1.0000 - val_loss: 3.3246e-06\n",
      "Epoch 26/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 1.5775e-05 - val_accuracy: 1.0000 - val_loss: 3.0067e-06\n",
      "Epoch 27/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 1.4660e-05 - val_accuracy: 1.0000 - val_loss: 2.7374e-06\n",
      "Epoch 28/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 1.2770e-05 - val_accuracy: 1.0000 - val_loss: 2.5343e-06\n",
      "Epoch 29/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 1.3062e-05 - val_accuracy: 1.0000 - val_loss: 2.2870e-06\n",
      "Epoch 30/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 1.1631e-05 - val_accuracy: 1.0000 - val_loss: 2.0972e-06\n",
      "Epoch 31/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 1.1229e-05 - val_accuracy: 1.0000 - val_loss: 1.9118e-06\n",
      "Epoch 32/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 1.1312e-05 - val_accuracy: 1.0000 - val_loss: 1.7705e-06\n",
      "Epoch 33/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 9.2200e-06 - val_accuracy: 1.0000 - val_loss: 1.6248e-06\n",
      "Epoch 34/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 8.8368e-06 - val_accuracy: 1.0000 - val_loss: 1.5321e-06\n",
      "Epoch 35/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 8.0848e-06 - val_accuracy: 1.0000 - val_loss: 1.3775e-06\n",
      "Epoch 36/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 7.6031e-06 - val_accuracy: 1.0000 - val_loss: 1.3113e-06\n",
      "Epoch 37/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 7.3460e-06 - val_accuracy: 1.0000 - val_loss: 1.2098e-06\n",
      "Epoch 38/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 6.2912e-06 - val_accuracy: 1.0000 - val_loss: 1.1479e-06\n",
      "Epoch 39/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 6.6495e-06 - val_accuracy: 1.0000 - val_loss: 1.0552e-06\n",
      "Epoch 40/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 6.1167e-06 - val_accuracy: 1.0000 - val_loss: 9.7133e-07\n",
      "Epoch 41/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 5.7108e-06 - val_accuracy: 1.0000 - val_loss: 9.2277e-07\n",
      "Epoch 42/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 5.3208e-06 - val_accuracy: 1.0000 - val_loss: 8.5213e-07\n",
      "Epoch 43/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 5.1063e-06 - val_accuracy: 1.0000 - val_loss: 7.9473e-07\n",
      "Epoch 44/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 4.6041e-06 - val_accuracy: 1.0000 - val_loss: 7.5941e-07\n",
      "Epoch 45/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 4.6766e-06 - val_accuracy: 1.0000 - val_loss: 6.9759e-07\n",
      "Epoch 46/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 4.1934e-06 - val_accuracy: 1.0000 - val_loss: 6.6669e-07\n",
      "Epoch 47/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 3.9935e-06 - val_accuracy: 1.0000 - val_loss: 6.0046e-07\n",
      "Epoch 48/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 74ms/step - accuracy: 1.0000 - loss: 4.5970e-06 - val_accuracy: 1.0000 - val_loss: 5.6956e-07\n",
      "Epoch 49/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 3.7024e-06 - val_accuracy: 1.0000 - val_loss: 5.4748e-07\n",
      "Epoch 50/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 3.5741e-06 - val_accuracy: 1.0000 - val_loss: 4.9450e-07\n",
      "Epoch 51/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 3.2873e-06 - val_accuracy: 1.0000 - val_loss: 4.7242e-07\n",
      "Epoch 52/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 3.1588e-06 - val_accuracy: 1.0000 - val_loss: 4.6359e-07\n",
      "Epoch 53/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 2.9901e-06 - val_accuracy: 1.0000 - val_loss: 4.4593e-07\n",
      "Epoch 54/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 2.9906e-06 - val_accuracy: 1.0000 - val_loss: 4.2386e-07\n",
      "Epoch 55/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 2.5901e-06 - val_accuracy: 1.0000 - val_loss: 3.5763e-07\n",
      "Epoch 56/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 2.7510e-06 - val_accuracy: 1.0000 - val_loss: 3.4438e-07\n",
      "Epoch 57/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 2.3316e-06 - val_accuracy: 1.0000 - val_loss: 3.2672e-07\n",
      "Epoch 58/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 2.4177e-06 - val_accuracy: 1.0000 - val_loss: 3.0906e-07\n",
      "Epoch 59/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 2.2813e-06 - val_accuracy: 1.0000 - val_loss: 3.0023e-07\n",
      "Epoch 60/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 2.1835e-06 - val_accuracy: 1.0000 - val_loss: 2.9140e-07\n",
      "Epoch 61/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 2.0086e-06 - val_accuracy: 1.0000 - val_loss: 2.5166e-07\n",
      "Epoch 62/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 1.8479e-06 - val_accuracy: 1.0000 - val_loss: 2.4283e-07\n",
      "Epoch 63/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 1.9989e-06 - val_accuracy: 1.0000 - val_loss: 2.3400e-07\n",
      "Epoch 64/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 1.6324e-06 - val_accuracy: 1.0000 - val_loss: 2.2517e-07\n",
      "Epoch 65/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 1.6447e-06 - val_accuracy: 1.0000 - val_loss: 2.1634e-07\n",
      "Epoch 66/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 1.6055e-06 - val_accuracy: 1.0000 - val_loss: 2.0751e-07\n",
      "Epoch 67/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 1.4430e-06 - val_accuracy: 1.0000 - val_loss: 2.0310e-07\n",
      "Epoch 68/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 1.3813e-06 - val_accuracy: 1.0000 - val_loss: 1.9868e-07\n",
      "Epoch 69/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 1.3001e-06 - val_accuracy: 1.0000 - val_loss: 1.8102e-07\n",
      "Epoch 70/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 1.2870e-06 - val_accuracy: 1.0000 - val_loss: 1.3687e-07\n",
      "Epoch 71/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 1.1889e-06 - val_accuracy: 1.0000 - val_loss: 1.3687e-07\n",
      "Epoch 72/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 1.1719e-06 - val_accuracy: 1.0000 - val_loss: 1.2804e-07\n",
      "Epoch 73/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 1.1741e-06 - val_accuracy: 1.0000 - val_loss: 1.2804e-07\n",
      "Epoch 74/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 1.1033e-06 - val_accuracy: 1.0000 - val_loss: 1.2804e-07\n",
      "Epoch 75/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 1.1222e-06 - val_accuracy: 1.0000 - val_loss: 1.1479e-07\n",
      "Epoch 76/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 8.9810e-07 - val_accuracy: 1.0000 - val_loss: 1.0596e-07\n",
      "Epoch 77/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 9.7669e-07 - val_accuracy: 1.0000 - val_loss: 1.0155e-07\n",
      "Epoch 78/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 8.7008e-07 - val_accuracy: 1.0000 - val_loss: 9.2718e-08\n",
      "Epoch 79/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 8.3808e-07 - val_accuracy: 1.0000 - val_loss: 9.2718e-08\n",
      "Epoch 80/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 7.4951e-07 - val_accuracy: 1.0000 - val_loss: 8.8303e-08\n",
      "Epoch 81/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 7.7017e-07 - val_accuracy: 1.0000 - val_loss: 8.8303e-08\n",
      "Epoch 82/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 7.6747e-07 - val_accuracy: 1.0000 - val_loss: 8.8303e-08\n",
      "Epoch 83/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 6.7394e-07 - val_accuracy: 1.0000 - val_loss: 8.8303e-08\n",
      "Epoch 84/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 6.6200e-07 - val_accuracy: 1.0000 - val_loss: 7.9473e-08\n",
      "Epoch 85/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 6.5837e-07 - val_accuracy: 1.0000 - val_loss: 7.5058e-08\n",
      "Epoch 86/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 5.6662e-07 - val_accuracy: 1.0000 - val_loss: 7.5058e-08\n",
      "Epoch 87/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 6.1510e-07 - val_accuracy: 1.0000 - val_loss: 7.0643e-08\n",
      "Epoch 88/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 6.1306e-07 - val_accuracy: 1.0000 - val_loss: 6.6227e-08\n",
      "Epoch 89/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 74ms/step - accuracy: 1.0000 - loss: 5.1877e-07 - val_accuracy: 1.0000 - val_loss: 6.6227e-08\n",
      "Epoch 90/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 5.2343e-07 - val_accuracy: 1.0000 - val_loss: 3.5321e-08\n",
      "Epoch 91/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 4.9375e-07 - val_accuracy: 1.0000 - val_loss: 6.6227e-08\n",
      "Epoch 92/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 4.6464e-07 - val_accuracy: 1.0000 - val_loss: 3.0906e-08\n",
      "Epoch 93/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 4.6381e-07 - val_accuracy: 1.0000 - val_loss: 2.6491e-08\n",
      "Epoch 94/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 4.0275e-07 - val_accuracy: 1.0000 - val_loss: 2.2076e-08\n",
      "Epoch 95/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 3.7796e-07 - val_accuracy: 1.0000 - val_loss: 1.7661e-08\n",
      "Epoch 96/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 3.8427e-07 - val_accuracy: 1.0000 - val_loss: 1.7661e-08\n",
      "Epoch 97/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 75ms/step - accuracy: 1.0000 - loss: 3.5302e-07 - val_accuracy: 1.0000 - val_loss: 8.8303e-09\n",
      "Epoch 98/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 3.6137e-07 - val_accuracy: 1.0000 - val_loss: 8.8303e-09\n",
      "Epoch 99/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 3.3739e-07 - val_accuracy: 1.0000 - val_loss: 8.8303e-09\n",
      "Epoch 100/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 3.0955e-07 - val_accuracy: 1.0000 - val_loss: 8.8303e-09\n",
      "Epoch 101/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 1.0000 - loss: 3.2283e-07 - val_accuracy: 1.0000 - val_loss: 8.8303e-09\n",
      "Epoch 102/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 75ms/step - accuracy: 1.0000 - loss: 2.9130e-07 - val_accuracy: 1.0000 - val_loss: 3.9736e-08\n",
      "Epoch 103/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 2.6861e-07 - val_accuracy: 1.0000 - val_loss: 3.9736e-08\n",
      "Epoch 104/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 2.7889e-07 - val_accuracy: 1.0000 - val_loss: 8.8303e-09\n",
      "Epoch 105/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 75ms/step - accuracy: 1.0000 - loss: 2.6994e-07 - val_accuracy: 1.0000 - val_loss: 8.8303e-09\n",
      "Epoch 106/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 2.5465e-07 - val_accuracy: 1.0000 - val_loss: 8.8303e-09\n",
      "Epoch 107/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 74ms/step - accuracy: 1.0000 - loss: 2.5119e-07 - val_accuracy: 1.0000 - val_loss: 8.8303e-09\n",
      "Epoch 108/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 75ms/step - accuracy: 1.0000 - loss: 2.0888e-07 - val_accuracy: 1.0000 - val_loss: 3.9736e-08\n",
      "Epoch 109/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 2.0183e-07 - val_accuracy: 1.0000 - val_loss: 3.9736e-08\n",
      "Epoch 110/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 2.1563e-07 - val_accuracy: 1.0000 - val_loss: 8.8303e-09\n",
      "Epoch 111/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 75ms/step - accuracy: 1.0000 - loss: 2.0999e-07 - val_accuracy: 1.0000 - val_loss: 8.8303e-09\n",
      "Epoch 112/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 1.0000 - loss: 1.8698e-07 - val_accuracy: 1.0000 - val_loss: 3.9736e-08\n",
      "Epoch 113/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 79ms/step - accuracy: 1.0000 - loss: 1.6697e-07 - val_accuracy: 1.0000 - val_loss: 3.9736e-08\n",
      "Epoch 114/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 1.0000 - loss: 1.7559e-07 - val_accuracy: 1.0000 - val_loss: 8.8303e-09\n",
      "Epoch 115/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 1.5981e-07 - val_accuracy: 1.0000 - val_loss: 3.9736e-08\n",
      "Epoch 116/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 1.0000 - loss: 1.5243e-07 - val_accuracy: 1.0000 - val_loss: 8.8303e-09\n",
      "Epoch 117/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 1.4701e-07 - val_accuracy: 1.0000 - val_loss: 8.8303e-09\n",
      "Epoch 118/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 78ms/step - accuracy: 1.0000 - loss: 1.4644e-07 - val_accuracy: 1.0000 - val_loss: 3.9736e-08\n",
      "Epoch 119/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 1.0000 - loss: 1.3350e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 120/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 1.0000 - loss: 1.4032e-07 - val_accuracy: 1.0000 - val_loss: 3.9736e-08\n",
      "Epoch 121/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 79ms/step - accuracy: 1.0000 - loss: 1.1582e-07 - val_accuracy: 1.0000 - val_loss: 3.9736e-08\n",
      "Epoch 122/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 1.0000 - loss: 1.0838e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 123/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 1.1913e-07 - val_accuracy: 1.0000 - val_loss: 3.9736e-08\n",
      "Epoch 124/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 1.0292e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 125/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 1.0000 - loss: 9.2806e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 126/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 1.0000 - loss: 9.0262e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-08\n",
      "Epoch 127/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 1.0000 - loss: 9.4865e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 128/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 8.2959e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 129/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 74ms/step - accuracy: 1.0000 - loss: 7.7851e-08 - val_accuracy: 1.0000 - val_loss: 8.8303e-09\n",
      "Epoch 130/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 101ms/step - accuracy: 1.0000 - loss: 7.9024e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 131/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 1.0000 - loss: 6.8689e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 132/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 89ms/step - accuracy: 1.0000 - loss: 6.8143e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 133/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 88ms/step - accuracy: 1.0000 - loss: 6.9782e-08 - val_accuracy: 1.0000 - val_loss: 3.0906e-08\n",
      "Epoch 134/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 6.7910e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 135/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 91ms/step - accuracy: 1.0000 - loss: 6.0000e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 136/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - accuracy: 1.0000 - loss: 5.4755e-08 - val_accuracy: 1.0000 - val_loss: 8.8303e-09\n",
      "Epoch 137/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 1.0000 - loss: 5.4392e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 138/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 1.0000 - loss: 5.1220e-08 - val_accuracy: 1.0000 - val_loss: 8.8303e-09\n",
      "Epoch 139/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 79ms/step - accuracy: 1.0000 - loss: 4.5795e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 140/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 88ms/step - accuracy: 1.0000 - loss: 4.6146e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 141/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 1.0000 - loss: 4.9588e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 142/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 4.4612e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-08\n",
      "Epoch 143/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 99ms/step - accuracy: 1.0000 - loss: 4.1242e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 144/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 93ms/step - accuracy: 1.0000 - loss: 3.3248e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 145/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 1.0000 - loss: 3.5708e-08 - val_accuracy: 1.0000 - val_loss: 3.0906e-08\n",
      "Epoch 146/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 1.0000 - loss: 3.6824e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 147/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 1.0000 - loss: 3.2157e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 148/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 89ms/step - accuracy: 1.0000 - loss: 2.7963e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 149/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 1.0000 - loss: 2.9871e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 149: early stopping\n",
      "Restoring model weights from the end of the best epoch: 119.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step\n",
      "\n",
      "Training fold 2\n",
      "\n",
      "Generating upsampling and SMOTE...\n",
      "2640 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({np.int64(2): 240, np.int64(3): 240, np.int64(6): 240, np.int64(5): 240, np.int64(1): 240, np.int64(0): 240, np.int64(7): 240, np.int64(4): 240, np.int64(10): 240, np.int64(8): 240, np.int64(9): 240})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 106ms/step - accuracy: 0.1800 - loss: 5.4386 - val_accuracy: 0.0000e+00 - val_loss: 2.4929\n",
      "Epoch 2/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 91ms/step - accuracy: 0.0953 - loss: 2.3978 - val_accuracy: 0.0000e+00 - val_loss: 2.4996\n",
      "Epoch 3/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.0829 - loss: 2.3981 - val_accuracy: 0.0000e+00 - val_loss: 2.5046\n",
      "Epoch 4/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.0834 - loss: 2.3992 - val_accuracy: 0.0000e+00 - val_loss: 2.4993\n",
      "Epoch 5/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.0894 - loss: 2.3974 - val_accuracy: 0.0000e+00 - val_loss: 2.5032\n",
      "Epoch 6/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.0887 - loss: 2.3980 - val_accuracy: 0.0000e+00 - val_loss: 2.4982\n",
      "Epoch 7/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.0981 - loss: 2.3957 - val_accuracy: 0.0000e+00 - val_loss: 2.5034\n",
      "Epoch 8/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.0830 - loss: 2.3972 - val_accuracy: 0.0000e+00 - val_loss: 2.5054\n",
      "Epoch 9/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.0800 - loss: 2.3973 - val_accuracy: 0.0000e+00 - val_loss: 2.5044\n",
      "Epoch 10/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 88ms/step - accuracy: 0.0974 - loss: 2.3963 - val_accuracy: 0.0000e+00 - val_loss: 2.5041\n",
      "Epoch 11/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.0814 - loss: 2.3964 - val_accuracy: 0.0000e+00 - val_loss: 2.5053\n",
      "Epoch 12/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.0858 - loss: 2.3979 - val_accuracy: 0.0000e+00 - val_loss: 2.4997\n",
      "Epoch 13/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.0948 - loss: 2.3975 - val_accuracy: 0.0000e+00 - val_loss: 2.5076\n",
      "Epoch 14/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 99ms/step - accuracy: 0.1050 - loss: 2.3966 - val_accuracy: 0.0000e+00 - val_loss: 2.5058\n",
      "Epoch 15/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.0925 - loss: 2.3979 - val_accuracy: 0.0000e+00 - val_loss: 2.5041\n",
      "Epoch 16/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 67ms/step - accuracy: 0.0966 - loss: 2.3976 - val_accuracy: 0.0000e+00 - val_loss: 2.5063\n",
      "Epoch 17/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 70ms/step - accuracy: 0.0939 - loss: 2.3976 - val_accuracy: 0.0000e+00 - val_loss: 2.5081\n",
      "Epoch 18/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 69ms/step - accuracy: 0.0844 - loss: 2.3970 - val_accuracy: 0.0000e+00 - val_loss: 2.5095\n",
      "Epoch 19/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 66ms/step - accuracy: 0.0899 - loss: 2.3974 - val_accuracy: 0.0000e+00 - val_loss: 2.5052\n",
      "Epoch 20/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 68ms/step - accuracy: 0.0873 - loss: 2.3968 - val_accuracy: 0.0000e+00 - val_loss: 2.5066\n",
      "Epoch 21/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 67ms/step - accuracy: 0.0907 - loss: 2.3972 - val_accuracy: 0.0000e+00 - val_loss: 2.5064\n",
      "Epoch 22/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 70ms/step - accuracy: 0.0757 - loss: 2.3968 - val_accuracy: 0.0000e+00 - val_loss: 2.5120\n",
      "Epoch 23/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 71ms/step - accuracy: 0.1092 - loss: 2.3956 - val_accuracy: 0.0000e+00 - val_loss: 2.5058\n",
      "Epoch 24/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 71ms/step - accuracy: 0.0918 - loss: 2.3979 - val_accuracy: 0.0000e+00 - val_loss: 2.4993\n",
      "Epoch 25/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 69ms/step - accuracy: 0.0909 - loss: 2.3968 - val_accuracy: 0.0000e+00 - val_loss: 2.5035\n",
      "Epoch 26/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 71ms/step - accuracy: 0.0908 - loss: 2.3985 - val_accuracy: 0.0000e+00 - val_loss: 2.5054\n",
      "Epoch 27/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 72ms/step - accuracy: 0.0748 - loss: 2.3976 - val_accuracy: 0.0000e+00 - val_loss: 2.5043\n",
      "Epoch 28/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 68ms/step - accuracy: 0.0987 - loss: 2.3980 - val_accuracy: 0.0000e+00 - val_loss: 2.5042\n",
      "Epoch 29/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 69ms/step - accuracy: 0.0993 - loss: 2.3971 - val_accuracy: 0.0000e+00 - val_loss: 2.5108\n",
      "Epoch 30/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 68ms/step - accuracy: 0.0895 - loss: 2.3979 - val_accuracy: 0.0000e+00 - val_loss: 2.5105\n",
      "Epoch 31/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 73ms/step - accuracy: 0.0841 - loss: 2.3969 - val_accuracy: 0.0000e+00 - val_loss: 2.5058\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\n",
      "Training fold 3\n",
      "\n",
      "Generating upsampling and SMOTE...\n",
      "2640 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({np.int64(2): 240, np.int64(3): 240, np.int64(6): 240, np.int64(5): 240, np.int64(1): 240, np.int64(0): 240, np.int64(7): 240, np.int64(8): 240, np.int64(4): 240, np.int64(10): 240, np.int64(9): 240})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 89ms/step - accuracy: 0.0770 - loss: 2.4006 - val_accuracy: 0.0000e+00 - val_loss: 2.4972\n",
      "Epoch 2/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 75ms/step - accuracy: 0.0883 - loss: 2.3983 - val_accuracy: 0.0000e+00 - val_loss: 2.4971\n",
      "Epoch 3/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 73ms/step - accuracy: 0.0962 - loss: 2.3974 - val_accuracy: 0.0000e+00 - val_loss: 2.5057\n",
      "Epoch 4/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.0837 - loss: 2.3985 - val_accuracy: 0.0000e+00 - val_loss: 2.5015\n",
      "Epoch 5/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 73ms/step - accuracy: 0.0969 - loss: 2.3985 - val_accuracy: 0.0000e+00 - val_loss: 2.5092\n",
      "Epoch 6/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 74ms/step - accuracy: 0.0944 - loss: 2.3975 - val_accuracy: 0.0000e+00 - val_loss: 2.5119\n",
      "Epoch 7/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 72ms/step - accuracy: 0.0880 - loss: 2.3978 - val_accuracy: 0.0000e+00 - val_loss: 2.5035\n",
      "Epoch 8/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 77ms/step - accuracy: 0.0860 - loss: 2.3987 - val_accuracy: 0.0000e+00 - val_loss: 2.5092\n",
      "Epoch 9/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 79ms/step - accuracy: 0.0995 - loss: 2.3977 - val_accuracy: 0.0000e+00 - val_loss: 2.5042\n",
      "Epoch 10/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.0827 - loss: 2.3977 - val_accuracy: 0.0000e+00 - val_loss: 2.5034\n",
      "Epoch 11/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 77ms/step - accuracy: 0.0955 - loss: 2.3973 - val_accuracy: 0.0000e+00 - val_loss: 2.5091\n",
      "Epoch 12/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 77ms/step - accuracy: 0.0847 - loss: 2.3978 - val_accuracy: 0.0000e+00 - val_loss: 2.5085\n",
      "Epoch 13/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 76ms/step - accuracy: 0.0890 - loss: 2.3988 - val_accuracy: 0.0000e+00 - val_loss: 2.5031\n",
      "Epoch 14/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.0925 - loss: 2.3976 - val_accuracy: 0.0000e+00 - val_loss: 2.5089\n",
      "Epoch 15/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 76ms/step - accuracy: 0.1025 - loss: 2.3972 - val_accuracy: 0.0000e+00 - val_loss: 2.5069\n",
      "Epoch 16/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 76ms/step - accuracy: 0.0940 - loss: 2.3968 - val_accuracy: 0.0000e+00 - val_loss: 2.5076\n",
      "Epoch 17/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 76ms/step - accuracy: 0.0949 - loss: 2.3975 - val_accuracy: 0.0000e+00 - val_loss: 2.5096\n",
      "Epoch 18/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 75ms/step - accuracy: 0.0894 - loss: 2.3979 - val_accuracy: 0.0000e+00 - val_loss: 2.5051\n",
      "Epoch 19/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 74ms/step - accuracy: 0.0894 - loss: 2.3977 - val_accuracy: 0.0000e+00 - val_loss: 2.5001\n",
      "Epoch 20/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 76ms/step - accuracy: 0.0710 - loss: 2.3975 - val_accuracy: 0.0000e+00 - val_loss: 2.5079\n",
      "Epoch 21/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.0925 - loss: 2.3973 - val_accuracy: 0.0000e+00 - val_loss: 2.5044\n",
      "Epoch 22/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 77ms/step - accuracy: 0.0858 - loss: 2.3976 - val_accuracy: 0.0000e+00 - val_loss: 2.5053\n",
      "Epoch 23/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 76ms/step - accuracy: 0.0782 - loss: 2.3977 - val_accuracy: 0.0000e+00 - val_loss: 2.5068\n",
      "Epoch 24/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.1009 - loss: 2.3986 - val_accuracy: 0.0000e+00 - val_loss: 2.5025\n",
      "Epoch 25/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.0889 - loss: 2.3970 - val_accuracy: 0.0000e+00 - val_loss: 2.5096\n",
      "Epoch 26/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 79ms/step - accuracy: 0.0802 - loss: 2.3987 - val_accuracy: 0.0000e+00 - val_loss: 2.5051\n",
      "Epoch 27/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.0988 - loss: 2.3970 - val_accuracy: 0.0000e+00 - val_loss: 2.5077\n",
      "Epoch 28/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 77ms/step - accuracy: 0.0967 - loss: 2.3971 - val_accuracy: 0.0000e+00 - val_loss: 2.5051\n",
      "Epoch 29/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.0903 - loss: 2.3976 - val_accuracy: 0.0000e+00 - val_loss: 2.5079\n",
      "Epoch 30/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 75ms/step - accuracy: 0.1027 - loss: 2.3978 - val_accuracy: 0.0000e+00 - val_loss: 2.5038\n",
      "Epoch 31/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 76ms/step - accuracy: 0.0899 - loss: 2.3979 - val_accuracy: 0.0000e+00 - val_loss: 2.5119\n",
      "Epoch 32/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.0794 - loss: 2.3973 - val_accuracy: 0.0000e+00 - val_loss: 2.5096\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\n",
      "Training fold 4\n",
      "\n",
      "Generating upsampling and SMOTE...\n",
      "2640 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({np.int64(2): 240, np.int64(3): 240, np.int64(6): 240, np.int64(5): 240, np.int64(1): 240, np.int64(0): 240, np.int64(7): 240, np.int64(8): 240, np.int64(4): 240, np.int64(10): 240, np.int64(9): 240})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 101ms/step - accuracy: 0.0969 - loss: 2.3971 - val_accuracy: 0.0000e+00 - val_loss: 2.4956\n",
      "Epoch 2/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.0930 - loss: 2.3978 - val_accuracy: 0.0000e+00 - val_loss: 2.5009\n",
      "Epoch 3/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 88ms/step - accuracy: 0.1010 - loss: 2.3971 - val_accuracy: 0.0000e+00 - val_loss: 2.4970\n",
      "Epoch 4/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 78ms/step - accuracy: 0.0928 - loss: 2.3978 - val_accuracy: 0.0000e+00 - val_loss: 2.5047\n",
      "Epoch 5/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.0956 - loss: 2.3975 - val_accuracy: 0.0000e+00 - val_loss: 2.5024\n",
      "Epoch 6/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 78ms/step - accuracy: 0.0996 - loss: 2.3972 - val_accuracy: 0.0000e+00 - val_loss: 2.5029\n",
      "Epoch 7/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.0943 - loss: 2.3967 - val_accuracy: 0.0000e+00 - val_loss: 2.5027\n",
      "Epoch 8/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.0860 - loss: 2.3970 - val_accuracy: 0.0000e+00 - val_loss: 2.5060\n",
      "Epoch 9/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 81ms/step - accuracy: 0.0928 - loss: 2.3966 - val_accuracy: 0.0000e+00 - val_loss: 2.5062\n",
      "Epoch 10/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.0930 - loss: 2.3978 - val_accuracy: 0.0000e+00 - val_loss: 2.4980\n",
      "Epoch 11/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 96ms/step - accuracy: 0.0803 - loss: 2.3982 - val_accuracy: 0.0000e+00 - val_loss: 2.5023\n",
      "Epoch 12/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.0843 - loss: 2.3969 - val_accuracy: 0.0000e+00 - val_loss: 2.5084\n",
      "Epoch 13/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.0954 - loss: 2.3988 - val_accuracy: 0.0000e+00 - val_loss: 2.5013\n",
      "Epoch 14/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.0880 - loss: 2.3975 - val_accuracy: 0.0000e+00 - val_loss: 2.5059\n",
      "Epoch 15/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 78ms/step - accuracy: 0.0845 - loss: 2.3986 - val_accuracy: 0.0000e+00 - val_loss: 2.5003\n",
      "Epoch 16/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.0873 - loss: 2.3980 - val_accuracy: 0.0000e+00 - val_loss: 2.5080\n",
      "Epoch 17/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.0834 - loss: 2.3974 - val_accuracy: 0.0000e+00 - val_loss: 2.5047\n",
      "Epoch 18/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.0993 - loss: 2.3969 - val_accuracy: 0.0000e+00 - val_loss: 2.5055\n",
      "Epoch 19/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.0765 - loss: 2.3979 - val_accuracy: 0.0000e+00 - val_loss: 2.5043\n",
      "Epoch 20/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.0908 - loss: 2.3973 - val_accuracy: 0.0000e+00 - val_loss: 2.5057\n",
      "Epoch 21/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.0897 - loss: 2.3968 - val_accuracy: 0.0000e+00 - val_loss: 2.5103\n",
      "Epoch 22/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.0808 - loss: 2.3988 - val_accuracy: 0.0000e+00 - val_loss: 2.5000\n",
      "Epoch 23/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 77ms/step - accuracy: 0.0857 - loss: 2.3976 - val_accuracy: 0.0000e+00 - val_loss: 2.5061\n",
      "Epoch 24/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 78ms/step - accuracy: 0.0952 - loss: 2.3977 - val_accuracy: 0.0000e+00 - val_loss: 2.5067\n",
      "Epoch 25/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.0916 - loss: 2.3973 - val_accuracy: 0.0000e+00 - val_loss: 2.5090\n",
      "Epoch 26/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.0980 - loss: 2.3979 - val_accuracy: 0.0000e+00 - val_loss: 2.5077\n",
      "Epoch 27/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 78ms/step - accuracy: 0.0846 - loss: 2.3974 - val_accuracy: 0.0000e+00 - val_loss: 2.5092\n",
      "Epoch 28/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.0798 - loss: 2.3971 - val_accuracy: 0.0000e+00 - val_loss: 2.5096\n",
      "Epoch 29/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.1026 - loss: 2.3965 - val_accuracy: 0.0000e+00 - val_loss: 2.5057\n",
      "Epoch 30/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.0919 - loss: 2.3973 - val_accuracy: 0.0000e+00 - val_loss: 2.5019\n",
      "Epoch 31/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.0891 - loss: 2.3968 - val_accuracy: 0.0000e+00 - val_loss: 2.5059\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\n",
      "Training fold 5\n",
      "\n",
      "Generating upsampling and SMOTE...\n",
      "2640 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({np.int64(2): 240, np.int64(3): 240, np.int64(6): 240, np.int64(5): 240, np.int64(1): 240, np.int64(0): 240, np.int64(7): 240, np.int64(8): 240, np.int64(4): 240, np.int64(10): 240, np.int64(9): 240})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 108ms/step - accuracy: 0.0949 - loss: 2.3972 - val_accuracy: 0.0000e+00 - val_loss: 2.4985\n",
      "Epoch 2/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 97ms/step - accuracy: 0.0900 - loss: 2.3974 - val_accuracy: 0.0000e+00 - val_loss: 2.4984\n",
      "Epoch 3/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.0950 - loss: 2.3975 - val_accuracy: 0.0000e+00 - val_loss: 2.5022\n",
      "Epoch 4/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 107ms/step - accuracy: 0.0963 - loss: 2.3986 - val_accuracy: 0.0000e+00 - val_loss: 2.4976\n",
      "Epoch 5/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.0905 - loss: 2.3972 - val_accuracy: 0.0000e+00 - val_loss: 2.5018\n",
      "Epoch 6/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.0877 - loss: 2.3970 - val_accuracy: 0.0000e+00 - val_loss: 2.5013\n",
      "Epoch 7/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.0882 - loss: 2.3986 - val_accuracy: 0.0000e+00 - val_loss: 2.4988\n",
      "Epoch 8/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.0957 - loss: 2.3980 - val_accuracy: 0.0000e+00 - val_loss: 2.5013\n",
      "Epoch 9/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.0875 - loss: 2.3977 - val_accuracy: 0.0000e+00 - val_loss: 2.5074\n",
      "Epoch 10/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 79ms/step - accuracy: 0.0886 - loss: 2.3970 - val_accuracy: 0.0000e+00 - val_loss: 2.5060\n",
      "Epoch 11/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.0693 - loss: 2.3972 - val_accuracy: 0.0000e+00 - val_loss: 2.5068\n",
      "Epoch 12/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.0903 - loss: 2.3975 - val_accuracy: 0.0000e+00 - val_loss: 2.5082\n",
      "Epoch 13/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.0820 - loss: 2.3975 - val_accuracy: 0.0000e+00 - val_loss: 2.5065\n",
      "Epoch 14/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.0937 - loss: 2.3973 - val_accuracy: 0.0000e+00 - val_loss: 2.5038\n",
      "Epoch 15/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.0848 - loss: 2.3977 - val_accuracy: 0.0000e+00 - val_loss: 2.5052\n",
      "Epoch 16/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.0864 - loss: 2.3970 - val_accuracy: 0.0000e+00 - val_loss: 2.5059\n",
      "Epoch 17/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.0934 - loss: 2.3973 - val_accuracy: 0.0000e+00 - val_loss: 2.5056\n",
      "Epoch 18/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 68ms/step - accuracy: 0.0975 - loss: 2.3974 - val_accuracy: 0.0000e+00 - val_loss: 2.5057\n",
      "Epoch 19/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 67ms/step - accuracy: 0.0969 - loss: 2.3975 - val_accuracy: 0.0000e+00 - val_loss: 2.5053\n",
      "Epoch 20/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 68ms/step - accuracy: 0.1063 - loss: 2.3977 - val_accuracy: 0.0000e+00 - val_loss: 2.5101\n",
      "Epoch 21/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 69ms/step - accuracy: 0.0872 - loss: 2.3980 - val_accuracy: 0.0000e+00 - val_loss: 2.5086\n",
      "Epoch 22/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 68ms/step - accuracy: 0.0913 - loss: 2.3982 - val_accuracy: 0.0000e+00 - val_loss: 2.5046\n",
      "Epoch 23/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 74ms/step - accuracy: 0.0939 - loss: 2.3979 - val_accuracy: 0.0000e+00 - val_loss: 2.5072\n",
      "Epoch 24/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 69ms/step - accuracy: 0.0822 - loss: 2.3966 - val_accuracy: 0.0000e+00 - val_loss: 2.5101\n",
      "Epoch 25/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 71ms/step - accuracy: 0.0840 - loss: 2.3967 - val_accuracy: 0.0000e+00 - val_loss: 2.5020\n",
      "Epoch 26/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 69ms/step - accuracy: 0.0940 - loss: 2.3972 - val_accuracy: 0.0000e+00 - val_loss: 2.5061\n",
      "Epoch 27/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 67ms/step - accuracy: 0.0867 - loss: 2.3975 - val_accuracy: 0.0000e+00 - val_loss: 2.5011\n",
      "Epoch 28/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 69ms/step - accuracy: 0.0956 - loss: 2.3983 - val_accuracy: 0.0000e+00 - val_loss: 2.5034\n",
      "Epoch 29/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 69ms/step - accuracy: 0.0894 - loss: 2.3975 - val_accuracy: 0.0000e+00 - val_loss: 2.5074\n",
      "Epoch 30/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 69ms/step - accuracy: 0.0796 - loss: 2.3975 - val_accuracy: 0.0000e+00 - val_loss: 2.5054\n",
      "Epoch 31/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.0921 - loss: 2.3978 - val_accuracy: 0.0000e+00 - val_loss: 2.5081\n",
      "Epoch 32/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 77ms/step - accuracy: 0.0863 - loss: 2.3978 - val_accuracy: 0.0000e+00 - val_loss: 2.5093\n",
      "Epoch 33/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 71ms/step - accuracy: 0.0818 - loss: 2.3973 - val_accuracy: 0.0000e+00 - val_loss: 2.5056\n",
      "Epoch 34/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 75ms/step - accuracy: 0.1079 - loss: 2.3970 - val_accuracy: 0.0000e+00 - val_loss: 2.5051\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\n",
      "Training fold 6\n",
      "\n",
      "Generating upsampling and SMOTE...\n",
      "2640 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({np.int64(2): 240, np.int64(3): 240, np.int64(6): 240, np.int64(5): 240, np.int64(1): 240, np.int64(0): 240, np.int64(7): 240, np.int64(8): 240, np.int64(4): 240, np.int64(10): 240, np.int64(9): 240})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.0934 - loss: 2.3968 - val_accuracy: 0.0000e+00 - val_loss: 2.5029\n",
      "Epoch 2/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 74ms/step - accuracy: 0.0852 - loss: 2.3981 - val_accuracy: 0.0000e+00 - val_loss: 2.5048\n",
      "Epoch 3/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 94ms/step - accuracy: 0.0968 - loss: 2.3962 - val_accuracy: 0.0000e+00 - val_loss: 2.4991\n",
      "Epoch 4/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 78ms/step - accuracy: 0.0932 - loss: 2.3975 - val_accuracy: 0.0000e+00 - val_loss: 2.5031\n",
      "Epoch 5/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 75ms/step - accuracy: 0.0895 - loss: 2.3981 - val_accuracy: 0.0000e+00 - val_loss: 2.5045\n",
      "Epoch 6/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 73ms/step - accuracy: 0.0782 - loss: 2.3972 - val_accuracy: 0.0000e+00 - val_loss: 2.5077\n",
      "Epoch 7/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.0941 - loss: 2.3976 - val_accuracy: 0.0000e+00 - val_loss: 2.5045\n",
      "Epoch 8/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 78ms/step - accuracy: 0.1014 - loss: 2.3976 - val_accuracy: 0.0000e+00 - val_loss: 2.5052\n",
      "Epoch 9/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 75ms/step - accuracy: 0.0814 - loss: 2.3979 - val_accuracy: 0.0000e+00 - val_loss: 2.5051\n",
      "Epoch 10/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.0871 - loss: 2.3974 - val_accuracy: 0.0000e+00 - val_loss: 2.5086\n",
      "Epoch 11/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.0848 - loss: 2.3983 - val_accuracy: 0.0000e+00 - val_loss: 2.5063\n",
      "Epoch 12/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 90ms/step - accuracy: 0.0855 - loss: 2.3973 - val_accuracy: 0.0000e+00 - val_loss: 2.5033\n",
      "Epoch 13/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 88ms/step - accuracy: 0.1005 - loss: 2.3978 - val_accuracy: 0.0000e+00 - val_loss: 2.5065\n",
      "Epoch 14/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 91ms/step - accuracy: 0.0852 - loss: 2.3973 - val_accuracy: 0.0000e+00 - val_loss: 2.5040\n",
      "Epoch 15/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.0906 - loss: 2.3973 - val_accuracy: 0.0000e+00 - val_loss: 2.5045\n",
      "Epoch 16/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 76ms/step - accuracy: 0.1012 - loss: 2.3980 - val_accuracy: 0.0000e+00 - val_loss: 2.5012\n",
      "Epoch 17/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 77ms/step - accuracy: 0.0822 - loss: 2.3979 - val_accuracy: 0.0000e+00 - val_loss: 2.5074\n",
      "Epoch 18/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 75ms/step - accuracy: 0.0842 - loss: 2.3966 - val_accuracy: 0.0000e+00 - val_loss: 2.5094\n",
      "Epoch 19/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 74ms/step - accuracy: 0.0896 - loss: 2.3967 - val_accuracy: 0.0000e+00 - val_loss: 2.5059\n",
      "Epoch 20/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 75ms/step - accuracy: 0.0959 - loss: 2.3976 - val_accuracy: 0.0000e+00 - val_loss: 2.5065\n",
      "Epoch 21/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 76ms/step - accuracy: 0.0918 - loss: 2.3972 - val_accuracy: 0.0000e+00 - val_loss: 2.5067\n",
      "Epoch 22/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.0786 - loss: 2.3958 - val_accuracy: 0.0000e+00 - val_loss: 2.5040\n",
      "Epoch 23/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 78ms/step - accuracy: 0.0881 - loss: 2.3980 - val_accuracy: 0.0000e+00 - val_loss: 2.5070\n",
      "Epoch 24/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 77ms/step - accuracy: 0.0991 - loss: 2.3968 - val_accuracy: 0.0000e+00 - val_loss: 2.5070\n",
      "Epoch 25/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 76ms/step - accuracy: 0.0899 - loss: 2.3968 - val_accuracy: 0.0000e+00 - val_loss: 2.5041\n",
      "Epoch 26/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.0969 - loss: 2.3968 - val_accuracy: 0.0000e+00 - val_loss: 2.5062\n",
      "Epoch 27/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 78ms/step - accuracy: 0.0780 - loss: 2.3976 - val_accuracy: 0.0000e+00 - val_loss: 2.5029\n",
      "Epoch 28/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 77ms/step - accuracy: 0.0903 - loss: 2.3987 - val_accuracy: 0.0000e+00 - val_loss: 2.5036\n",
      "Epoch 29/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 75ms/step - accuracy: 0.0791 - loss: 2.3970 - val_accuracy: 0.0000e+00 - val_loss: 2.5080\n",
      "Epoch 30/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.0935 - loss: 2.3973 - val_accuracy: 0.0000e+00 - val_loss: 2.5047\n",
      "Epoch 31/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.0815 - loss: 2.3973 - val_accuracy: 0.0000e+00 - val_loss: 2.5047\n",
      "Epoch 32/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.0833 - loss: 2.3980 - val_accuracy: 0.0000e+00 - val_loss: 2.5075\n",
      "Epoch 33/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.0800 - loss: 2.3969 - val_accuracy: 0.0000e+00 - val_loss: 2.5039\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\n",
      "Training fold 7\n",
      "\n",
      "Generating upsampling and SMOTE...\n",
      "2640 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({np.int64(2): 240, np.int64(3): 240, np.int64(6): 240, np.int64(5): 240, np.int64(1): 240, np.int64(0): 240, np.int64(7): 240, np.int64(8): 240, np.int64(4): 240, np.int64(10): 240, np.int64(9): 240})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 96ms/step - accuracy: 0.0939 - loss: 2.3984 - val_accuracy: 0.0000e+00 - val_loss: 2.5001\n",
      "Epoch 2/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 102ms/step - accuracy: 0.0862 - loss: 2.3979 - val_accuracy: 0.0000e+00 - val_loss: 2.5019\n",
      "Epoch 3/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 89ms/step - accuracy: 0.0947 - loss: 2.3968 - val_accuracy: 0.0000e+00 - val_loss: 2.5030\n",
      "Epoch 4/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 88ms/step - accuracy: 0.0899 - loss: 2.3969 - val_accuracy: 0.0000e+00 - val_loss: 2.5022\n",
      "Epoch 5/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 95ms/step - accuracy: 0.0976 - loss: 2.3971 - val_accuracy: 0.0000e+00 - val_loss: 2.5052\n",
      "Epoch 6/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 102ms/step - accuracy: 0.0820 - loss: 2.3985 - val_accuracy: 0.0000e+00 - val_loss: 2.5034\n",
      "Epoch 7/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 88ms/step - accuracy: 0.0886 - loss: 2.3967 - val_accuracy: 0.0000e+00 - val_loss: 2.5083\n",
      "Epoch 8/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.0872 - loss: 2.3973 - val_accuracy: 0.0000e+00 - val_loss: 2.5060\n",
      "Epoch 9/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 92ms/step - accuracy: 0.0967 - loss: 2.3980 - val_accuracy: 0.0000e+00 - val_loss: 2.5019\n",
      "Epoch 10/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.0928 - loss: 2.3986 - val_accuracy: 0.0000e+00 - val_loss: 2.5063\n",
      "Epoch 11/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.0833 - loss: 2.3965 - val_accuracy: 0.0000e+00 - val_loss: 2.5082\n",
      "Epoch 12/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.0832 - loss: 2.3978 - val_accuracy: 0.0000e+00 - val_loss: 2.5092\n",
      "Epoch 13/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.0869 - loss: 2.3971 - val_accuracy: 0.0000e+00 - val_loss: 2.5097\n",
      "Epoch 14/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.0810 - loss: 2.3973 - val_accuracy: 0.0000e+00 - val_loss: 2.5051\n",
      "Epoch 15/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.1014 - loss: 2.3982 - val_accuracy: 0.0000e+00 - val_loss: 2.5050\n",
      "Epoch 16/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.0866 - loss: 2.3970 - val_accuracy: 0.0000e+00 - val_loss: 2.5056\n",
      "Epoch 17/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 92ms/step - accuracy: 0.0897 - loss: 2.3973 - val_accuracy: 0.0000e+00 - val_loss: 2.5062\n",
      "Epoch 18/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.0849 - loss: 2.3976 - val_accuracy: 0.0000e+00 - val_loss: 2.5094\n",
      "Epoch 19/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 90ms/step - accuracy: 0.0917 - loss: 2.3978 - val_accuracy: 0.0000e+00 - val_loss: 2.5044\n",
      "Epoch 20/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.0921 - loss: 2.3970 - val_accuracy: 0.0000e+00 - val_loss: 2.5076\n",
      "Epoch 21/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.0860 - loss: 2.3976 - val_accuracy: 0.0000e+00 - val_loss: 2.5081\n",
      "Epoch 22/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.0882 - loss: 2.3972 - val_accuracy: 0.0000e+00 - val_loss: 2.5096\n",
      "Epoch 23/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.0922 - loss: 2.3968 - val_accuracy: 0.0000e+00 - val_loss: 2.5046\n",
      "Epoch 24/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 89ms/step - accuracy: 0.0868 - loss: 2.3966 - val_accuracy: 0.0000e+00 - val_loss: 2.5040\n",
      "Epoch 25/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.0872 - loss: 2.3979 - val_accuracy: 0.0000e+00 - val_loss: 2.5026\n",
      "Epoch 26/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 100ms/step - accuracy: 0.0854 - loss: 2.3978 - val_accuracy: 0.0000e+00 - val_loss: 2.5007\n",
      "Epoch 27/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 96ms/step - accuracy: 0.0893 - loss: 2.3980 - val_accuracy: 0.0000e+00 - val_loss: 2.5042\n",
      "Epoch 28/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.0984 - loss: 2.3977 - val_accuracy: 0.0000e+00 - val_loss: 2.5045\n",
      "Epoch 29/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.0804 - loss: 2.3968 - val_accuracy: 0.0000e+00 - val_loss: 2.5080\n",
      "Epoch 30/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.0944 - loss: 2.3970 - val_accuracy: 0.0000e+00 - val_loss: 2.5070\n",
      "Epoch 31/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.0880 - loss: 2.3971 - val_accuracy: 0.0000e+00 - val_loss: 2.5053\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\n",
      "Training fold 8\n",
      "\n",
      "Generating upsampling and SMOTE...\n",
      "2640 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({np.int64(3): 240, np.int64(4): 240, np.int64(0): 240, np.int64(6): 240, np.int64(7): 240, np.int64(5): 240, np.int64(1): 240, np.int64(2): 240, np.int64(8): 240, np.int64(10): 240, np.int64(9): 240})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 101ms/step - accuracy: 0.0868 - loss: 2.3981 - val_accuracy: 0.0000e+00 - val_loss: 2.5013\n",
      "Epoch 2/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 95ms/step - accuracy: 0.0857 - loss: 2.3971 - val_accuracy: 0.0000e+00 - val_loss: 2.5017\n",
      "Epoch 3/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 91ms/step - accuracy: 0.1003 - loss: 2.3970 - val_accuracy: 0.0000e+00 - val_loss: 2.5009\n",
      "Epoch 4/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 93ms/step - accuracy: 0.0772 - loss: 2.3979 - val_accuracy: 0.0000e+00 - val_loss: 2.5003\n",
      "Epoch 5/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.1020 - loss: 2.3979 - val_accuracy: 0.0000e+00 - val_loss: 2.5025\n",
      "Epoch 6/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.0931 - loss: 2.3972 - val_accuracy: 0.0000e+00 - val_loss: 2.5028\n",
      "Epoch 7/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 79ms/step - accuracy: 0.0828 - loss: 2.3985 - val_accuracy: 0.0000e+00 - val_loss: 2.4980\n",
      "Epoch 8/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.0899 - loss: 2.3976 - val_accuracy: 0.0000e+00 - val_loss: 2.5020\n",
      "Epoch 9/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 77ms/step - accuracy: 0.0860 - loss: 2.3970 - val_accuracy: 0.0000e+00 - val_loss: 2.5061\n",
      "Epoch 10/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.1015 - loss: 2.3976 - val_accuracy: 0.0000e+00 - val_loss: 2.5070\n",
      "Epoch 11/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.0780 - loss: 2.3977 - val_accuracy: 0.0000e+00 - val_loss: 2.5042\n",
      "Epoch 12/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 97ms/step - accuracy: 0.0986 - loss: 2.3982 - val_accuracy: 0.0000e+00 - val_loss: 2.5067\n",
      "Epoch 13/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 78ms/step - accuracy: 0.0999 - loss: 2.3973 - val_accuracy: 0.0000e+00 - val_loss: 2.5023\n",
      "Epoch 14/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.0917 - loss: 2.3973 - val_accuracy: 0.0000e+00 - val_loss: 2.5050\n",
      "Epoch 15/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.0883 - loss: 2.3977 - val_accuracy: 0.0000e+00 - val_loss: 2.5065\n",
      "Epoch 16/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.0916 - loss: 2.3977 - val_accuracy: 0.0000e+00 - val_loss: 2.5057\n",
      "Epoch 17/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.0980 - loss: 2.3978 - val_accuracy: 0.0000e+00 - val_loss: 2.5088\n",
      "Epoch 18/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.0906 - loss: 2.3976 - val_accuracy: 0.0000e+00 - val_loss: 2.5065\n",
      "Epoch 19/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.0805 - loss: 2.3988 - val_accuracy: 0.0000e+00 - val_loss: 2.5051\n",
      "Epoch 20/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.0763 - loss: 2.3980 - val_accuracy: 0.0000e+00 - val_loss: 2.5033\n",
      "Epoch 21/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.0886 - loss: 2.3979 - val_accuracy: 0.0000e+00 - val_loss: 2.5052\n",
      "Epoch 22/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.0821 - loss: 2.3978 - val_accuracy: 0.0000e+00 - val_loss: 2.5076\n",
      "Epoch 23/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.1002 - loss: 2.3971 - val_accuracy: 0.0000e+00 - val_loss: 2.5127\n",
      "Epoch 24/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 78ms/step - accuracy: 0.0976 - loss: 2.3976 - val_accuracy: 0.0000e+00 - val_loss: 2.5069\n",
      "Epoch 25/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.0859 - loss: 2.3967 - val_accuracy: 0.0000e+00 - val_loss: 2.5059\n",
      "Epoch 26/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.0879 - loss: 2.3975 - val_accuracy: 0.0000e+00 - val_loss: 2.5052\n",
      "Epoch 27/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.0845 - loss: 2.3975 - val_accuracy: 0.0000e+00 - val_loss: 2.5038\n",
      "Epoch 28/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.0857 - loss: 2.3973 - val_accuracy: 0.0000e+00 - val_loss: 2.5039\n",
      "Epoch 29/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.0752 - loss: 2.3979 - val_accuracy: 0.0000e+00 - val_loss: 2.5059\n",
      "Epoch 30/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.0868 - loss: 2.3976 - val_accuracy: 0.0000e+00 - val_loss: 2.5051\n",
      "Epoch 31/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.0896 - loss: 2.3978 - val_accuracy: 0.0000e+00 - val_loss: 2.5082\n",
      "Epoch 32/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.0882 - loss: 2.3973 - val_accuracy: 0.0000e+00 - val_loss: 2.5030\n",
      "Epoch 33/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.0846 - loss: 2.3974 - val_accuracy: 0.0000e+00 - val_loss: 2.5057\n",
      "Epoch 34/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.0959 - loss: 2.3989 - val_accuracy: 0.0000e+00 - val_loss: 2.5039\n",
      "Epoch 35/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.0974 - loss: 2.3977 - val_accuracy: 0.0000e+00 - val_loss: 2.5066\n",
      "Epoch 36/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 78ms/step - accuracy: 0.0895 - loss: 2.3975 - val_accuracy: 0.0000e+00 - val_loss: 2.5122\n",
      "Epoch 37/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.0912 - loss: 2.3978 - val_accuracy: 0.0000e+00 - val_loss: 2.5060\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\n",
      "Training fold 9\n",
      "\n",
      "Generating upsampling and SMOTE...\n",
      "2640 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({np.int64(3): 240, np.int64(4): 240, np.int64(0): 240, np.int64(6): 240, np.int64(7): 240, np.int64(9): 240, np.int64(5): 240, np.int64(1): 240, np.int64(2): 240, np.int64(8): 240, np.int64(10): 240})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 74ms/step - accuracy: 0.0867 - loss: 2.3978 - val_accuracy: 0.0000e+00 - val_loss: 2.5003\n",
      "Epoch 2/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 71ms/step - accuracy: 0.0954 - loss: 2.3976 - val_accuracy: 0.0000e+00 - val_loss: 2.5006\n",
      "Epoch 3/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 71ms/step - accuracy: 0.0884 - loss: 2.3964 - val_accuracy: 0.0000e+00 - val_loss: 2.5006\n",
      "Epoch 4/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 74ms/step - accuracy: 0.0863 - loss: 2.3969 - val_accuracy: 0.0000e+00 - val_loss: 2.5028\n",
      "Epoch 5/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 67ms/step - accuracy: 0.0880 - loss: 2.3976 - val_accuracy: 0.0000e+00 - val_loss: 2.5005\n",
      "Epoch 6/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 68ms/step - accuracy: 0.0886 - loss: 2.3982 - val_accuracy: 0.0000e+00 - val_loss: 2.5016\n",
      "Epoch 7/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 76ms/step - accuracy: 0.0931 - loss: 2.3964 - val_accuracy: 0.0000e+00 - val_loss: 2.5021\n",
      "Epoch 8/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 78ms/step - accuracy: 0.0950 - loss: 2.3975 - val_accuracy: 0.0000e+00 - val_loss: 2.5039\n",
      "Epoch 9/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 70ms/step - accuracy: 0.0862 - loss: 2.3977 - val_accuracy: 0.0000e+00 - val_loss: 2.4973\n",
      "Epoch 10/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 69ms/step - accuracy: 0.0999 - loss: 2.3974 - val_accuracy: 0.0000e+00 - val_loss: 2.5028\n",
      "Epoch 11/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 74ms/step - accuracy: 0.0944 - loss: 2.3971 - val_accuracy: 0.0000e+00 - val_loss: 2.5019\n",
      "Epoch 12/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 71ms/step - accuracy: 0.0928 - loss: 2.3975 - val_accuracy: 0.0000e+00 - val_loss: 2.5013\n",
      "Epoch 13/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 67ms/step - accuracy: 0.0862 - loss: 2.3975 - val_accuracy: 0.0000e+00 - val_loss: 2.5010\n",
      "Epoch 14/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 76ms/step - accuracy: 0.0908 - loss: 2.3977 - val_accuracy: 0.0000e+00 - val_loss: 2.5034\n",
      "Epoch 15/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.0919 - loss: 2.3971 - val_accuracy: 0.0000e+00 - val_loss: 2.5044\n",
      "Epoch 16/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 70ms/step - accuracy: 0.0833 - loss: 2.3973 - val_accuracy: 0.0000e+00 - val_loss: 2.5014\n",
      "Epoch 17/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 71ms/step - accuracy: 0.0873 - loss: 2.3972 - val_accuracy: 0.0000e+00 - val_loss: 2.5027\n",
      "Epoch 18/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 71ms/step - accuracy: 0.0934 - loss: 2.3979 - val_accuracy: 0.0000e+00 - val_loss: 2.5035\n",
      "Epoch 19/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 73ms/step - accuracy: 0.0888 - loss: 2.3977 - val_accuracy: 0.0000e+00 - val_loss: 2.5065\n",
      "Epoch 20/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.0833 - loss: 2.3987 - val_accuracy: 0.0000e+00 - val_loss: 2.5057\n",
      "Epoch 21/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 76ms/step - accuracy: 0.0958 - loss: 2.3972 - val_accuracy: 0.0000e+00 - val_loss: 2.5091\n",
      "Epoch 22/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 70ms/step - accuracy: 0.0984 - loss: 2.3971 - val_accuracy: 0.0000e+00 - val_loss: 2.5081\n",
      "Epoch 23/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 71ms/step - accuracy: 0.0805 - loss: 2.3988 - val_accuracy: 0.0000e+00 - val_loss: 2.5048\n",
      "Epoch 24/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 75ms/step - accuracy: 0.0866 - loss: 2.3971 - val_accuracy: 0.0000e+00 - val_loss: 2.5091\n",
      "Epoch 25/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 73ms/step - accuracy: 0.0807 - loss: 2.3967 - val_accuracy: 0.0000e+00 - val_loss: 2.5062\n",
      "Epoch 26/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 72ms/step - accuracy: 0.0874 - loss: 2.3977 - val_accuracy: 0.0000e+00 - val_loss: 2.5035\n",
      "Epoch 27/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 71ms/step - accuracy: 0.0796 - loss: 2.3974 - val_accuracy: 0.0000e+00 - val_loss: 2.5023\n",
      "Epoch 28/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 73ms/step - accuracy: 0.0851 - loss: 2.3972 - val_accuracy: 0.0000e+00 - val_loss: 2.5106\n",
      "Epoch 29/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 72ms/step - accuracy: 0.0917 - loss: 2.3987 - val_accuracy: 0.0000e+00 - val_loss: 2.5039\n",
      "Epoch 30/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 78ms/step - accuracy: 0.1021 - loss: 2.3979 - val_accuracy: 0.0000e+00 - val_loss: 2.5065\n",
      "Epoch 31/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 74ms/step - accuracy: 0.0760 - loss: 2.3980 - val_accuracy: 0.0000e+00 - val_loss: 2.5062\n",
      "Epoch 32/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 75ms/step - accuracy: 0.1044 - loss: 2.3961 - val_accuracy: 0.0000e+00 - val_loss: 2.5083\n",
      "Epoch 33/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 77ms/step - accuracy: 0.0694 - loss: 2.3975 - val_accuracy: 0.0000e+00 - val_loss: 2.5066\n",
      "Epoch 34/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 73ms/step - accuracy: 0.1001 - loss: 2.3970 - val_accuracy: 0.0000e+00 - val_loss: 2.5066\n",
      "Epoch 35/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 72ms/step - accuracy: 0.0889 - loss: 2.3977 - val_accuracy: 0.0000e+00 - val_loss: 2.5016\n",
      "Epoch 36/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 75ms/step - accuracy: 0.0823 - loss: 2.3977 - val_accuracy: 0.0000e+00 - val_loss: 2.5062\n",
      "Epoch 37/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 75ms/step - accuracy: 0.0953 - loss: 2.3974 - val_accuracy: 0.0000e+00 - val_loss: 2.5072\n",
      "Epoch 38/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 71ms/step - accuracy: 0.0814 - loss: 2.3978 - val_accuracy: 0.0000e+00 - val_loss: 2.5044\n",
      "Epoch 39/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 74ms/step - accuracy: 0.1012 - loss: 2.3960 - val_accuracy: 0.0000e+00 - val_loss: 2.5081\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\n",
      "Training fold 10\n",
      "\n",
      "Generating upsampling and SMOTE...\n",
      "2640 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({np.int64(3): 240, np.int64(4): 240, np.int64(0): 240, np.int64(6): 240, np.int64(7): 240, np.int64(9): 240, np.int64(5): 240, np.int64(1): 240, np.int64(2): 240, np.int64(8): 240, np.int64(10): 240})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 91ms/step - accuracy: 0.0886 - loss: 2.3979 - val_accuracy: 0.0000e+00 - val_loss: 2.4986\n",
      "Epoch 2/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 79ms/step - accuracy: 0.0870 - loss: 2.3974 - val_accuracy: 0.0000e+00 - val_loss: 2.4970\n",
      "Epoch 3/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 95ms/step - accuracy: 0.0753 - loss: 2.3980 - val_accuracy: 0.0000e+00 - val_loss: 2.4989\n",
      "Epoch 4/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 94ms/step - accuracy: 0.0867 - loss: 2.3970 - val_accuracy: 0.0000e+00 - val_loss: 2.5032\n",
      "Epoch 5/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.0928 - loss: 2.3976 - val_accuracy: 0.0000e+00 - val_loss: 2.4982\n",
      "Epoch 6/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 79ms/step - accuracy: 0.0825 - loss: 2.3982 - val_accuracy: 0.0000e+00 - val_loss: 2.5037\n",
      "Epoch 7/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 77ms/step - accuracy: 0.0820 - loss: 2.3982 - val_accuracy: 0.0000e+00 - val_loss: 2.5006\n",
      "Epoch 8/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.0724 - loss: 2.3974 - val_accuracy: 0.0000e+00 - val_loss: 2.5017\n",
      "Epoch 9/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.0864 - loss: 2.3974 - val_accuracy: 0.0000e+00 - val_loss: 2.5022\n",
      "Epoch 10/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.0949 - loss: 2.3967 - val_accuracy: 0.0000e+00 - val_loss: 2.5051\n",
      "Epoch 11/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.0927 - loss: 2.3985 - val_accuracy: 0.0000e+00 - val_loss: 2.5001\n",
      "Epoch 12/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 89ms/step - accuracy: 0.0812 - loss: 2.3977 - val_accuracy: 0.0000e+00 - val_loss: 2.5033\n",
      "Epoch 13/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 91ms/step - accuracy: 0.0849 - loss: 2.3978 - val_accuracy: 0.0000e+00 - val_loss: 2.5069\n",
      "Epoch 14/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.0830 - loss: 2.3966 - val_accuracy: 0.0000e+00 - val_loss: 2.5071\n",
      "Epoch 15/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.0870 - loss: 2.3968 - val_accuracy: 0.0000e+00 - val_loss: 2.5057\n",
      "Epoch 16/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 88ms/step - accuracy: 0.0948 - loss: 2.3987 - val_accuracy: 0.0000e+00 - val_loss: 2.5039\n",
      "Epoch 17/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.0823 - loss: 2.3977 - val_accuracy: 0.0000e+00 - val_loss: 2.5051\n",
      "Epoch 18/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 89ms/step - accuracy: 0.0928 - loss: 2.3972 - val_accuracy: 0.0000e+00 - val_loss: 2.5059\n",
      "Epoch 19/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 78ms/step - accuracy: 0.0902 - loss: 2.3978 - val_accuracy: 0.0000e+00 - val_loss: 2.5081\n",
      "Epoch 20/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.0941 - loss: 2.3977 - val_accuracy: 0.0000e+00 - val_loss: 2.5066\n",
      "Epoch 21/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 92ms/step - accuracy: 0.0828 - loss: 2.3981 - val_accuracy: 0.0000e+00 - val_loss: 2.5064\n",
      "Epoch 22/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.0892 - loss: 2.3977 - val_accuracy: 0.0000e+00 - val_loss: 2.5104\n",
      "Epoch 23/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 88ms/step - accuracy: 0.0806 - loss: 2.3974 - val_accuracy: 0.0000e+00 - val_loss: 2.5058\n",
      "Epoch 24/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.0966 - loss: 2.3967 - val_accuracy: 0.0000e+00 - val_loss: 2.5022\n",
      "Epoch 25/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 88ms/step - accuracy: 0.0898 - loss: 2.3969 - val_accuracy: 0.0000e+00 - val_loss: 2.5037\n",
      "Epoch 26/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.0866 - loss: 2.3974 - val_accuracy: 0.0000e+00 - val_loss: 2.5045\n",
      "Epoch 27/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 94ms/step - accuracy: 0.0905 - loss: 2.3983 - val_accuracy: 0.0000e+00 - val_loss: 2.5026\n",
      "Epoch 28/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.0755 - loss: 2.3974 - val_accuracy: 0.0000e+00 - val_loss: 2.5088\n",
      "Epoch 29/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.0924 - loss: 2.3967 - val_accuracy: 0.0000e+00 - val_loss: 2.5082\n",
      "Epoch 30/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.0888 - loss: 2.3969 - val_accuracy: 0.0000e+00 - val_loss: 2.5084\n",
      "Epoch 31/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.0777 - loss: 2.3972 - val_accuracy: 0.0000e+00 - val_loss: 2.5026\n",
      "Epoch 32/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 89ms/step - accuracy: 0.0899 - loss: 2.3971 - val_accuracy: 0.0000e+00 - val_loss: 2.5060\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\n",
      "Time taken for training:  00:57:23\n",
      "\n",
      "\n",
      "Fold 1 - Train Accuracy 1.0000 - Test Accuracy 0.2500\n",
      "Fold 2 - Train Accuracy 0.0909 - Test Accuracy 0.0417\n",
      "Fold 3 - Train Accuracy 0.0909 - Test Accuracy 0.0625\n",
      "Fold 4 - Train Accuracy 0.0909 - Test Accuracy 0.0625\n",
      "Fold 5 - Train Accuracy 0.0909 - Test Accuracy 0.0625\n",
      "Fold 6 - Train Accuracy 0.0909 - Test Accuracy 0.0625\n",
      "Fold 7 - Train Accuracy 0.0909 - Test Accuracy 0.0625\n",
      "Fold 8 - Train Accuracy 0.0909 - Test Accuracy 0.0417\n",
      "Fold 9 - Train Accuracy 0.0909 - Test Accuracy 0.0417\n",
      "Fold 10 - Train Accuracy 0.0909 - Test Accuracy 0.1042\n",
      "\n",
      "Mean Train Accuracy: 0.1818 \n",
      "Mean Test Accuracy: 0.0792 \n",
      "\n",
      "Evaluate other metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.07      0.12       120\n",
      "           1       0.00      0.00      0.00        19\n",
      "           2       0.05      0.84      0.10        25\n",
      "           3       0.19      0.05      0.08        58\n",
      "           4       0.33      0.02      0.04        54\n",
      "           5       0.00      0.00      0.00        77\n",
      "           6       0.10      0.09      0.09        57\n",
      "           7       0.00      0.00      0.00        32\n",
      "           8       0.00      0.00      0.00        24\n",
      "           9       0.00      0.00      0.00        10\n",
      "          10       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.08       480\n",
      "   macro avg       0.11      0.10      0.04       480\n",
      "weighted avg       0.21      0.08      0.06       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def create_baseline():\n",
    "    act_function = \"relu\"\n",
    "    kernel_init = \"he_uniform\"\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(number_of_steps, number_of_features)))\n",
    "    model.add(Conv1D(filters = 64, kernel_size = 3, activation = act_function,\n",
    "                     kernel_initializer = kernel_init))\n",
    "    model.add(Conv1D(filters = 32, kernel_size = 3, activation = act_function,\n",
    "                     kernel_initializer = kernel_init))\n",
    "    model.add(Conv1D(filters = 16, kernel_size = 3, activation = act_function,\n",
    "                     kernel_initializer = kernel_init))\n",
    "    model.add(MaxPooling1D(pool_size = 2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(32, activation = act_function))\n",
    "    model.add(Dense(11, activation = 'softmax'))\n",
    "    opt = AdamW(learning_rate = 0.001)\n",
    "    model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = opt, metrics = [\"accuracy\"])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "X_list, y_list = build_time_window_structure(df)\n",
    "X_arr = np.array(X_list)\n",
    "y_arr = np.array(y_list)\n",
    "\n",
    "model = create_baseline()\n",
    "history_by_fold = train_cnn_model(model, X_arr, y_arr, quantity_of_resample = len(y_arr) * 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ad099f",
   "metadata": {},
   "source": [
    "#### Train a Convolutional Neural Network model and evaluate the metrics.\n",
    "- Layer architecture => Conv1D (64) + Conv1D (32) + Conv1D (16) + MaxPooling1D + Dense (32) + Dense(32) + Dense(32) + Dense (11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aaf55fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting build_time_window_structure function...\n",
      "Quantity of samples (features) =>  480\n",
      "Quantity os samples (labels) =>  480\n",
      "Finishing build_time_window_structure function.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3198</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3196</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,176</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3194</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,552</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1597</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25552</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">817,696</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">363</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3198\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │         \u001b[38;5;34m6,208\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3196\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │         \u001b[38;5;34m6,176\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3194\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │         \u001b[38;5;34m1,552\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1597\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25552\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │       \u001b[38;5;34m817,696\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m1,056\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m1,056\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m)             │           \u001b[38;5;34m363\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">834,107</span> (3.18 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m834,107\u001b[0m (3.18 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">834,107</span> (3.18 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m834,107\u001b[0m (3.18 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training...\n",
      "\n",
      "Training fold 1\n",
      "\n",
      "Generating upsampling and SMOTE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\DeveloperTools\\python\\3.11.0\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2640 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({np.int64(3): 240, np.int64(4): 240, np.int64(0): 240, np.int64(6): 240, np.int64(7): 240, np.int64(9): 240, np.int64(5): 240, np.int64(1): 240, np.int64(2): 240, np.int64(8): 240, np.int64(10): 240})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 68ms/step - accuracy: 0.1114 - loss: 3.3159 - val_accuracy: 1.0000 - val_loss: 1.2068\n",
      "Epoch 2/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - accuracy: 0.1678 - loss: 2.0863 - val_accuracy: 1.0000 - val_loss: 0.5495\n",
      "Epoch 3/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.1834 - loss: 1.8687 - val_accuracy: 1.0000 - val_loss: 0.5053\n",
      "Epoch 4/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - accuracy: 0.2131 - loss: 1.7181 - val_accuracy: 1.0000 - val_loss: 0.3162\n",
      "Epoch 5/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.2540 - loss: 1.5947 - val_accuracy: 0.6296 - val_loss: 0.7931\n",
      "Epoch 6/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.2808 - loss: 1.5415 - val_accuracy: 1.0000 - val_loss: 0.1205\n",
      "Epoch 7/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.2883 - loss: 1.4760 - val_accuracy: 1.0000 - val_loss: 0.1524\n",
      "Epoch 8/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.3512 - loss: 1.4051 - val_accuracy: 1.0000 - val_loss: 0.3097\n",
      "Epoch 9/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - accuracy: 0.3599 - loss: 1.4086 - val_accuracy: 1.0000 - val_loss: 0.3567\n",
      "Epoch 10/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - accuracy: 0.3581 - loss: 1.4137 - val_accuracy: 1.0000 - val_loss: 0.0258\n",
      "Epoch 11/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - accuracy: 0.4027 - loss: 1.2994 - val_accuracy: 1.0000 - val_loss: 0.0226\n",
      "Epoch 12/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 66ms/step - accuracy: 0.4009 - loss: 1.2930 - val_accuracy: 1.0000 - val_loss: 0.0995\n",
      "Epoch 13/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 0.3839 - loss: 1.2889 - val_accuracy: 1.0000 - val_loss: 0.0102\n",
      "Epoch 14/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 66ms/step - accuracy: 0.4616 - loss: 1.1948 - val_accuracy: 1.0000 - val_loss: 0.0606\n",
      "Epoch 15/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 0.4446 - loss: 1.1964 - val_accuracy: 1.0000 - val_loss: 0.0203\n",
      "Epoch 16/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.4798 - loss: 1.2017 - val_accuracy: 1.0000 - val_loss: 0.0279\n",
      "Epoch 17/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - accuracy: 0.4846 - loss: 1.1820 - val_accuracy: 1.0000 - val_loss: 0.2138\n",
      "Epoch 18/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - accuracy: 0.4638 - loss: 1.2214 - val_accuracy: 1.0000 - val_loss: 0.0229\n",
      "Epoch 19/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 68ms/step - accuracy: 0.5214 - loss: 1.0803 - val_accuracy: 1.0000 - val_loss: 0.0209\n",
      "Epoch 20/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 0.5269 - loss: 1.0531 - val_accuracy: 1.0000 - val_loss: 0.0359\n",
      "Epoch 21/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - accuracy: 0.5215 - loss: 1.0569 - val_accuracy: 1.0000 - val_loss: 0.0146\n",
      "Epoch 22/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - accuracy: 0.5096 - loss: 1.0949 - val_accuracy: 1.0000 - val_loss: 0.0791\n",
      "Epoch 23/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 64ms/step - accuracy: 0.5021 - loss: 1.1410 - val_accuracy: 1.0000 - val_loss: 0.0988\n",
      "Epoch 24/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 69ms/step - accuracy: 0.5233 - loss: 1.0857 - val_accuracy: 1.0000 - val_loss: 0.1131\n",
      "Epoch 25/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 69ms/step - accuracy: 0.5291 - loss: 1.0588 - val_accuracy: 1.0000 - val_loss: 0.0097\n",
      "Epoch 26/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 64ms/step - accuracy: 0.5670 - loss: 0.9937 - val_accuracy: 1.0000 - val_loss: 0.0186\n",
      "Epoch 27/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - accuracy: 0.5661 - loss: 0.9526 - val_accuracy: 1.0000 - val_loss: 0.0152\n",
      "Epoch 28/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 71ms/step - accuracy: 0.5188 - loss: 1.0083 - val_accuracy: 1.0000 - val_loss: 0.0248\n",
      "Epoch 29/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 67ms/step - accuracy: 0.5566 - loss: 0.9568 - val_accuracy: 1.0000 - val_loss: 0.0242\n",
      "Epoch 30/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 0.5528 - loss: 0.9738 - val_accuracy: 1.0000 - val_loss: 0.0051\n",
      "Epoch 31/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 0.5714 - loss: 0.9179 - val_accuracy: 1.0000 - val_loss: 0.0118\n",
      "Epoch 32/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 0.6087 - loss: 0.9282 - val_accuracy: 1.0000 - val_loss: 0.0015\n",
      "Epoch 33/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 67ms/step - accuracy: 0.5834 - loss: 0.9524 - val_accuracy: 1.0000 - val_loss: 2.6860e-04\n",
      "Epoch 34/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - accuracy: 0.6029 - loss: 0.9945 - val_accuracy: 1.0000 - val_loss: 0.0059\n",
      "Epoch 35/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.5583 - loss: 0.9741 - val_accuracy: 1.0000 - val_loss: 0.0128\n",
      "Epoch 36/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - accuracy: 0.5848 - loss: 0.9853 - val_accuracy: 1.0000 - val_loss: 0.0088\n",
      "Epoch 37/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 67ms/step - accuracy: 0.6130 - loss: 0.9058 - val_accuracy: 1.0000 - val_loss: 0.0023\n",
      "Epoch 38/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 74ms/step - accuracy: 0.6125 - loss: 0.8849 - val_accuracy: 1.0000 - val_loss: 0.0729\n",
      "Epoch 39/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 66ms/step - accuracy: 0.6298 - loss: 0.8427 - val_accuracy: 1.0000 - val_loss: 0.0065\n",
      "Epoch 40/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 77ms/step - accuracy: 0.5906 - loss: 0.9358 - val_accuracy: 1.0000 - val_loss: 0.0363\n",
      "Epoch 41/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 71ms/step - accuracy: 0.5995 - loss: 0.9333 - val_accuracy: 1.0000 - val_loss: 0.0031\n",
      "Epoch 42/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 70ms/step - accuracy: 0.6273 - loss: 0.8366 - val_accuracy: 1.0000 - val_loss: 0.0170\n",
      "Epoch 43/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 73ms/step - accuracy: 0.6075 - loss: 0.8359 - val_accuracy: 1.0000 - val_loss: 0.0033\n",
      "Epoch 44/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 73ms/step - accuracy: 0.6310 - loss: 0.7826 - val_accuracy: 1.0000 - val_loss: 0.0087\n",
      "Epoch 45/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 70ms/step - accuracy: 0.6407 - loss: 0.7755 - val_accuracy: 1.0000 - val_loss: 0.0030\n",
      "Epoch 46/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 76ms/step - accuracy: 0.6315 - loss: 0.7730 - val_accuracy: 1.0000 - val_loss: 0.0020\n",
      "Epoch 47/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 70ms/step - accuracy: 0.6314 - loss: 0.7797 - val_accuracy: 1.0000 - val_loss: 0.0023\n",
      "Epoch 48/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 67ms/step - accuracy: 0.6416 - loss: 0.7666 - val_accuracy: 1.0000 - val_loss: 0.0065\n",
      "Epoch 49/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 67ms/step - accuracy: 0.6478 - loss: 0.7340 - val_accuracy: 1.0000 - val_loss: 7.3052e-04\n",
      "Epoch 50/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 70ms/step - accuracy: 0.6266 - loss: 0.7482 - val_accuracy: 1.0000 - val_loss: 0.0025\n",
      "Epoch 51/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 74ms/step - accuracy: 0.6377 - loss: 0.7589 - val_accuracy: 1.0000 - val_loss: 0.0023\n",
      "Epoch 52/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 66ms/step - accuracy: 0.6334 - loss: 0.7543 - val_accuracy: 1.0000 - val_loss: 0.0051\n",
      "Epoch 53/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 68ms/step - accuracy: 0.6432 - loss: 0.7471 - val_accuracy: 1.0000 - val_loss: 0.0014\n",
      "Epoch 54/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 67ms/step - accuracy: 0.5280 - loss: 1.1938 - val_accuracy: 1.0000 - val_loss: 0.0109\n",
      "Epoch 55/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 74ms/step - accuracy: 0.5414 - loss: 1.1161 - val_accuracy: 1.0000 - val_loss: 0.0052\n",
      "Epoch 56/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 75ms/step - accuracy: 0.5648 - loss: 0.9638 - val_accuracy: 1.0000 - val_loss: 0.0024\n",
      "Epoch 57/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 72ms/step - accuracy: 0.6093 - loss: 0.9089 - val_accuracy: 1.0000 - val_loss: 0.0042\n",
      "Epoch 58/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 69ms/step - accuracy: 0.6337 - loss: 0.8436 - val_accuracy: 1.0000 - val_loss: 0.0041\n",
      "Epoch 59/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 74ms/step - accuracy: 0.6081 - loss: 0.8411 - val_accuracy: 1.0000 - val_loss: 0.0024\n",
      "Epoch 60/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 74ms/step - accuracy: 0.6172 - loss: 0.8151 - val_accuracy: 1.0000 - val_loss: 0.0021\n",
      "Epoch 61/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 71ms/step - accuracy: 0.6036 - loss: 0.8243 - val_accuracy: 1.0000 - val_loss: 0.0067\n",
      "Epoch 62/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 77ms/step - accuracy: 0.5960 - loss: 0.8302 - val_accuracy: 1.0000 - val_loss: 0.0014\n",
      "Epoch 63/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 78ms/step - accuracy: 0.6203 - loss: 0.8281 - val_accuracy: 1.0000 - val_loss: 2.0751e-06\n",
      "Epoch 64/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.5577 - loss: 0.9562 - val_accuracy: 1.0000 - val_loss: 0.0975\n",
      "Epoch 65/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.5876 - loss: 0.9027 - val_accuracy: 1.0000 - val_loss: 9.3696e-05\n",
      "Epoch 66/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.6088 - loss: 0.8624 - val_accuracy: 1.0000 - val_loss: 1.2114e-04\n",
      "Epoch 67/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 63ms/step - accuracy: 0.6234 - loss: 0.8299 - val_accuracy: 1.0000 - val_loss: 0.0014\n",
      "Epoch 68/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 78ms/step - accuracy: 0.6318 - loss: 0.7954 - val_accuracy: 1.0000 - val_loss: 0.0010\n",
      "Epoch 69/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 92ms/step - accuracy: 0.6214 - loss: 0.8104 - val_accuracy: 1.0000 - val_loss: 0.0032\n",
      "Epoch 70/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.6105 - loss: 0.8229 - val_accuracy: 1.0000 - val_loss: 0.0252\n",
      "Epoch 71/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.5872 - loss: 0.8787 - val_accuracy: 1.0000 - val_loss: 0.0024\n",
      "Epoch 72/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.6182 - loss: 0.8342 - val_accuracy: 1.0000 - val_loss: 0.0014\n",
      "Epoch 73/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.6122 - loss: 0.8024 - val_accuracy: 1.0000 - val_loss: 2.0906e-04\n",
      "Epoch 74/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.6255 - loss: 0.7929 - val_accuracy: 1.0000 - val_loss: 4.6631e-04\n",
      "Epoch 75/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.5986 - loss: 0.8284 - val_accuracy: 1.0000 - val_loss: 1.3846e-04\n",
      "Epoch 76/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.6022 - loss: 0.8514 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
      "Epoch 77/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.6141 - loss: 0.8162 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 78/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.6237 - loss: 0.7683 - val_accuracy: 1.0000 - val_loss: 4.2464e-04\n",
      "Epoch 79/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.6352 - loss: 0.7846 - val_accuracy: 1.0000 - val_loss: 7.1353e-04\n",
      "Epoch 80/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.6255 - loss: 0.7868 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
      "Epoch 81/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 93ms/step - accuracy: 0.6152 - loss: 0.7924 - val_accuracy: 1.0000 - val_loss: 8.5654e-04\n",
      "Epoch 82/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 115ms/step - accuracy: 0.6406 - loss: 0.7585 - val_accuracy: 1.0000 - val_loss: 4.7247e-04\n",
      "Epoch 83/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 127ms/step - accuracy: 0.6333 - loss: 0.7620 - val_accuracy: 1.0000 - val_loss: 7.0325e-04\n",
      "Epoch 84/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 89ms/step - accuracy: 0.6450 - loss: 0.7545 - val_accuracy: 1.0000 - val_loss: 0.0010\n",
      "Epoch 85/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.6426 - loss: 0.7461 - val_accuracy: 1.0000 - val_loss: 5.6938e-04\n",
      "Epoch 86/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.6204 - loss: 0.7882 - val_accuracy: 1.0000 - val_loss: 8.1633e-04\n",
      "Epoch 87/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 89ms/step - accuracy: 0.6285 - loss: 0.7873 - val_accuracy: 1.0000 - val_loss: 7.7143e-04\n",
      "Epoch 88/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 93ms/step - accuracy: 0.6250 - loss: 0.7837 - val_accuracy: 1.0000 - val_loss: 0.0010\n",
      "Epoch 89/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 95ms/step - accuracy: 0.6205 - loss: 0.7618 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
      "Epoch 90/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 89ms/step - accuracy: 0.6219 - loss: 0.7669 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
      "Epoch 91/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 89ms/step - accuracy: 0.6186 - loss: 0.7542 - val_accuracy: 1.0000 - val_loss: 6.9264e-04\n",
      "Epoch 92/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 88ms/step - accuracy: 0.6174 - loss: 0.7883 - val_accuracy: 1.0000 - val_loss: 4.2192e-04\n",
      "Epoch 93/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 78ms/step - accuracy: 0.6237 - loss: 0.7790 - val_accuracy: 1.0000 - val_loss: 6.0551e-04\n",
      "Epoch 93: early stopping\n",
      "Restoring model weights from the end of the best epoch: 63.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step\n",
      "\n",
      "Training fold 2\n",
      "\n",
      "Generating upsampling and SMOTE...\n",
      "2640 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({np.int64(2): 240, np.int64(3): 240, np.int64(6): 240, np.int64(5): 240, np.int64(1): 240, np.int64(0): 240, np.int64(7): 240, np.int64(4): 240, np.int64(10): 240, np.int64(8): 240, np.int64(9): 240})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 104ms/step - accuracy: 0.3720 - loss: 2.2760 - val_accuracy: 1.0000 - val_loss: 0.0533\n",
      "Epoch 2/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 99ms/step - accuracy: 0.5268 - loss: 1.0610 - val_accuracy: 1.0000 - val_loss: 0.0246\n",
      "Epoch 3/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 108ms/step - accuracy: 0.5497 - loss: 0.9936 - val_accuracy: 1.0000 - val_loss: 0.0063\n",
      "Epoch 4/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 105ms/step - accuracy: 0.5823 - loss: 0.9206 - val_accuracy: 1.0000 - val_loss: 0.0054\n",
      "Epoch 5/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 100ms/step - accuracy: 0.6114 - loss: 0.8473 - val_accuracy: 1.0000 - val_loss: 0.0033\n",
      "Epoch 6/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 120ms/step - accuracy: 0.5975 - loss: 0.8731 - val_accuracy: 1.0000 - val_loss: 0.0026\n",
      "Epoch 7/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 102ms/step - accuracy: 0.6212 - loss: 0.8397 - val_accuracy: 1.0000 - val_loss: 0.0026\n",
      "Epoch 8/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 90ms/step - accuracy: 0.6067 - loss: 0.8470 - val_accuracy: 1.0000 - val_loss: 0.0048\n",
      "Epoch 9/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 93ms/step - accuracy: 0.6194 - loss: 0.8778 - val_accuracy: 1.0000 - val_loss: 0.0087\n",
      "Epoch 10/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.5951 - loss: 0.9195 - val_accuracy: 1.0000 - val_loss: 1.3439e-05\n",
      "Epoch 11/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.5803 - loss: 0.9093 - val_accuracy: 1.0000 - val_loss: 9.5228e-05\n",
      "Epoch 12/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.5910 - loss: 0.9262 - val_accuracy: 1.0000 - val_loss: 0.0045\n",
      "Epoch 13/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 92ms/step - accuracy: 0.6182 - loss: 0.8591 - val_accuracy: 1.0000 - val_loss: 0.0247\n",
      "Epoch 14/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 98ms/step - accuracy: 0.6116 - loss: 0.8297 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
      "Epoch 15/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 96ms/step - accuracy: 0.6087 - loss: 0.8587 - val_accuracy: 1.0000 - val_loss: 0.0191\n",
      "Epoch 16/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 90ms/step - accuracy: 0.6098 - loss: 0.8501 - val_accuracy: 1.0000 - val_loss: 7.2825e-04\n",
      "Epoch 17/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 97ms/step - accuracy: 0.6015 - loss: 0.8449 - val_accuracy: 1.0000 - val_loss: 0.0019\n",
      "Epoch 18/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.6103 - loss: 0.8392 - val_accuracy: 1.0000 - val_loss: 9.8795e-04\n",
      "Epoch 19/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.6162 - loss: 0.8407 - val_accuracy: 1.0000 - val_loss: 0.0013\n",
      "Epoch 20/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 114ms/step - accuracy: 0.6021 - loss: 0.8314 - val_accuracy: 1.0000 - val_loss: 0.0015\n",
      "Epoch 21/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 135ms/step - accuracy: 0.6087 - loss: 0.8164 - val_accuracy: 1.0000 - val_loss: 6.4919e-04\n",
      "Epoch 22/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 125ms/step - accuracy: 0.5982 - loss: 0.8356 - val_accuracy: 1.0000 - val_loss: 2.0653e-04\n",
      "Epoch 23/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 119ms/step - accuracy: 0.5906 - loss: 0.8678 - val_accuracy: 1.0000 - val_loss: 0.0018\n",
      "Epoch 24/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 113ms/step - accuracy: 0.6003 - loss: 0.8523 - val_accuracy: 1.0000 - val_loss: 0.0019\n",
      "Epoch 25/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 121ms/step - accuracy: 0.6010 - loss: 0.8548 - val_accuracy: 1.0000 - val_loss: 0.0045\n",
      "Epoch 26/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 106ms/step - accuracy: 0.6251 - loss: 0.8209 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 27/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 115ms/step - accuracy: 0.6151 - loss: 0.8410 - val_accuracy: 1.0000 - val_loss: 0.0044\n",
      "Epoch 28/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 114ms/step - accuracy: 0.6015 - loss: 0.8361 - val_accuracy: 1.0000 - val_loss: 0.0077\n",
      "Epoch 29/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step - accuracy: 0.5937 - loss: 0.9323 - val_accuracy: 1.0000 - val_loss: 7.9514e-05\n",
      "Epoch 30/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 96ms/step - accuracy: 0.5807 - loss: 0.9192 - val_accuracy: 1.0000 - val_loss: 0.0026\n",
      "Epoch 31/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 93ms/step - accuracy: 0.5950 - loss: 0.9009 - val_accuracy: 1.0000 - val_loss: 2.7369e-04\n",
      "Epoch 32/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 105ms/step - accuracy: 0.5967 - loss: 0.8844 - val_accuracy: 1.0000 - val_loss: 0.0073\n",
      "Epoch 33/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 91ms/step - accuracy: 0.6041 - loss: 0.8723 - val_accuracy: 1.0000 - val_loss: 0.0015\n",
      "Epoch 34/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 94ms/step - accuracy: 0.6004 - loss: 0.8814 - val_accuracy: 1.0000 - val_loss: 1.8682e-04\n",
      "Epoch 35/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 100ms/step - accuracy: 0.6221 - loss: 0.8352 - val_accuracy: 1.0000 - val_loss: 0.0033\n",
      "Epoch 36/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step - accuracy: 0.6175 - loss: 0.8620 - val_accuracy: 1.0000 - val_loss: 8.5809e-04\n",
      "Epoch 37/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 120ms/step - accuracy: 0.6083 - loss: 0.8709 - val_accuracy: 1.0000 - val_loss: 1.3456e-04\n",
      "Epoch 38/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 111ms/step - accuracy: 0.5378 - loss: 1.2486 - val_accuracy: 1.0000 - val_loss: 0.0518\n",
      "Epoch 39/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 93ms/step - accuracy: 0.5169 - loss: 1.1899 - val_accuracy: 1.0000 - val_loss: 0.0028\n",
      "Epoch 40/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 92ms/step - accuracy: 0.5659 - loss: 0.9995 - val_accuracy: 1.0000 - val_loss: 0.0015\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\n",
      "Training fold 3\n",
      "\n",
      "Generating upsampling and SMOTE...\n",
      "2640 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({np.int64(2): 240, np.int64(3): 240, np.int64(6): 240, np.int64(5): 240, np.int64(1): 240, np.int64(0): 240, np.int64(7): 240, np.int64(8): 240, np.int64(4): 240, np.int64(10): 240, np.int64(9): 240})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 110ms/step - accuracy: 0.5558 - loss: 1.1658 - val_accuracy: 1.0000 - val_loss: 0.0013\n",
      "Epoch 2/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 105ms/step - accuracy: 0.5735 - loss: 1.0133 - val_accuracy: 1.0000 - val_loss: 5.0531e-04\n",
      "Epoch 3/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 95ms/step - accuracy: 0.5631 - loss: 1.0184 - val_accuracy: 1.0000 - val_loss: 3.0869e-04\n",
      "Epoch 4/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.5962 - loss: 0.9036 - val_accuracy: 1.0000 - val_loss: 0.0040\n",
      "Epoch 5/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.5757 - loss: 0.9244 - val_accuracy: 1.0000 - val_loss: 2.3730e-04\n",
      "Epoch 6/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.5817 - loss: 0.8947 - val_accuracy: 1.0000 - val_loss: 0.0037\n",
      "Epoch 7/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.6123 - loss: 0.8533 - val_accuracy: 1.0000 - val_loss: 0.0085\n",
      "Epoch 8/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.5960 - loss: 0.8947 - val_accuracy: 1.0000 - val_loss: 0.0028\n",
      "Epoch 9/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.6119 - loss: 0.8537 - val_accuracy: 1.0000 - val_loss: 0.0039\n",
      "Epoch 10/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 90ms/step - accuracy: 0.5949 - loss: 0.8457 - val_accuracy: 1.0000 - val_loss: 0.0023\n",
      "Epoch 11/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.5985 - loss: 0.8554 - val_accuracy: 1.0000 - val_loss: 4.9360e-04\n",
      "Epoch 12/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 98ms/step - accuracy: 0.6066 - loss: 0.8427 - val_accuracy: 1.0000 - val_loss: 0.0037\n",
      "Epoch 13/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 88ms/step - accuracy: 0.6018 - loss: 0.8486 - val_accuracy: 1.0000 - val_loss: 0.0010\n",
      "Epoch 14/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.6155 - loss: 0.8584 - val_accuracy: 1.0000 - val_loss: 0.0010\n",
      "Epoch 15/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 88ms/step - accuracy: 0.6142 - loss: 0.8578 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
      "Epoch 16/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 92ms/step - accuracy: 0.6231 - loss: 0.8618 - val_accuracy: 1.0000 - val_loss: 0.0029\n",
      "Epoch 17/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 95ms/step - accuracy: 0.5983 - loss: 0.8718 - val_accuracy: 1.0000 - val_loss: 9.0948e-05\n",
      "Epoch 18/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 99ms/step - accuracy: 0.5731 - loss: 1.1124 - val_accuracy: 1.0000 - val_loss: 1.2480e-04\n",
      "Epoch 19/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 95ms/step - accuracy: 0.5467 - loss: 1.0568 - val_accuracy: 1.0000 - val_loss: 0.0025\n",
      "Epoch 20/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.6025 - loss: 0.8976 - val_accuracy: 1.0000 - val_loss: 0.0025\n",
      "Epoch 21/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 89ms/step - accuracy: 0.5945 - loss: 0.8839 - val_accuracy: 1.0000 - val_loss: 1.9134e-04\n",
      "Epoch 22/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 93ms/step - accuracy: 0.6143 - loss: 0.8604 - val_accuracy: 1.0000 - val_loss: 0.0015\n",
      "Epoch 23/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 93ms/step - accuracy: 0.6284 - loss: 0.8279 - val_accuracy: 1.0000 - val_loss: 6.2847e-04\n",
      "Epoch 24/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 120ms/step - accuracy: 0.6227 - loss: 0.8232 - val_accuracy: 1.0000 - val_loss: 2.9257e-04\n",
      "Epoch 25/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 109ms/step - accuracy: 0.6067 - loss: 0.8319 - val_accuracy: 1.0000 - val_loss: 0.0017\n",
      "Epoch 26/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 103ms/step - accuracy: 0.6285 - loss: 0.8089 - val_accuracy: 1.0000 - val_loss: 0.0018\n",
      "Epoch 27/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 96ms/step - accuracy: 0.6145 - loss: 0.8318 - val_accuracy: 1.0000 - val_loss: 2.7123e-04\n",
      "Epoch 28/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 100ms/step - accuracy: 0.6211 - loss: 0.8054 - val_accuracy: 1.0000 - val_loss: 6.5584e-05\n",
      "Epoch 29/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 99ms/step - accuracy: 0.6203 - loss: 0.8122 - val_accuracy: 1.0000 - val_loss: 0.0015\n",
      "Epoch 30/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 92ms/step - accuracy: 0.6213 - loss: 0.8347 - val_accuracy: 1.0000 - val_loss: 4.4101e-04\n",
      "Epoch 31/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 92ms/step - accuracy: 0.5702 - loss: 1.3761 - val_accuracy: 1.0000 - val_loss: 0.0059\n",
      "Epoch 32/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 106ms/step - accuracy: 0.5556 - loss: 1.0595 - val_accuracy: 1.0000 - val_loss: 0.0339\n",
      "Epoch 33/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 98ms/step - accuracy: 0.5890 - loss: 1.1023 - val_accuracy: 1.0000 - val_loss: 8.5097e-04\n",
      "Epoch 34/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 94ms/step - accuracy: 0.5748 - loss: 0.9736 - val_accuracy: 1.0000 - val_loss: 3.4937e-04\n",
      "Epoch 35/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 128ms/step - accuracy: 0.5916 - loss: 0.9072 - val_accuracy: 1.0000 - val_loss: 8.4521e-04\n",
      "Epoch 36/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 105ms/step - accuracy: 0.6193 - loss: 0.8911 - val_accuracy: 1.0000 - val_loss: 4.8425e-04\n",
      "Epoch 37/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 95ms/step - accuracy: 0.6156 - loss: 0.8792 - val_accuracy: 1.0000 - val_loss: 4.1136e-04\n",
      "Epoch 38/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 100ms/step - accuracy: 0.6206 - loss: 0.8557 - val_accuracy: 1.0000 - val_loss: 4.4108e-04\n",
      "Epoch 39/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 97ms/step - accuracy: 0.6272 - loss: 0.8553 - val_accuracy: 1.0000 - val_loss: 2.8560e-04\n",
      "Epoch 40/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 109ms/step - accuracy: 0.6100 - loss: 0.8893 - val_accuracy: 1.0000 - val_loss: 3.2914e-04\n",
      "Epoch 41/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 91ms/step - accuracy: 0.6052 - loss: 0.8783 - val_accuracy: 1.0000 - val_loss: 0.0036\n",
      "Epoch 42/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.6140 - loss: 0.8801 - val_accuracy: 1.0000 - val_loss: 4.1968e-04\n",
      "Epoch 43/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 93ms/step - accuracy: 0.6113 - loss: 0.8645 - val_accuracy: 1.0000 - val_loss: 0.0048\n",
      "Epoch 44/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.6118 - loss: 0.8986 - val_accuracy: 1.0000 - val_loss: 1.5135e-05\n",
      "Epoch 45/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.5753 - loss: 0.9788 - val_accuracy: 1.0000 - val_loss: 7.2219e-04\n",
      "Epoch 46/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.5826 - loss: 0.9431 - val_accuracy: 1.0000 - val_loss: 0.0025\n",
      "Epoch 47/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.5846 - loss: 0.9318 - val_accuracy: 1.0000 - val_loss: 0.0021\n",
      "Epoch 48/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 86ms/step - accuracy: 0.6166 - loss: 0.8889 - val_accuracy: 1.0000 - val_loss: 6.8162e-04\n",
      "Epoch 49/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.5911 - loss: 0.9178 - val_accuracy: 1.0000 - val_loss: 0.0021\n",
      "Epoch 50/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.6214 - loss: 0.8666 - val_accuracy: 1.0000 - val_loss: 0.0029\n",
      "Epoch 51/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 89ms/step - accuracy: 0.6113 - loss: 0.8890 - val_accuracy: 1.0000 - val_loss: 9.9432e-04\n",
      "Epoch 52/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 92ms/step - accuracy: 0.6226 - loss: 0.8540 - val_accuracy: 1.0000 - val_loss: 1.5247e-04\n",
      "Epoch 53/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 101ms/step - accuracy: 0.6387 - loss: 0.8947 - val_accuracy: 1.0000 - val_loss: 7.7710e-04\n",
      "Epoch 54/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 103ms/step - accuracy: 0.5293 - loss: 1.1906 - val_accuracy: 1.0000 - val_loss: 0.0026\n",
      "Epoch 55/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 97ms/step - accuracy: 0.5347 - loss: 1.1117 - val_accuracy: 1.0000 - val_loss: 2.7955e-04\n",
      "Epoch 56/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 100ms/step - accuracy: 0.5788 - loss: 0.9727 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
      "Epoch 57/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.5784 - loss: 0.9483 - val_accuracy: 1.0000 - val_loss: 0.0010\n",
      "Epoch 58/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.6304 - loss: 0.8983 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
      "Epoch 59/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 105ms/step - accuracy: 0.6406 - loss: 0.8702 - val_accuracy: 1.0000 - val_loss: 3.5326e-04\n",
      "Epoch 60/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 109ms/step - accuracy: 0.6397 - loss: 0.8527 - val_accuracy: 1.0000 - val_loss: 4.5588e-04\n",
      "Epoch 61/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 102ms/step - accuracy: 0.6394 - loss: 0.8801 - val_accuracy: 1.0000 - val_loss: 4.7543e-04\n",
      "Epoch 62/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 94ms/step - accuracy: 0.6313 - loss: 0.8790 - val_accuracy: 1.0000 - val_loss: 8.1795e-04\n",
      "Epoch 63/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 88ms/step - accuracy: 0.6248 - loss: 0.8710 - val_accuracy: 1.0000 - val_loss: 4.1703e-04\n",
      "Epoch 64/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.6167 - loss: 0.8962 - val_accuracy: 1.0000 - val_loss: 6.6480e-04\n",
      "Epoch 65/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 91ms/step - accuracy: 0.6201 - loss: 0.9392 - val_accuracy: 1.0000 - val_loss: 2.7328e-04\n",
      "Epoch 66/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.6002 - loss: 0.9872 - val_accuracy: 0.7778 - val_loss: 0.7325\n",
      "Epoch 67/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.5715 - loss: 1.0482 - val_accuracy: 1.0000 - val_loss: 2.6773e-05\n",
      "Epoch 68/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.6473 - loss: 0.9172 - val_accuracy: 1.0000 - val_loss: 0.0013\n",
      "Epoch 69/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 89ms/step - accuracy: 0.6383 - loss: 0.8835 - val_accuracy: 1.0000 - val_loss: 1.8977e-04\n",
      "Epoch 70/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.6544 - loss: 0.8538 - val_accuracy: 1.0000 - val_loss: 2.8571e-04\n",
      "Epoch 71/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.6546 - loss: 0.8315 - val_accuracy: 1.0000 - val_loss: 1.5144e-04\n",
      "Epoch 72/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.6522 - loss: 0.8407 - val_accuracy: 1.0000 - val_loss: 7.6039e-05\n",
      "Epoch 73/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 89ms/step - accuracy: 0.6585 - loss: 0.8199 - val_accuracy: 1.0000 - val_loss: 4.9708e-04\n",
      "Epoch 74/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.6474 - loss: 0.8304 - val_accuracy: 1.0000 - val_loss: 5.4782e-04\n",
      "Epoch 74: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\n",
      "Training fold 4\n",
      "\n",
      "Generating upsampling and SMOTE...\n",
      "2640 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({np.int64(2): 240, np.int64(3): 240, np.int64(6): 240, np.int64(5): 240, np.int64(1): 240, np.int64(0): 240, np.int64(7): 240, np.int64(8): 240, np.int64(4): 240, np.int64(10): 240, np.int64(9): 240})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 98ms/step - accuracy: 0.5534 - loss: 1.1238 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
      "Epoch 2/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 88ms/step - accuracy: 0.5735 - loss: 1.0234 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
      "Epoch 3/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.5940 - loss: 0.9135 - val_accuracy: 1.0000 - val_loss: 8.4639e-04\n",
      "Epoch 4/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.5970 - loss: 0.8809 - val_accuracy: 1.0000 - val_loss: 7.9743e-04\n",
      "Epoch 5/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 93ms/step - accuracy: 0.6049 - loss: 0.8888 - val_accuracy: 1.0000 - val_loss: 6.0446e-04\n",
      "Epoch 6/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 88ms/step - accuracy: 0.6405 - loss: 0.8235 - val_accuracy: 1.0000 - val_loss: 4.5034e-04\n",
      "Epoch 7/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.6243 - loss: 0.8364 - val_accuracy: 1.0000 - val_loss: 3.6762e-04\n",
      "Epoch 8/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.6249 - loss: 0.8465 - val_accuracy: 1.0000 - val_loss: 4.9513e-04\n",
      "Epoch 9/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.6200 - loss: 0.8618 - val_accuracy: 1.0000 - val_loss: 9.1638e-04\n",
      "Epoch 10/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.6145 - loss: 0.8426 - val_accuracy: 1.0000 - val_loss: 2.0098e-04\n",
      "Epoch 11/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.6480 - loss: 0.7978 - val_accuracy: 1.0000 - val_loss: 4.9702e-04\n",
      "Epoch 12/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 93ms/step - accuracy: 0.6565 - loss: 0.7967 - val_accuracy: 1.0000 - val_loss: 2.6928e-04\n",
      "Epoch 13/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 94ms/step - accuracy: 0.6212 - loss: 0.8336 - val_accuracy: 1.0000 - val_loss: 5.8428e-05\n",
      "Epoch 14/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 91ms/step - accuracy: 0.6026 - loss: 0.8968 - val_accuracy: 1.0000 - val_loss: 1.6525e-04\n",
      "Epoch 15/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.5514 - loss: 1.0308 - val_accuracy: 1.0000 - val_loss: 7.9805e-04\n",
      "Epoch 16/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 93ms/step - accuracy: 0.5818 - loss: 0.9805 - val_accuracy: 1.0000 - val_loss: 3.2701e-04\n",
      "Epoch 17/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.5915 - loss: 0.9173 - val_accuracy: 1.0000 - val_loss: 0.0015\n",
      "Epoch 18/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 97ms/step - accuracy: 0.6155 - loss: 0.9096 - val_accuracy: 1.0000 - val_loss: 6.6602e-04\n",
      "Epoch 19/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 91ms/step - accuracy: 0.6261 - loss: 0.8972 - val_accuracy: 1.0000 - val_loss: 1.1705e-04\n",
      "Epoch 20/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 91ms/step - accuracy: 0.6419 - loss: 0.8563 - val_accuracy: 1.0000 - val_loss: 5.1672e-04\n",
      "Epoch 21/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 89ms/step - accuracy: 0.6169 - loss: 0.8742 - val_accuracy: 1.0000 - val_loss: 2.7468e-04\n",
      "Epoch 22/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 92ms/step - accuracy: 0.6344 - loss: 0.8321 - val_accuracy: 1.0000 - val_loss: 0.0019\n",
      "Epoch 23/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 96ms/step - accuracy: 0.6122 - loss: 0.9477 - val_accuracy: 1.0000 - val_loss: 3.7589e-04\n",
      "Epoch 24/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 90ms/step - accuracy: 0.5839 - loss: 0.9623 - val_accuracy: 1.0000 - val_loss: 0.0020\n",
      "Epoch 25/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 90ms/step - accuracy: 0.5993 - loss: 0.9825 - val_accuracy: 1.0000 - val_loss: 0.0028\n",
      "Epoch 26/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 89ms/step - accuracy: 0.6007 - loss: 0.9307 - val_accuracy: 1.0000 - val_loss: 4.0401e-04\n",
      "Epoch 27/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.6134 - loss: 0.9095 - val_accuracy: 1.0000 - val_loss: 4.3727e-04\n",
      "Epoch 28/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.6331 - loss: 0.8487 - val_accuracy: 1.0000 - val_loss: 2.7463e-04\n",
      "Epoch 29/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.6322 - loss: 0.8654 - val_accuracy: 1.0000 - val_loss: 4.0917e-04\n",
      "Epoch 30/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 90ms/step - accuracy: 0.5940 - loss: 0.9057 - val_accuracy: 1.0000 - val_loss: 1.5075e-04\n",
      "Epoch 31/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.6168 - loss: 0.8963 - val_accuracy: 1.0000 - val_loss: 5.0332e-04\n",
      "Epoch 32/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.6026 - loss: 0.9402 - val_accuracy: 1.0000 - val_loss: 5.3443e-04\n",
      "Epoch 33/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.6121 - loss: 0.9106 - val_accuracy: 1.0000 - val_loss: 6.8165e-04\n",
      "Epoch 34/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 90ms/step - accuracy: 0.5640 - loss: 1.0527 - val_accuracy: 1.0000 - val_loss: 0.0045\n",
      "Epoch 35/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.5874 - loss: 0.9684 - val_accuracy: 1.0000 - val_loss: 0.0034\n",
      "Epoch 36/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.5765 - loss: 0.9934 - val_accuracy: 1.0000 - val_loss: 0.0020\n",
      "Epoch 37/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.6093 - loss: 0.9171 - val_accuracy: 1.0000 - val_loss: 3.8960e-04\n",
      "Epoch 38/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 89ms/step - accuracy: 0.6098 - loss: 0.8935 - val_accuracy: 1.0000 - val_loss: 3.8428e-04\n",
      "Epoch 39/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 92ms/step - accuracy: 0.6321 - loss: 0.8509 - val_accuracy: 1.0000 - val_loss: 0.0047\n",
      "Epoch 40/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.6279 - loss: 0.8543 - val_accuracy: 1.0000 - val_loss: 8.0210e-04\n",
      "Epoch 41/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 89ms/step - accuracy: 0.6262 - loss: 0.8499 - val_accuracy: 1.0000 - val_loss: 2.3410e-04\n",
      "Epoch 42/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 89ms/step - accuracy: 0.6055 - loss: 0.8856 - val_accuracy: 1.0000 - val_loss: 2.3184e-04\n",
      "Epoch 43/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.6378 - loss: 0.8428 - val_accuracy: 1.0000 - val_loss: 2.8936e-04\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\n",
      "Training fold 5\n",
      "\n",
      "Generating upsampling and SMOTE...\n",
      "2640 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({np.int64(2): 240, np.int64(3): 240, np.int64(6): 240, np.int64(5): 240, np.int64(1): 240, np.int64(0): 240, np.int64(7): 240, np.int64(8): 240, np.int64(4): 240, np.int64(10): 240, np.int64(9): 240})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 99ms/step - accuracy: 0.5795 - loss: 0.9935 - val_accuracy: 1.0000 - val_loss: 0.0101\n",
      "Epoch 2/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 101ms/step - accuracy: 0.5428 - loss: 1.1320 - val_accuracy: 1.0000 - val_loss: 2.9200e-04\n",
      "Epoch 3/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 97ms/step - accuracy: 0.5837 - loss: 0.9133 - val_accuracy: 1.0000 - val_loss: 4.3860e-04\n",
      "Epoch 4/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 101ms/step - accuracy: 0.5983 - loss: 0.8708 - val_accuracy: 1.0000 - val_loss: 0.0032\n",
      "Epoch 5/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 98ms/step - accuracy: 0.5976 - loss: 0.8736 - val_accuracy: 1.0000 - val_loss: 5.3966e-04\n",
      "Epoch 6/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 107ms/step - accuracy: 0.6197 - loss: 0.8342 - val_accuracy: 1.0000 - val_loss: 3.8647e-04\n",
      "Epoch 7/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 90ms/step - accuracy: 0.6122 - loss: 0.8583 - val_accuracy: 1.0000 - val_loss: 4.9276e-04\n",
      "Epoch 8/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.6188 - loss: 0.8515 - val_accuracy: 1.0000 - val_loss: 2.0306e-04\n",
      "Epoch 9/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 88ms/step - accuracy: 0.6143 - loss: 0.8346 - val_accuracy: 1.0000 - val_loss: 2.3933e-04\n",
      "Epoch 10/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.6009 - loss: 0.9120 - val_accuracy: 1.0000 - val_loss: 3.9304e-04\n",
      "Epoch 11/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.5970 - loss: 0.9387 - val_accuracy: 1.0000 - val_loss: 2.9738e-04\n",
      "Epoch 12/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 90ms/step - accuracy: 0.6046 - loss: 0.9210 - val_accuracy: 1.0000 - val_loss: 4.8043e-04\n",
      "Epoch 13/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 97ms/step - accuracy: 0.5706 - loss: 1.0260 - val_accuracy: 1.0000 - val_loss: 0.0294\n",
      "Epoch 14/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 90ms/step - accuracy: 0.5786 - loss: 1.0485 - val_accuracy: 1.0000 - val_loss: 1.0278e-04\n",
      "Epoch 15/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 103ms/step - accuracy: 0.5663 - loss: 1.0105 - val_accuracy: 1.0000 - val_loss: 2.0508e-04\n",
      "Epoch 16/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 99ms/step - accuracy: 0.6039 - loss: 0.9358 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
      "Epoch 17/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 99ms/step - accuracy: 0.5944 - loss: 0.9459 - val_accuracy: 1.0000 - val_loss: 6.3059e-04\n",
      "Epoch 18/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 100ms/step - accuracy: 0.6025 - loss: 0.9107 - val_accuracy: 1.0000 - val_loss: 0.0018\n",
      "Epoch 19/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 109ms/step - accuracy: 0.5994 - loss: 0.8995 - val_accuracy: 1.0000 - val_loss: 3.2683e-04\n",
      "Epoch 20/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 103ms/step - accuracy: 0.6443 - loss: 0.8227 - val_accuracy: 1.0000 - val_loss: 1.7099e-04\n",
      "Epoch 21/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 89ms/step - accuracy: 0.6261 - loss: 0.8383 - val_accuracy: 1.0000 - val_loss: 2.6183e-04\n",
      "Epoch 22/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 91ms/step - accuracy: 0.6172 - loss: 0.8466 - val_accuracy: 1.0000 - val_loss: 0.0371\n",
      "Epoch 23/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.6017 - loss: 0.9013 - val_accuracy: 1.0000 - val_loss: 1.0567e-04\n",
      "Epoch 24/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 89ms/step - accuracy: 0.6113 - loss: 0.8792 - val_accuracy: 1.0000 - val_loss: 0.0015\n",
      "Epoch 25/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 92ms/step - accuracy: 0.5972 - loss: 0.8820 - val_accuracy: 1.0000 - val_loss: 5.3093e-04\n",
      "Epoch 26/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 90ms/step - accuracy: 0.6141 - loss: 0.8271 - val_accuracy: 1.0000 - val_loss: 5.7942e-04\n",
      "Epoch 27/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 91ms/step - accuracy: 0.6326 - loss: 0.7981 - val_accuracy: 1.0000 - val_loss: 7.6431e-04\n",
      "Epoch 28/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 90ms/step - accuracy: 0.6269 - loss: 0.8068 - val_accuracy: 1.0000 - val_loss: 3.7891e-04\n",
      "Epoch 29/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 95ms/step - accuracy: 0.6129 - loss: 0.8111 - val_accuracy: 1.0000 - val_loss: 6.7440e-04\n",
      "Epoch 30/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 89ms/step - accuracy: 0.6239 - loss: 0.8126 - val_accuracy: 1.0000 - val_loss: 2.7136e-04\n",
      "Epoch 31/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 92ms/step - accuracy: 0.6386 - loss: 0.7827 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
      "Epoch 32/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 101ms/step - accuracy: 0.6143 - loss: 0.8190 - val_accuracy: 1.0000 - val_loss: 2.3197e-04\n",
      "Epoch 33/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 95ms/step - accuracy: 0.6130 - loss: 0.8305 - val_accuracy: 1.0000 - val_loss: 3.8175e-04\n",
      "Epoch 34/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 103ms/step - accuracy: 0.6233 - loss: 0.7776 - val_accuracy: 1.0000 - val_loss: 9.2675e-04\n",
      "Epoch 35/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 103ms/step - accuracy: 0.6280 - loss: 0.7924 - val_accuracy: 1.0000 - val_loss: 5.6729e-04\n",
      "Epoch 36/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 108ms/step - accuracy: 0.6395 - loss: 0.7916 - val_accuracy: 1.0000 - val_loss: 6.3910e-04\n",
      "Epoch 37/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 101ms/step - accuracy: 0.6319 - loss: 0.7924 - val_accuracy: 1.0000 - val_loss: 3.0573e-04\n",
      "Epoch 38/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 91ms/step - accuracy: 0.6215 - loss: 0.7887 - val_accuracy: 1.0000 - val_loss: 0.0026\n",
      "Epoch 39/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 89ms/step - accuracy: 0.6228 - loss: 0.8024 - val_accuracy: 1.0000 - val_loss: 2.7571e-04\n",
      "Epoch 40/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.6312 - loss: 0.7912 - val_accuracy: 1.0000 - val_loss: 3.0261e-04\n",
      "Epoch 41/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.6222 - loss: 0.8102 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
      "Epoch 42/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.6189 - loss: 0.8555 - val_accuracy: 1.0000 - val_loss: 0.0032\n",
      "Epoch 43/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 89ms/step - accuracy: 0.6062 - loss: 0.8370 - val_accuracy: 1.0000 - val_loss: 2.9579e-04\n",
      "Epoch 44/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.6163 - loss: 0.8539 - val_accuracy: 1.0000 - val_loss: 6.1746e-04\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
      "\n",
      "Training fold 6\n",
      "\n",
      "Generating upsampling and SMOTE...\n",
      "2640 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({np.int64(2): 240, np.int64(3): 240, np.int64(6): 240, np.int64(5): 240, np.int64(1): 240, np.int64(0): 240, np.int64(7): 240, np.int64(8): 240, np.int64(4): 240, np.int64(10): 240, np.int64(9): 240})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 92ms/step - accuracy: 0.5255 - loss: 1.1158 - val_accuracy: 1.0000 - val_loss: 0.0449\n",
      "Epoch 2/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.5338 - loss: 1.1138 - val_accuracy: 1.0000 - val_loss: 5.4942e-04\n",
      "Epoch 3/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 93ms/step - accuracy: 0.6120 - loss: 0.9298 - val_accuracy: 1.0000 - val_loss: 5.1767e-04\n",
      "Epoch 4/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 99ms/step - accuracy: 0.6313 - loss: 0.8701 - val_accuracy: 1.0000 - val_loss: 2.9077e-04\n",
      "Epoch 5/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 92ms/step - accuracy: 0.6471 - loss: 0.8254 - val_accuracy: 1.0000 - val_loss: 2.6062e-04\n",
      "Epoch 6/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 88ms/step - accuracy: 0.6386 - loss: 0.8572 - val_accuracy: 1.0000 - val_loss: 0.0027\n",
      "Epoch 7/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 91ms/step - accuracy: 0.6341 - loss: 0.8437 - val_accuracy: 1.0000 - val_loss: 6.9914e-04\n",
      "Epoch 8/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 91ms/step - accuracy: 0.6485 - loss: 0.8202 - val_accuracy: 1.0000 - val_loss: 4.0634e-04\n",
      "Epoch 9/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 91ms/step - accuracy: 0.6573 - loss: 0.7809 - val_accuracy: 1.0000 - val_loss: 3.4797e-04\n",
      "Epoch 10/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 89ms/step - accuracy: 0.6723 - loss: 0.7701 - val_accuracy: 1.0000 - val_loss: 2.5324e-04\n",
      "Epoch 11/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 101ms/step - accuracy: 0.6668 - loss: 0.7795 - val_accuracy: 1.0000 - val_loss: 3.0743e-04\n",
      "Epoch 12/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 93ms/step - accuracy: 0.6754 - loss: 0.7573 - val_accuracy: 1.0000 - val_loss: 4.5702e-04\n",
      "Epoch 13/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.6582 - loss: 0.7841 - val_accuracy: 1.0000 - val_loss: 2.5923e-04\n",
      "Epoch 14/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 89ms/step - accuracy: 0.6523 - loss: 0.7648 - val_accuracy: 1.0000 - val_loss: 5.0293e-04\n",
      "Epoch 15/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 88ms/step - accuracy: 0.6631 - loss: 0.7646 - val_accuracy: 1.0000 - val_loss: 2.0427e-04\n",
      "Epoch 16/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.6494 - loss: 0.7603 - val_accuracy: 1.0000 - val_loss: 3.3526e-04\n",
      "Epoch 17/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.6639 - loss: 0.7544 - val_accuracy: 1.0000 - val_loss: 5.8500e-04\n",
      "Epoch 18/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 91ms/step - accuracy: 0.6649 - loss: 0.7461 - val_accuracy: 1.0000 - val_loss: 5.7881e-04\n",
      "Epoch 19/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 97ms/step - accuracy: 0.6729 - loss: 0.7312 - val_accuracy: 1.0000 - val_loss: 3.0404e-04\n",
      "Epoch 20/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.6560 - loss: 0.7696 - val_accuracy: 1.0000 - val_loss: 2.1387e-05\n",
      "Epoch 21/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.6096 - loss: 0.9265 - val_accuracy: 1.0000 - val_loss: 7.9010e-04\n",
      "Epoch 22/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 92ms/step - accuracy: 0.6163 - loss: 0.9005 - val_accuracy: 1.0000 - val_loss: 6.0970e-04\n",
      "Epoch 23/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.6230 - loss: 0.9229 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
      "Epoch 24/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.6601 - loss: 0.8063 - val_accuracy: 1.0000 - val_loss: 4.1829e-04\n",
      "Epoch 25/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.6523 - loss: 0.7774 - val_accuracy: 1.0000 - val_loss: 7.6585e-04\n",
      "Epoch 26/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 93ms/step - accuracy: 0.6812 - loss: 0.7687 - val_accuracy: 1.0000 - val_loss: 4.4102e-04\n",
      "Epoch 27/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 94ms/step - accuracy: 0.6853 - loss: 0.7377 - val_accuracy: 1.0000 - val_loss: 3.5502e-04\n",
      "Epoch 28/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 106ms/step - accuracy: 0.6722 - loss: 0.7441 - val_accuracy: 1.0000 - val_loss: 2.7552e-04\n",
      "Epoch 29/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 93ms/step - accuracy: 0.6765 - loss: 0.7453 - val_accuracy: 1.0000 - val_loss: 3.7088e-04\n",
      "Epoch 30/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.6553 - loss: 0.7584 - val_accuracy: 1.0000 - val_loss: 2.0952e-04\n",
      "Epoch 31/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 91ms/step - accuracy: 0.6711 - loss: 0.7673 - val_accuracy: 1.0000 - val_loss: 2.2730e-04\n",
      "Epoch 32/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 89ms/step - accuracy: 0.6733 - loss: 0.7432 - val_accuracy: 1.0000 - val_loss: 2.3052e-04\n",
      "Epoch 33/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 93ms/step - accuracy: 0.6688 - loss: 0.7578 - val_accuracy: 1.0000 - val_loss: 3.0571e-04\n",
      "Epoch 34/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 89ms/step - accuracy: 0.6690 - loss: 0.7563 - val_accuracy: 1.0000 - val_loss: 2.4219e-04\n",
      "Epoch 35/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 90ms/step - accuracy: 0.6688 - loss: 0.7467 - val_accuracy: 1.0000 - val_loss: 2.4158e-04\n",
      "Epoch 36/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 95ms/step - accuracy: 0.6904 - loss: 0.6924 - val_accuracy: 1.0000 - val_loss: 2.0746e-04\n",
      "Epoch 37/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 92ms/step - accuracy: 0.6692 - loss: 0.7561 - val_accuracy: 1.0000 - val_loss: 2.0882e-04\n",
      "Epoch 38/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 91ms/step - accuracy: 0.6579 - loss: 0.7544 - val_accuracy: 1.0000 - val_loss: 3.7519e-04\n",
      "Epoch 39/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 90ms/step - accuracy: 0.6584 - loss: 0.7370 - val_accuracy: 1.0000 - val_loss: 1.3606e-04\n",
      "Epoch 40/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.6616 - loss: 0.7638 - val_accuracy: 1.0000 - val_loss: 6.5201e-04\n",
      "Epoch 41/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.6694 - loss: 0.7594 - val_accuracy: 1.0000 - val_loss: 4.5021e-04\n",
      "Epoch 42/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.6771 - loss: 0.7540 - val_accuracy: 1.0000 - val_loss: 2.6553e-04\n",
      "Epoch 43/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.6702 - loss: 0.7472 - val_accuracy: 1.0000 - val_loss: 2.0182e-04\n",
      "Epoch 44/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.6640 - loss: 0.7609 - val_accuracy: 1.0000 - val_loss: 2.6789e-04\n",
      "Epoch 45/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 103ms/step - accuracy: 0.6889 - loss: 0.7208 - val_accuracy: 1.0000 - val_loss: 5.5157e-04\n",
      "Epoch 46/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 94ms/step - accuracy: 0.6832 - loss: 0.7143 - val_accuracy: 1.0000 - val_loss: 2.0741e-04\n",
      "Epoch 47/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 90ms/step - accuracy: 0.6625 - loss: 0.7722 - val_accuracy: 1.0000 - val_loss: 2.5021e-04\n",
      "Epoch 48/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.6738 - loss: 0.7165 - val_accuracy: 1.0000 - val_loss: 0.0095\n",
      "Epoch 49/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.5670 - loss: 1.2299 - val_accuracy: 1.0000 - val_loss: 2.7338e-05\n",
      "Epoch 50/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.5809 - loss: 1.0455 - val_accuracy: 1.0000 - val_loss: 1.1995e-04\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\n",
      "Training fold 7\n",
      "\n",
      "Generating upsampling and SMOTE...\n",
      "2640 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({np.int64(2): 240, np.int64(3): 240, np.int64(6): 240, np.int64(5): 240, np.int64(1): 240, np.int64(0): 240, np.int64(7): 240, np.int64(8): 240, np.int64(4): 240, np.int64(10): 240, np.int64(9): 240})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 104ms/step - accuracy: 0.5552 - loss: 1.1679 - val_accuracy: 1.0000 - val_loss: 1.6213e-04\n",
      "Epoch 2/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 107ms/step - accuracy: 0.6227 - loss: 0.9293 - val_accuracy: 1.0000 - val_loss: 0.0031\n",
      "Epoch 3/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 89ms/step - accuracy: 0.6444 - loss: 0.8354 - val_accuracy: 1.0000 - val_loss: 8.9189e-04\n",
      "Epoch 4/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 96ms/step - accuracy: 0.6309 - loss: 0.8590 - val_accuracy: 1.0000 - val_loss: 0.0027\n",
      "Epoch 5/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 91ms/step - accuracy: 0.6614 - loss: 0.7687 - val_accuracy: 1.0000 - val_loss: 7.3985e-04\n",
      "Epoch 6/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 97ms/step - accuracy: 0.6604 - loss: 0.7829 - val_accuracy: 1.0000 - val_loss: 8.8841e-04\n",
      "Epoch 7/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 89ms/step - accuracy: 0.6721 - loss: 0.7392 - val_accuracy: 1.0000 - val_loss: 4.4203e-04\n",
      "Epoch 8/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 94ms/step - accuracy: 0.6753 - loss: 0.7322 - val_accuracy: 1.0000 - val_loss: 3.3468e-04\n",
      "Epoch 9/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 104ms/step - accuracy: 0.6703 - loss: 0.7454 - val_accuracy: 1.0000 - val_loss: 2.4291e-04\n",
      "Epoch 10/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 88ms/step - accuracy: 0.6590 - loss: 0.7573 - val_accuracy: 1.0000 - val_loss: 3.7190e-04\n",
      "Epoch 11/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.6629 - loss: 0.7487 - val_accuracy: 1.0000 - val_loss: 4.1479e-04\n",
      "Epoch 12/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.6694 - loss: 0.7419 - val_accuracy: 1.0000 - val_loss: 5.5533e-04\n",
      "Epoch 13/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.6496 - loss: 0.7889 - val_accuracy: 1.0000 - val_loss: 1.3031e-04\n",
      "Epoch 14/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.6677 - loss: 0.7523 - val_accuracy: 1.0000 - val_loss: 2.6833e-04\n",
      "Epoch 15/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 90ms/step - accuracy: 0.6561 - loss: 0.7496 - val_accuracy: 1.0000 - val_loss: 6.3038e-04\n",
      "Epoch 16/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.6630 - loss: 0.7493 - val_accuracy: 1.0000 - val_loss: 3.9351e-04\n",
      "Epoch 17/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.6787 - loss: 0.7332 - val_accuracy: 1.0000 - val_loss: 4.4286e-04\n",
      "Epoch 18/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.6598 - loss: 0.7533 - val_accuracy: 1.0000 - val_loss: 3.4981e-04\n",
      "Epoch 19/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 94ms/step - accuracy: 0.6767 - loss: 0.7318 - val_accuracy: 1.0000 - val_loss: 1.3670e-04\n",
      "Epoch 20/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.6579 - loss: 0.7451 - val_accuracy: 1.0000 - val_loss: 0.0013\n",
      "Epoch 21/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.6510 - loss: 0.7660 - val_accuracy: 1.0000 - val_loss: 8.0675e-04\n",
      "Epoch 22/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.6682 - loss: 0.7404 - val_accuracy: 1.0000 - val_loss: 4.2741e-05\n",
      "Epoch 23/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.6711 - loss: 0.7454 - val_accuracy: 1.0000 - val_loss: 7.0629e-05\n",
      "Epoch 24/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 94ms/step - accuracy: 0.6807 - loss: 0.7697 - val_accuracy: 0.9259 - val_loss: 0.3406\n",
      "Epoch 25/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.5651 - loss: 1.1033 - val_accuracy: 1.0000 - val_loss: 8.5697e-04\n",
      "Epoch 26/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 93ms/step - accuracy: 0.6238 - loss: 0.9618 - val_accuracy: 1.0000 - val_loss: 0.0537\n",
      "Epoch 27/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 89ms/step - accuracy: 0.6618 - loss: 0.8481 - val_accuracy: 1.0000 - val_loss: 0.0110\n",
      "Epoch 28/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 107ms/step - accuracy: 0.6416 - loss: 0.8325 - val_accuracy: 1.0000 - val_loss: 0.0030\n",
      "Epoch 29/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 101ms/step - accuracy: 0.6532 - loss: 0.8123 - val_accuracy: 1.0000 - val_loss: 0.0014\n",
      "Epoch 30/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 99ms/step - accuracy: 0.6629 - loss: 0.7886 - val_accuracy: 1.0000 - val_loss: 6.2913e-04\n",
      "Epoch 31/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 107ms/step - accuracy: 0.6498 - loss: 0.7923 - val_accuracy: 1.0000 - val_loss: 3.3897e-04\n",
      "Epoch 32/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 93ms/step - accuracy: 0.6734 - loss: 0.7375 - val_accuracy: 1.0000 - val_loss: 3.1498e-04\n",
      "Epoch 33/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 97ms/step - accuracy: 0.6630 - loss: 0.7696 - val_accuracy: 1.0000 - val_loss: 2.6722e-04\n",
      "Epoch 34/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 90ms/step - accuracy: 0.6517 - loss: 0.7927 - val_accuracy: 1.0000 - val_loss: 2.2368e-04\n",
      "Epoch 35/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 98ms/step - accuracy: 0.6413 - loss: 0.7980 - val_accuracy: 1.0000 - val_loss: 1.9347e-04\n",
      "Epoch 36/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 96ms/step - accuracy: 0.6532 - loss: 0.7805 - val_accuracy: 1.0000 - val_loss: 1.8199e-04\n",
      "Epoch 37/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 96ms/step - accuracy: 0.6455 - loss: 0.7880 - val_accuracy: 1.0000 - val_loss: 3.8233e-04\n",
      "Epoch 38/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 89ms/step - accuracy: 0.6686 - loss: 0.7618 - val_accuracy: 1.0000 - val_loss: 2.8676e-04\n",
      "Epoch 39/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 93ms/step - accuracy: 0.6473 - loss: 0.7848 - val_accuracy: 1.0000 - val_loss: 1.7797e-04\n",
      "Epoch 40/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 92ms/step - accuracy: 0.6797 - loss: 0.7572 - val_accuracy: 1.0000 - val_loss: 2.6285e-04\n",
      "Epoch 41/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.6722 - loss: 0.7506 - val_accuracy: 1.0000 - val_loss: 1.7879e-04\n",
      "Epoch 42/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 93ms/step - accuracy: 0.6585 - loss: 0.7737 - val_accuracy: 1.0000 - val_loss: 1.7739e-04\n",
      "Epoch 43/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.6433 - loss: 0.7779 - val_accuracy: 1.0000 - val_loss: 2.1360e-04\n",
      "Epoch 44/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.6830 - loss: 0.7364 - val_accuracy: 1.0000 - val_loss: 1.7661e-04\n",
      "Epoch 45/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.6696 - loss: 0.7685 - val_accuracy: 1.0000 - val_loss: 0.0021\n",
      "Epoch 46/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.6337 - loss: 0.8605 - val_accuracy: 1.0000 - val_loss: 3.2191e-04\n",
      "Epoch 47/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 90ms/step - accuracy: 0.6388 - loss: 0.8472 - val_accuracy: 1.0000 - val_loss: 0.0013\n",
      "Epoch 48/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 110ms/step - accuracy: 0.5793 - loss: 1.1231 - val_accuracy: 1.0000 - val_loss: 3.6159e-04\n",
      "Epoch 49/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 99ms/step - accuracy: 0.6231 - loss: 0.9782 - val_accuracy: 1.0000 - val_loss: 5.3271e-04\n",
      "Epoch 50/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.6445 - loss: 0.8470 - val_accuracy: 1.0000 - val_loss: 0.0024\n",
      "Epoch 51/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 90ms/step - accuracy: 0.6556 - loss: 0.8220 - val_accuracy: 1.0000 - val_loss: 4.7873e-04\n",
      "Epoch 52/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 107ms/step - accuracy: 0.6579 - loss: 0.7944 - val_accuracy: 1.0000 - val_loss: 4.0528e-04\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\n",
      "Training fold 8\n",
      "\n",
      "Generating upsampling and SMOTE...\n",
      "2640 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({np.int64(3): 240, np.int64(4): 240, np.int64(0): 240, np.int64(6): 240, np.int64(7): 240, np.int64(5): 240, np.int64(1): 240, np.int64(2): 240, np.int64(8): 240, np.int64(10): 240, np.int64(9): 240})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 92ms/step - accuracy: 0.6186 - loss: 0.9143 - val_accuracy: 1.0000 - val_loss: 8.4359e-04\n",
      "Epoch 2/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.6518 - loss: 0.8658 - val_accuracy: 1.0000 - val_loss: 0.0015\n",
      "Epoch 3/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.6433 - loss: 0.9156 - val_accuracy: 1.0000 - val_loss: 8.6063e-04\n",
      "Epoch 4/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 90ms/step - accuracy: 0.6136 - loss: 1.2227 - val_accuracy: 1.0000 - val_loss: 0.0021\n",
      "Epoch 5/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 88ms/step - accuracy: 0.6619 - loss: 0.8487 - val_accuracy: 1.0000 - val_loss: 0.0018\n",
      "Epoch 6/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.6598 - loss: 0.7889 - val_accuracy: 1.0000 - val_loss: 0.0265\n",
      "Epoch 7/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.6671 - loss: 0.7845 - val_accuracy: 1.0000 - val_loss: 0.0045\n",
      "Epoch 8/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.6741 - loss: 0.7480 - val_accuracy: 1.0000 - val_loss: 0.0017\n",
      "Epoch 9/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.6688 - loss: 0.7367 - val_accuracy: 1.0000 - val_loss: 0.0025\n",
      "Epoch 10/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.6719 - loss: 0.7092 - val_accuracy: 1.0000 - val_loss: 0.0021\n",
      "Epoch 11/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.6729 - loss: 0.7018 - val_accuracy: 1.0000 - val_loss: 0.0017\n",
      "Epoch 12/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.6917 - loss: 0.6784 - val_accuracy: 1.0000 - val_loss: 9.9946e-04\n",
      "Epoch 13/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.6972 - loss: 0.6579 - val_accuracy: 1.0000 - val_loss: 0.0031\n",
      "Epoch 14/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.6824 - loss: 0.7004 - val_accuracy: 1.0000 - val_loss: 0.0019\n",
      "Epoch 15/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 89ms/step - accuracy: 0.6945 - loss: 0.6764 - val_accuracy: 1.0000 - val_loss: 8.4097e-04\n",
      "Epoch 16/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 88ms/step - accuracy: 0.6854 - loss: 0.6640 - val_accuracy: 1.0000 - val_loss: 8.2609e-04\n",
      "Epoch 17/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.6952 - loss: 0.6636 - val_accuracy: 1.0000 - val_loss: 2.4140e-04\n",
      "Epoch 18/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.6863 - loss: 0.6920 - val_accuracy: 1.0000 - val_loss: 2.8297e-04\n",
      "Epoch 19/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.6814 - loss: 0.6654 - val_accuracy: 1.0000 - val_loss: 5.6685e-04\n",
      "Epoch 20/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 88ms/step - accuracy: 0.6885 - loss: 0.6782 - val_accuracy: 1.0000 - val_loss: 2.7931e-04\n",
      "Epoch 21/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 90ms/step - accuracy: 0.6889 - loss: 0.6656 - val_accuracy: 1.0000 - val_loss: 0.0017\n",
      "Epoch 22/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 96ms/step - accuracy: 0.6959 - loss: 0.6717 - val_accuracy: 1.0000 - val_loss: 1.2804e-07\n",
      "Epoch 23/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 88ms/step - accuracy: 0.6396 - loss: 0.9272 - val_accuracy: 1.0000 - val_loss: 1.1887e-04\n",
      "Epoch 24/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.6449 - loss: 0.8264 - val_accuracy: 1.0000 - val_loss: 9.1146e-04\n",
      "Epoch 25/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.6694 - loss: 0.7487 - val_accuracy: 1.0000 - val_loss: 0.0019\n",
      "Epoch 26/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 92ms/step - accuracy: 0.6733 - loss: 0.7238 - val_accuracy: 1.0000 - val_loss: 8.5667e-04\n",
      "Epoch 27/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.6762 - loss: 0.6986 - val_accuracy: 1.0000 - val_loss: 5.2977e-04\n",
      "Epoch 28/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.6939 - loss: 0.6881 - val_accuracy: 1.0000 - val_loss: 3.7315e-04\n",
      "Epoch 29/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.6905 - loss: 0.7021 - val_accuracy: 1.0000 - val_loss: 3.4847e-04\n",
      "Epoch 30/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 89ms/step - accuracy: 0.6919 - loss: 0.6821 - val_accuracy: 1.0000 - val_loss: 3.4640e-04\n",
      "Epoch 31/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.6772 - loss: 0.6948 - val_accuracy: 1.0000 - val_loss: 1.3903e-04\n",
      "Epoch 32/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.6828 - loss: 0.6924 - val_accuracy: 1.0000 - val_loss: 5.0621e-04\n",
      "Epoch 33/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.6994 - loss: 0.6767 - val_accuracy: 1.0000 - val_loss: 2.0689e-04\n",
      "Epoch 34/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.6764 - loss: 0.6857 - val_accuracy: 1.0000 - val_loss: 1.3680e-04\n",
      "Epoch 35/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.6844 - loss: 0.6749 - val_accuracy: 1.0000 - val_loss: 9.7899e-05\n",
      "Epoch 36/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.6763 - loss: 0.6976 - val_accuracy: 1.0000 - val_loss: 1.0267e-04\n",
      "Epoch 37/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 89ms/step - accuracy: 0.6707 - loss: 0.7403 - val_accuracy: 1.0000 - val_loss: 5.0718e-04\n",
      "Epoch 38/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.6365 - loss: 0.8397 - val_accuracy: 1.0000 - val_loss: 0.0176\n",
      "Epoch 39/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.6374 - loss: 0.8226 - val_accuracy: 1.0000 - val_loss: 0.0202\n",
      "Epoch 40/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.6283 - loss: 0.8829 - val_accuracy: 1.0000 - val_loss: 5.9497e-05\n",
      "Epoch 41/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 90ms/step - accuracy: 0.6632 - loss: 0.7710 - val_accuracy: 1.0000 - val_loss: 7.6013e-05\n",
      "Epoch 42/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.6877 - loss: 0.7313 - val_accuracy: 1.0000 - val_loss: 6.9209e-05\n",
      "Epoch 43/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.6513 - loss: 0.7750 - val_accuracy: 1.0000 - val_loss: 8.1168e-05\n",
      "Epoch 44/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.6625 - loss: 0.7513 - val_accuracy: 1.0000 - val_loss: 1.9484e-04\n",
      "Epoch 45/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 94ms/step - accuracy: 0.6630 - loss: 0.7828 - val_accuracy: 1.0000 - val_loss: 1.5275e-04\n",
      "Epoch 46/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.6700 - loss: 0.7589 - val_accuracy: 1.0000 - val_loss: 2.5346e-04\n",
      "Epoch 47/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 99ms/step - accuracy: 0.6813 - loss: 0.7369 - val_accuracy: 1.0000 - val_loss: 1.2402e-04\n",
      "Epoch 48/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 88ms/step - accuracy: 0.6668 - loss: 0.7458 - val_accuracy: 1.0000 - val_loss: 2.7214e-04\n",
      "Epoch 49/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 89ms/step - accuracy: 0.6574 - loss: 0.7730 - val_accuracy: 1.0000 - val_loss: 1.3137e-04\n",
      "Epoch 50/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.6715 - loss: 0.7514 - val_accuracy: 1.0000 - val_loss: 3.5462e-05\n",
      "Epoch 51/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.6618 - loss: 0.7561 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
      "Epoch 52/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 89ms/step - accuracy: 0.6481 - loss: 0.8173 - val_accuracy: 1.0000 - val_loss: 8.4373e-06\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\n",
      "Training fold 9\n",
      "\n",
      "Generating upsampling and SMOTE...\n",
      "2640 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({np.int64(3): 240, np.int64(4): 240, np.int64(0): 240, np.int64(6): 240, np.int64(7): 240, np.int64(9): 240, np.int64(5): 240, np.int64(1): 240, np.int64(2): 240, np.int64(8): 240, np.int64(10): 240})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 107ms/step - accuracy: 0.6132 - loss: 0.9540 - val_accuracy: 1.0000 - val_loss: 0.0042\n",
      "Epoch 2/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 109ms/step - accuracy: 0.6613 - loss: 0.7883 - val_accuracy: 1.0000 - val_loss: 6.3158e-04\n",
      "Epoch 3/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 100ms/step - accuracy: 0.6559 - loss: 0.8217 - val_accuracy: 1.0000 - val_loss: 2.8155e-04\n",
      "Epoch 4/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 99ms/step - accuracy: 0.6624 - loss: 0.7838 - val_accuracy: 1.0000 - val_loss: 1.7683e-04\n",
      "Epoch 5/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 89ms/step - accuracy: 0.6659 - loss: 0.7535 - val_accuracy: 1.0000 - val_loss: 3.0406e-04\n",
      "Epoch 6/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 91ms/step - accuracy: 0.6817 - loss: 0.7114 - val_accuracy: 1.0000 - val_loss: 6.8643e-04\n",
      "Epoch 7/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 108ms/step - accuracy: 0.6975 - loss: 0.6748 - val_accuracy: 1.0000 - val_loss: 5.1284e-04\n",
      "Epoch 8/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 108ms/step - accuracy: 0.6966 - loss: 0.6948 - val_accuracy: 1.0000 - val_loss: 3.5794e-04\n",
      "Epoch 9/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 101ms/step - accuracy: 0.7063 - loss: 0.6732 - val_accuracy: 1.0000 - val_loss: 3.8135e-04\n",
      "Epoch 10/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.7083 - loss: 0.6636 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
      "Epoch 11/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 83ms/step - accuracy: 0.7105 - loss: 0.6677 - val_accuracy: 1.0000 - val_loss: 4.2594e-04\n",
      "Epoch 12/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.6992 - loss: 0.6558 - val_accuracy: 1.0000 - val_loss: 1.7479e-04\n",
      "Epoch 13/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.6889 - loss: 0.6666 - val_accuracy: 1.0000 - val_loss: 7.0608e-04\n",
      "Epoch 14/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 91ms/step - accuracy: 0.7016 - loss: 0.6510 - val_accuracy: 1.0000 - val_loss: 6.3003e-04\n",
      "Epoch 15/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 99ms/step - accuracy: 0.6998 - loss: 0.6580 - val_accuracy: 1.0000 - val_loss: 4.1042e-04\n",
      "Epoch 16/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 93ms/step - accuracy: 0.7012 - loss: 0.6687 - val_accuracy: 1.0000 - val_loss: 2.1964e-04\n",
      "Epoch 17/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 89ms/step - accuracy: 0.6900 - loss: 0.6825 - val_accuracy: 1.0000 - val_loss: 7.0665e-04\n",
      "Epoch 18/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 101ms/step - accuracy: 0.7078 - loss: 0.6389 - val_accuracy: 1.0000 - val_loss: 8.2278e-04\n",
      "Epoch 19/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 96ms/step - accuracy: 0.7013 - loss: 0.6596 - val_accuracy: 1.0000 - val_loss: 2.6844e-06\n",
      "Epoch 20/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 97ms/step - accuracy: 0.6646 - loss: 0.8232 - val_accuracy: 1.0000 - val_loss: 9.4864e-05\n",
      "Epoch 21/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 106ms/step - accuracy: 0.6448 - loss: 0.8540 - val_accuracy: 1.0000 - val_loss: 2.6161e-04\n",
      "Epoch 22/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 100ms/step - accuracy: 0.6598 - loss: 0.8265 - val_accuracy: 1.0000 - val_loss: 3.3067e-04\n",
      "Epoch 23/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 110ms/step - accuracy: 0.6588 - loss: 0.7667 - val_accuracy: 1.0000 - val_loss: 1.5159e-04\n",
      "Epoch 24/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 98ms/step - accuracy: 0.6965 - loss: 0.7416 - val_accuracy: 1.0000 - val_loss: 2.1318e-04\n",
      "Epoch 25/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 92ms/step - accuracy: 0.6907 - loss: 0.7388 - val_accuracy: 1.0000 - val_loss: 7.2514e-04\n",
      "Epoch 26/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 106ms/step - accuracy: 0.6892 - loss: 0.7052 - val_accuracy: 1.0000 - val_loss: 2.7872e-04\n",
      "Epoch 27/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 108ms/step - accuracy: 0.6891 - loss: 0.7362 - val_accuracy: 1.0000 - val_loss: 5.9310e-04\n",
      "Epoch 28/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 90ms/step - accuracy: 0.6763 - loss: 0.7342 - val_accuracy: 1.0000 - val_loss: 6.6802e-05\n",
      "Epoch 29/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 92ms/step - accuracy: 0.6630 - loss: 0.7556 - val_accuracy: 1.0000 - val_loss: 7.0518e-04\n",
      "Epoch 30/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 93ms/step - accuracy: 0.6721 - loss: 0.7511 - val_accuracy: 1.0000 - val_loss: 2.9906e-04\n",
      "Epoch 31/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 90ms/step - accuracy: 0.6858 - loss: 0.7574 - val_accuracy: 1.0000 - val_loss: 7.0595e-04\n",
      "Epoch 32/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.6755 - loss: 0.8041 - val_accuracy: 1.0000 - val_loss: 1.4129e-07\n",
      "Epoch 33/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.6007 - loss: 1.0045 - val_accuracy: 1.0000 - val_loss: 5.5660e-05\n",
      "Epoch 34/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 84ms/step - accuracy: 0.6605 - loss: 0.8371 - val_accuracy: 1.0000 - val_loss: 7.7779e-05\n",
      "Epoch 35/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.6696 - loss: 0.7846 - val_accuracy: 1.0000 - val_loss: 9.4201e-05\n",
      "Epoch 36/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.6715 - loss: 0.7644 - val_accuracy: 1.0000 - val_loss: 5.4495e-05\n",
      "Epoch 37/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.6555 - loss: 0.8169 - val_accuracy: 1.0000 - val_loss: 3.6654e-05\n",
      "Epoch 38/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.6768 - loss: 0.7893 - val_accuracy: 1.0000 - val_loss: 9.5838e-05\n",
      "Epoch 39/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.6849 - loss: 0.7418 - val_accuracy: 1.0000 - val_loss: 0.0019\n",
      "Epoch 40/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.6871 - loss: 0.7171 - val_accuracy: 1.0000 - val_loss: 6.3448e-04\n",
      "Epoch 41/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 93ms/step - accuracy: 0.6921 - loss: 0.7071 - val_accuracy: 1.0000 - val_loss: 0.0018\n",
      "Epoch 42/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.7054 - loss: 0.7120 - val_accuracy: 1.0000 - val_loss: 3.1069e-04\n",
      "Epoch 43/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.6805 - loss: 0.7696 - val_accuracy: 0.0000e+00 - val_loss: 1.9629\n",
      "Epoch 44/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.6618 - loss: 0.8077 - val_accuracy: 1.0000 - val_loss: 3.1881e-05\n",
      "Epoch 45/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 92ms/step - accuracy: 0.7333 - loss: 0.6168 - val_accuracy: 1.0000 - val_loss: 5.1236e-05\n",
      "Epoch 46/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 104ms/step - accuracy: 0.7471 - loss: 0.5759 - val_accuracy: 1.0000 - val_loss: 3.7139e-05\n",
      "Epoch 47/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 95ms/step - accuracy: 0.7843 - loss: 0.5518 - val_accuracy: 1.0000 - val_loss: 2.9802e-06\n",
      "Epoch 48/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 90ms/step - accuracy: 0.8022 - loss: 0.4408 - val_accuracy: 1.0000 - val_loss: 5.3776e-06\n",
      "Epoch 49/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 91ms/step - accuracy: 0.8074 - loss: 0.3848 - val_accuracy: 1.0000 - val_loss: 1.5744e-05\n",
      "Epoch 50/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.8238 - loss: 0.3745 - val_accuracy: 1.0000 - val_loss: 1.4376e-05\n",
      "Epoch 51/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 92ms/step - accuracy: 0.8046 - loss: 0.3871 - val_accuracy: 1.0000 - val_loss: 2.5285e-05\n",
      "Epoch 52/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 93ms/step - accuracy: 0.8196 - loss: 0.3694 - val_accuracy: 1.0000 - val_loss: 4.8437e-05\n",
      "Epoch 53/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 96ms/step - accuracy: 0.8212 - loss: 0.3668 - val_accuracy: 1.0000 - val_loss: 7.9150e-05\n",
      "Epoch 54/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 92ms/step - accuracy: 0.8192 - loss: 0.3873 - val_accuracy: 1.0000 - val_loss: 8.5158e-05\n",
      "Epoch 55/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 111ms/step - accuracy: 0.8002 - loss: 0.3861 - val_accuracy: 1.0000 - val_loss: 1.2305e-04\n",
      "Epoch 56/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 105ms/step - accuracy: 0.8111 - loss: 0.3589 - val_accuracy: 1.0000 - val_loss: 1.7404e-04\n",
      "Epoch 57/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 103ms/step - accuracy: 0.8220 - loss: 0.3594 - val_accuracy: 1.0000 - val_loss: 1.3459e-04\n",
      "Epoch 58/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 93ms/step - accuracy: 0.8020 - loss: 0.3817 - val_accuracy: 1.0000 - val_loss: 1.3235e-04\n",
      "Epoch 59/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.8117 - loss: 0.3864 - val_accuracy: 1.0000 - val_loss: 1.3336e-04\n",
      "Epoch 60/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.8015 - loss: 0.3660 - val_accuracy: 1.0000 - val_loss: 1.2797e-04\n",
      "Epoch 61/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 92ms/step - accuracy: 0.8228 - loss: 0.3542 - val_accuracy: 1.0000 - val_loss: 8.1742e-05\n",
      "Epoch 62/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 92ms/step - accuracy: 0.8201 - loss: 0.3457 - val_accuracy: 1.0000 - val_loss: 9.5180e-05\n",
      "Epoch 62: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\n",
      "Training fold 10\n",
      "\n",
      "Generating upsampling and SMOTE...\n",
      "2640 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({np.int64(3): 240, np.int64(4): 240, np.int64(0): 240, np.int64(6): 240, np.int64(7): 240, np.int64(9): 240, np.int64(5): 240, np.int64(1): 240, np.int64(2): 240, np.int64(8): 240, np.int64(10): 240})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 100ms/step - accuracy: 0.5461 - loss: 1.2238 - val_accuracy: 1.0000 - val_loss: 8.1636e-04\n",
      "Epoch 2/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 96ms/step - accuracy: 0.6392 - loss: 0.8515 - val_accuracy: 1.0000 - val_loss: 7.2107e-04\n",
      "Epoch 3/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 92ms/step - accuracy: 0.6333 - loss: 0.8122 - val_accuracy: 1.0000 - val_loss: 4.6666e-04\n",
      "Epoch 4/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.6675 - loss: 0.7371 - val_accuracy: 1.0000 - val_loss: 2.8460e-04\n",
      "Epoch 5/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 91ms/step - accuracy: 0.6877 - loss: 0.6860 - val_accuracy: 1.0000 - val_loss: 4.8615e-04\n",
      "Epoch 6/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.7031 - loss: 0.6485 - val_accuracy: 1.0000 - val_loss: 3.4205e-04\n",
      "Epoch 7/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 89ms/step - accuracy: 0.6976 - loss: 0.6417 - val_accuracy: 1.0000 - val_loss: 1.0457e-04\n",
      "Epoch 8/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 98ms/step - accuracy: 0.6756 - loss: 0.6651 - val_accuracy: 1.0000 - val_loss: 7.3634e-04\n",
      "Epoch 9/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 95ms/step - accuracy: 0.7010 - loss: 0.6603 - val_accuracy: 1.0000 - val_loss: 2.2326e-04\n",
      "Epoch 10/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.6913 - loss: 0.6474 - val_accuracy: 1.0000 - val_loss: 1.5992e-04\n",
      "Epoch 11/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.6932 - loss: 0.6313 - val_accuracy: 1.0000 - val_loss: 9.4167e-05\n",
      "Epoch 12/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 92ms/step - accuracy: 0.6924 - loss: 0.6369 - val_accuracy: 1.0000 - val_loss: 1.3421e-04\n",
      "Epoch 13/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 88ms/step - accuracy: 0.6805 - loss: 0.6394 - val_accuracy: 1.0000 - val_loss: 7.7585e-05\n",
      "Epoch 14/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 90ms/step - accuracy: 0.6730 - loss: 0.6776 - val_accuracy: 1.0000 - val_loss: 1.3459e-04\n",
      "Epoch 15/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 91ms/step - accuracy: 0.7116 - loss: 0.6211 - val_accuracy: 1.0000 - val_loss: 6.6847e-05\n",
      "Epoch 16/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 103ms/step - accuracy: 0.7125 - loss: 0.6312 - val_accuracy: 1.0000 - val_loss: 1.3513e-04\n",
      "Epoch 17/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.7017 - loss: 0.6361 - val_accuracy: 1.0000 - val_loss: 1.2477e-04\n",
      "Epoch 18/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.6991 - loss: 0.6186 - val_accuracy: 1.0000 - val_loss: 9.4692e-05\n",
      "Epoch 19/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 91ms/step - accuracy: 0.6973 - loss: 0.6429 - val_accuracy: 1.0000 - val_loss: 1.0067e-04\n",
      "Epoch 20/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 88ms/step - accuracy: 0.6946 - loss: 0.6398 - val_accuracy: 1.0000 - val_loss: 1.2952e-04\n",
      "Epoch 21/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 93ms/step - accuracy: 0.6989 - loss: 0.6463 - val_accuracy: 1.0000 - val_loss: 8.6269e-05\n",
      "Epoch 22/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.6949 - loss: 0.6356 - val_accuracy: 1.0000 - val_loss: 8.2863e-05\n",
      "Epoch 23/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 95ms/step - accuracy: 0.6995 - loss: 0.6239 - val_accuracy: 1.0000 - val_loss: 1.3689e-04\n",
      "Epoch 24/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.6978 - loss: 0.6468 - val_accuracy: 1.0000 - val_loss: 5.8567e-05\n",
      "Epoch 25/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 104ms/step - accuracy: 0.7028 - loss: 0.6000 - val_accuracy: 1.0000 - val_loss: 9.2991e-05\n",
      "Epoch 26/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 105ms/step - accuracy: 0.7014 - loss: 0.6199 - val_accuracy: 1.0000 - val_loss: 5.6259e-05\n",
      "Epoch 27/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 89ms/step - accuracy: 0.7260 - loss: 0.5925 - val_accuracy: 1.0000 - val_loss: 7.1608e-05\n",
      "Epoch 28/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 90ms/step - accuracy: 0.6772 - loss: 0.7404 - val_accuracy: 1.0000 - val_loss: 8.4771e-07\n",
      "Epoch 29/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 88ms/step - accuracy: 0.6312 - loss: 0.8507 - val_accuracy: 1.0000 - val_loss: 1.0596e-07\n",
      "Epoch 30/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 94ms/step - accuracy: 0.6410 - loss: 0.8551 - val_accuracy: 1.0000 - val_loss: 5.9264e-05\n",
      "Epoch 31/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 93ms/step - accuracy: 0.6802 - loss: 0.6908 - val_accuracy: 1.0000 - val_loss: 3.6955e-06\n",
      "Epoch 32/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 105ms/step - accuracy: 0.7126 - loss: 0.6240 - val_accuracy: 1.0000 - val_loss: 4.5918e-07\n",
      "Epoch 33/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 94ms/step - accuracy: 0.7570 - loss: 0.5187 - val_accuracy: 1.0000 - val_loss: 6.5123e-06\n",
      "Epoch 34/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.7642 - loss: 0.5035 - val_accuracy: 1.0000 - val_loss: 8.6404e-06\n",
      "Epoch 35/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 88ms/step - accuracy: 0.7741 - loss: 0.4706 - val_accuracy: 1.0000 - val_loss: 2.7475e-05\n",
      "Epoch 36/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.7710 - loss: 0.5054 - val_accuracy: 1.0000 - val_loss: 3.6212e-05\n",
      "Epoch 37/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 89ms/step - accuracy: 0.7829 - loss: 0.4534 - val_accuracy: 1.0000 - val_loss: 4.9368e-05\n",
      "Epoch 38/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.7681 - loss: 0.4807 - val_accuracy: 1.0000 - val_loss: 3.8737e-05\n",
      "Epoch 39/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.7847 - loss: 0.4646 - val_accuracy: 1.0000 - val_loss: 2.6111e-05\n",
      "Epoch 40/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 90ms/step - accuracy: 0.7847 - loss: 0.4587 - val_accuracy: 1.0000 - val_loss: 4.0865e-05\n",
      "Epoch 41/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.7848 - loss: 0.4501 - val_accuracy: 1.0000 - val_loss: 2.7938e-05\n",
      "Epoch 42/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.7749 - loss: 0.4760 - val_accuracy: 1.0000 - val_loss: 2.1749e-05\n",
      "Epoch 43/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 89ms/step - accuracy: 0.7808 - loss: 0.4518 - val_accuracy: 1.0000 - val_loss: 3.6945e-05\n",
      "Epoch 44/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 92ms/step - accuracy: 0.7830 - loss: 0.4444 - val_accuracy: 1.0000 - val_loss: 4.7540e-05\n",
      "Epoch 45/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.8011 - loss: 0.4350 - val_accuracy: 1.0000 - val_loss: 9.7618e-06\n",
      "Epoch 46/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.7702 - loss: 0.4713 - val_accuracy: 1.0000 - val_loss: 8.1148e-05\n",
      "Epoch 47/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 91ms/step - accuracy: 0.7705 - loss: 0.4793 - val_accuracy: 1.0000 - val_loss: 3.3997e-07\n",
      "Epoch 48/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 90ms/step - accuracy: 0.7742 - loss: 0.5489 - val_accuracy: 1.0000 - val_loss: 4.6459e-05\n",
      "Epoch 49/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 90ms/step - accuracy: 0.7808 - loss: 0.4451 - val_accuracy: 1.0000 - val_loss: 1.7934e-05\n",
      "Epoch 50/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.7851 - loss: 0.4531 - val_accuracy: 1.0000 - val_loss: 2.1131e-05\n",
      "Epoch 51/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 88ms/step - accuracy: 0.7885 - loss: 0.4339 - val_accuracy: 1.0000 - val_loss: 3.4438e-07\n",
      "Epoch 52/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 88ms/step - accuracy: 0.7811 - loss: 0.4139 - val_accuracy: 1.0000 - val_loss: 2.8345e-06\n",
      "Epoch 53/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.7874 - loss: 0.4108 - val_accuracy: 1.0000 - val_loss: 2.5078e-06\n",
      "Epoch 54/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 90ms/step - accuracy: 0.7888 - loss: 0.3959 - val_accuracy: 1.0000 - val_loss: 2.6800e-06\n",
      "Epoch 55/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 96ms/step - accuracy: 0.8119 - loss: 0.3847 - val_accuracy: 1.0000 - val_loss: 4.8743e-06\n",
      "Epoch 56/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.7864 - loss: 0.3957 - val_accuracy: 1.0000 - val_loss: 5.2231e-06\n",
      "Epoch 57/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 91ms/step - accuracy: 0.8064 - loss: 0.3731 - val_accuracy: 1.0000 - val_loss: 1.0164e-05\n",
      "Epoch 58/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 94ms/step - accuracy: 0.7911 - loss: 0.4118 - val_accuracy: 1.0000 - val_loss: 1.4888e-05\n",
      "Epoch 59/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 99ms/step - accuracy: 0.7935 - loss: 0.3996 - val_accuracy: 1.0000 - val_loss: 1.2473e-05\n",
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\n",
      "Time taken for training:  01:20:19\n",
      "\n",
      "\n",
      "Fold 1 - Train Accuracy 0.5837 - Test Accuracy 0.1875\n",
      "Fold 2 - Train Accuracy 0.5670 - Test Accuracy 0.4792\n",
      "Fold 3 - Train Accuracy 0.5678 - Test Accuracy 0.3333\n",
      "Fold 4 - Train Accuracy 0.6182 - Test Accuracy 0.5208\n",
      "Fold 5 - Train Accuracy 0.5598 - Test Accuracy 0.4375\n",
      "Fold 6 - Train Accuracy 0.6345 - Test Accuracy 0.5000\n",
      "Fold 7 - Train Accuracy 0.6742 - Test Accuracy 0.6042\n",
      "Fold 8 - Train Accuracy 0.6534 - Test Accuracy 0.5208\n",
      "Fold 9 - Train Accuracy 0.5792 - Test Accuracy 0.4583\n",
      "Fold 10 - Train Accuracy 0.6765 - Test Accuracy 0.5625\n",
      "\n",
      "Mean Train Accuracy: 0.6114 \n",
      "Mean Test Accuracy: 0.4604 \n",
      "\n",
      "Evaluate other metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.53      0.60       120\n",
      "           1       0.17      0.21      0.19        19\n",
      "           2       0.14      0.44      0.21        25\n",
      "           3       0.33      0.52      0.40        58\n",
      "           4       0.60      0.17      0.26        54\n",
      "           5       0.53      0.62      0.57        77\n",
      "           6       0.88      0.74      0.80        57\n",
      "           7       0.18      0.09      0.12        32\n",
      "           8       0.07      0.04      0.05        24\n",
      "           9       0.88      0.70      0.78        10\n",
      "          10       1.00      0.50      0.67         4\n",
      "\n",
      "    accuracy                           0.46       480\n",
      "   macro avg       0.50      0.41      0.42       480\n",
      "weighted avg       0.53      0.46      0.47       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def create_v1():\n",
    "    act_function = \"relu\"\n",
    "    kernel_init = \"he_uniform\"\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(number_of_steps, number_of_features)))\n",
    "    model.add(Conv1D(filters = 64, kernel_size = 3, activation = act_function,\n",
    "                     kernel_initializer = kernel_init))\n",
    "    model.add(Conv1D(filters = 32, kernel_size = 3, activation = act_function,\n",
    "                     kernel_initializer = kernel_init))\n",
    "    model.add(Conv1D(filters = 16, kernel_size = 3, activation = act_function,\n",
    "                     kernel_initializer = kernel_init))\n",
    "    model.add(MaxPooling1D(pool_size = 2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(32, activation = act_function, kernel_initializer = kernel_init))\n",
    "    model.add(Dense(32, activation = act_function, kernel_initializer = kernel_init))\n",
    "    model.add(Dense(32, activation = act_function, kernel_initializer = kernel_init))\n",
    "    model.add(Dense(11, activation = 'softmax'))\n",
    "    opt = AdamW(learning_rate = 0.001)\n",
    "    model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = opt, metrics = [\"accuracy\"])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "X_list, y_list = build_time_window_structure(df)\n",
    "X_arr = np.array(X_list)\n",
    "y_arr = np.array(y_list)\n",
    "\n",
    "model = create_v1()\n",
    "history_by_fold = train_cnn_model(model, X_arr, y_arr, quantity_of_resample = len(y_arr) * 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67529328",
   "metadata": {},
   "source": [
    "#### Train a Convolutional Neural Network model and evaluate the metrics.\n",
    "- Layer architecture => Conv1D (64) + Conv1D (32) + Conv1D (16) + MaxPooling1D + Dense (128) + Dense (11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a180bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting build_time_window_structure function...\n",
      "Quantity of samples (features) =>  480\n",
      "Quantity os samples (labels) =>  480\n",
      "Finishing build_time_window_structure function.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3198</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3196</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,176</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3194</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,552</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1597</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25552</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,270,784</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,419</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3198\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │         \u001b[38;5;34m6,208\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3196\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │         \u001b[38;5;34m6,176\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3194\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │         \u001b[38;5;34m1,552\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1597\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25552\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │     \u001b[38;5;34m3,270,784\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m)             │         \u001b[38;5;34m1,419\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,286,139</span> (12.54 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,286,139\u001b[0m (12.54 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,286,139</span> (12.54 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,286,139\u001b[0m (12.54 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training...\n",
      "\n",
      "Training fold 1\n",
      "\n",
      "Generating upsampling and SMOTE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\DeveloperTools\\python\\3.11.0\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2640 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({np.int64(3): 240, np.int64(4): 240, np.int64(0): 240, np.int64(6): 240, np.int64(7): 240, np.int64(9): 240, np.int64(5): 240, np.int64(1): 240, np.int64(2): 240, np.int64(8): 240, np.int64(10): 240})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 122ms/step - accuracy: 0.3427 - loss: 5.2348 - val_accuracy: 1.0000 - val_loss: 3.1038e-06\n",
      "Epoch 2/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 96ms/step - accuracy: 0.9519 - loss: 0.2112 - val_accuracy: 1.0000 - val_loss: 1.4967e-06\n",
      "Epoch 3/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 97ms/step - accuracy: 0.9823 - loss: 0.0614 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 4/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 111ms/step - accuracy: 0.9883 - loss: 0.0456 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 5/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 97ms/step - accuracy: 0.9951 - loss: 0.0250 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 6/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 103ms/step - accuracy: 0.9978 - loss: 0.0139 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 7/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 106ms/step - accuracy: 0.9958 - loss: 0.0146 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 8/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 100ms/step - accuracy: 0.9896 - loss: 0.0345 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 9/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 111ms/step - accuracy: 0.9959 - loss: 0.0148 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 10/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 105ms/step - accuracy: 0.9947 - loss: 0.0164 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 11/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 106ms/step - accuracy: 0.9941 - loss: 0.0214 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 12/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 103ms/step - accuracy: 0.9934 - loss: 0.0274 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 13/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 104ms/step - accuracy: 0.9980 - loss: 0.0072 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 14/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 107ms/step - accuracy: 0.9972 - loss: 0.0097 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 15/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 108ms/step - accuracy: 0.9978 - loss: 0.0107 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 16/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step - accuracy: 0.9963 - loss: 0.0100 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 17/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 119ms/step - accuracy: 0.9976 - loss: 0.0095 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 18/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 113ms/step - accuracy: 0.9994 - loss: 0.0040 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 19/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 107ms/step - accuracy: 0.9989 - loss: 0.0052 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 20/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 102ms/step - accuracy: 0.9928 - loss: 0.0253 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 21/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 109ms/step - accuracy: 0.9985 - loss: 0.0074 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 22/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 126ms/step - accuracy: 0.9952 - loss: 0.0140 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 23/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 102ms/step - accuracy: 0.9968 - loss: 0.0100 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 24/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 103ms/step - accuracy: 0.9906 - loss: 0.0232 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 25/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 102ms/step - accuracy: 0.9991 - loss: 0.0057 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 26/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 104ms/step - accuracy: 0.9990 - loss: 0.0028 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 27/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 107ms/step - accuracy: 0.9966 - loss: 0.0121 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 28/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 109ms/step - accuracy: 0.9962 - loss: 0.0107 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 29/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 113ms/step - accuracy: 0.9990 - loss: 0.0048 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 30/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 103ms/step - accuracy: 0.9977 - loss: 0.0106 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 31/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 106ms/step - accuracy: 0.9988 - loss: 0.0040 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 32/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 125ms/step - accuracy: 0.9975 - loss: 0.0101 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 33/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 109ms/step - accuracy: 0.9996 - loss: 0.0022 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step\n",
      "\n",
      "Training fold 2\n",
      "\n",
      "Generating upsampling and SMOTE...\n",
      "2640 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({np.int64(2): 240, np.int64(3): 240, np.int64(6): 240, np.int64(5): 240, np.int64(1): 240, np.int64(0): 240, np.int64(7): 240, np.int64(4): 240, np.int64(10): 240, np.int64(8): 240, np.int64(9): 240})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 103ms/step - accuracy: 0.8891 - loss: 0.4686 - val_accuracy: 1.0000 - val_loss: 2.3066e-05\n",
      "Epoch 2/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 99ms/step - accuracy: 0.9813 - loss: 0.0646 - val_accuracy: 1.0000 - val_loss: 1.8588e-06\n",
      "Epoch 3/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 105ms/step - accuracy: 0.9835 - loss: 0.0531 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 4/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 98ms/step - accuracy: 0.9869 - loss: 0.0464 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 5/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 117ms/step - accuracy: 0.9911 - loss: 0.0265 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 6/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 108ms/step - accuracy: 0.9915 - loss: 0.0312 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 7/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 105ms/step - accuracy: 0.9930 - loss: 0.0208 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 8/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 104ms/step - accuracy: 0.9977 - loss: 0.0108 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 9/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 98ms/step - accuracy: 0.9960 - loss: 0.0129 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 10/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 102ms/step - accuracy: 0.9954 - loss: 0.0129 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 11/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 110ms/step - accuracy: 0.9933 - loss: 0.0182 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 12/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 103ms/step - accuracy: 0.9978 - loss: 0.0106 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 13/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 102ms/step - accuracy: 0.9970 - loss: 0.0096 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 14/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 110ms/step - accuracy: 0.9976 - loss: 0.0069 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 15/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 102ms/step - accuracy: 0.9925 - loss: 0.0244 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 16/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 101ms/step - accuracy: 0.9983 - loss: 0.0098 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 17/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 119ms/step - accuracy: 0.9944 - loss: 0.0161 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 18/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 106ms/step - accuracy: 0.9969 - loss: 0.0067 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 19/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 122ms/step - accuracy: 0.9965 - loss: 0.0086 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 20/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 125ms/step - accuracy: 0.9981 - loss: 0.0079 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 21/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 121ms/step - accuracy: 0.9964 - loss: 0.0109 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 22/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - accuracy: 0.9965 - loss: 0.0122 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 23/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 110ms/step - accuracy: 0.9973 - loss: 0.0131 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 24/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 125ms/step - accuracy: 0.9987 - loss: 0.0060 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 25/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 122ms/step - accuracy: 0.9980 - loss: 0.0057 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 26/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 114ms/step - accuracy: 0.9953 - loss: 0.0099 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 27/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 113ms/step - accuracy: 0.9971 - loss: 0.0076 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 28/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 121ms/step - accuracy: 0.9959 - loss: 0.0200 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 29/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 120ms/step - accuracy: 0.9984 - loss: 0.0045 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 30/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 129ms/step - accuracy: 0.9947 - loss: 0.0198 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 31/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 138ms/step - accuracy: 0.9969 - loss: 0.0108 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 32/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 156ms/step - accuracy: 0.9965 - loss: 0.0082 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 33/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 166ms/step - accuracy: 0.9970 - loss: 0.0124 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\n",
      "Training fold 3\n",
      "\n",
      "Generating upsampling and SMOTE...\n",
      "2640 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({np.int64(2): 240, np.int64(3): 240, np.int64(6): 240, np.int64(5): 240, np.int64(1): 240, np.int64(0): 240, np.int64(7): 240, np.int64(8): 240, np.int64(4): 240, np.int64(10): 240, np.int64(9): 240})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 102ms/step - accuracy: 0.9528 - loss: 0.1562 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 2/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 97ms/step - accuracy: 0.9846 - loss: 0.0624 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 3/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 106ms/step - accuracy: 0.9900 - loss: 0.0392 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 4/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 112ms/step - accuracy: 0.9932 - loss: 0.0334 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 5/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 99ms/step - accuracy: 0.9940 - loss: 0.0216 - val_accuracy: 1.0000 - val_loss: 8.8303e-09\n",
      "Epoch 6/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 113ms/step - accuracy: 0.9929 - loss: 0.0199 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 7/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 99ms/step - accuracy: 0.9957 - loss: 0.0116 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 8/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 103ms/step - accuracy: 0.9935 - loss: 0.0304 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 9/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 105ms/step - accuracy: 0.9958 - loss: 0.0224 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 10/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 98ms/step - accuracy: 0.9940 - loss: 0.0193 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 11/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 102ms/step - accuracy: 0.9939 - loss: 0.0133 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 12/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 108ms/step - accuracy: 0.9978 - loss: 0.0129 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 13/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 107ms/step - accuracy: 0.9965 - loss: 0.0112 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 14/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 100ms/step - accuracy: 0.9985 - loss: 0.0064 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 15/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 106ms/step - accuracy: 0.9982 - loss: 0.0072 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 16/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 109ms/step - accuracy: 0.9957 - loss: 0.0102 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 17/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 108ms/step - accuracy: 0.9992 - loss: 0.0064 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 18/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 108ms/step - accuracy: 0.9955 - loss: 0.0115 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 19/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 107ms/step - accuracy: 0.9980 - loss: 0.0054 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 20/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 104ms/step - accuracy: 0.9967 - loss: 0.0110 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 21/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 121ms/step - accuracy: 0.9942 - loss: 0.0143 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 22/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 131ms/step - accuracy: 0.9947 - loss: 0.0100 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 23/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 118ms/step - accuracy: 0.9983 - loss: 0.0049 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 24/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step - accuracy: 0.9980 - loss: 0.0119 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 25/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 109ms/step - accuracy: 0.9966 - loss: 0.0131 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 26/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 111ms/step - accuracy: 0.9983 - loss: 0.0054 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 27/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 119ms/step - accuracy: 0.9977 - loss: 0.0088 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 28/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 117ms/step - accuracy: 0.9938 - loss: 0.0349 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 29/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 111ms/step - accuracy: 0.9952 - loss: 0.0096 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 30/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 126ms/step - accuracy: 0.9972 - loss: 0.0092 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 31/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 112ms/step - accuracy: 0.9996 - loss: 0.0019 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\n",
      "Training fold 4\n",
      "\n",
      "Generating upsampling and SMOTE...\n",
      "2640 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({np.int64(2): 240, np.int64(3): 240, np.int64(6): 240, np.int64(5): 240, np.int64(1): 240, np.int64(0): 240, np.int64(7): 240, np.int64(8): 240, np.int64(4): 240, np.int64(10): 240, np.int64(9): 240})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 120ms/step - accuracy: 0.9750 - loss: 0.0909 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 2/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 109ms/step - accuracy: 0.9847 - loss: 0.0430 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 3/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 102ms/step - accuracy: 0.9927 - loss: 0.0323 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 4/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 111ms/step - accuracy: 0.9952 - loss: 0.0122 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 5/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 122ms/step - accuracy: 0.9914 - loss: 0.0319 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 6/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 115ms/step - accuracy: 0.9951 - loss: 0.0155 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 7/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 107ms/step - accuracy: 0.9924 - loss: 0.0249 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 8/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 106ms/step - accuracy: 0.9976 - loss: 0.0066 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 9/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 105ms/step - accuracy: 0.9917 - loss: 0.0197 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 10/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 107ms/step - accuracy: 0.9946 - loss: 0.0152 - val_accuracy: 1.0000 - val_loss: 2.6491e-08\n",
      "Epoch 11/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 110ms/step - accuracy: 0.9905 - loss: 0.0345 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 12/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 108ms/step - accuracy: 0.9957 - loss: 0.0127 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 13/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 119ms/step - accuracy: 0.9964 - loss: 0.0134 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 14/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 117ms/step - accuracy: 0.9977 - loss: 0.0042 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 15/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 107ms/step - accuracy: 0.9979 - loss: 0.0060 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 16/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 117ms/step - accuracy: 0.9979 - loss: 0.0053 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 17/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 110ms/step - accuracy: 0.9980 - loss: 0.0066 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 18/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 109ms/step - accuracy: 0.9994 - loss: 0.0039 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 19/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 122ms/step - accuracy: 0.9972 - loss: 0.0066 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 20/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 110ms/step - accuracy: 0.9918 - loss: 0.0220 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 21/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 118ms/step - accuracy: 0.9999 - loss: 0.0023 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 22/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 120ms/step - accuracy: 0.9981 - loss: 0.0069 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 23/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 113ms/step - accuracy: 0.9988 - loss: 0.0040 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 24/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 113ms/step - accuracy: 0.9957 - loss: 0.0137 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 25/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 121ms/step - accuracy: 0.9990 - loss: 0.0054 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 26/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 115ms/step - accuracy: 0.9985 - loss: 0.0031 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 27/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step - accuracy: 0.9986 - loss: 0.0034 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 28/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 130ms/step - accuracy: 0.9980 - loss: 0.0069 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 29/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 118ms/step - accuracy: 0.9973 - loss: 0.0051 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 30/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 120ms/step - accuracy: 0.9991 - loss: 0.0028 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 31/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 122ms/step - accuracy: 0.9986 - loss: 0.0064 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\n",
      "Training fold 5\n",
      "\n",
      "Generating upsampling and SMOTE...\n",
      "2640 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({np.int64(2): 240, np.int64(3): 240, np.int64(6): 240, np.int64(5): 240, np.int64(1): 240, np.int64(0): 240, np.int64(7): 240, np.int64(8): 240, np.int64(4): 240, np.int64(10): 240, np.int64(9): 240})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 108ms/step - accuracy: 0.9870 - loss: 0.0715 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 2/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 100ms/step - accuracy: 0.9884 - loss: 0.0472 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 3/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 103ms/step - accuracy: 0.9896 - loss: 0.0280 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 4/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 102ms/step - accuracy: 0.9907 - loss: 0.0273 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 5/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 110ms/step - accuracy: 0.9904 - loss: 0.0278 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 6/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 101ms/step - accuracy: 0.9965 - loss: 0.0147 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 7/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 105ms/step - accuracy: 0.9995 - loss: 0.0041 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 8/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 96ms/step - accuracy: 0.9963 - loss: 0.0169 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 9/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 111ms/step - accuracy: 0.9969 - loss: 0.0087 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 10/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 107ms/step - accuracy: 0.9951 - loss: 0.0104 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 11/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 101ms/step - accuracy: 0.9975 - loss: 0.0055 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 12/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 101ms/step - accuracy: 0.9986 - loss: 0.0041 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 13/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 124ms/step - accuracy: 0.9985 - loss: 0.0073 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 14/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 103ms/step - accuracy: 0.9980 - loss: 0.0068 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 15/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 105ms/step - accuracy: 0.9983 - loss: 0.0060 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 16/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 117ms/step - accuracy: 0.9999 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 17/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 139ms/step - accuracy: 0.9980 - loss: 0.0159 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 18/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 108ms/step - accuracy: 0.9980 - loss: 0.0072 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 19/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 108ms/step - accuracy: 0.9940 - loss: 0.0221 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 20/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 107ms/step - accuracy: 0.9981 - loss: 0.0072 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 21/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 120ms/step - accuracy: 0.9974 - loss: 0.0074 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 22/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 154ms/step - accuracy: 0.9978 - loss: 0.0125 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 23/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 147ms/step - accuracy: 0.9999 - loss: 0.0024 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 24/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 117ms/step - accuracy: 0.9965 - loss: 0.0112 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 25/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 112ms/step - accuracy: 0.9979 - loss: 0.0039 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 26/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 115ms/step - accuracy: 0.9997 - loss: 0.0023 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 27/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 111ms/step - accuracy: 0.9957 - loss: 0.0090 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 28/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 29/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 124ms/step - accuracy: 0.9998 - loss: 0.0025 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 30/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 117ms/step - accuracy: 0.9981 - loss: 0.0058 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 31/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 123ms/step - accuracy: 0.9986 - loss: 0.0068 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\n",
      "Training fold 6\n",
      "\n",
      "Generating upsampling and SMOTE...\n",
      "2640 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({np.int64(2): 240, np.int64(3): 240, np.int64(6): 240, np.int64(5): 240, np.int64(1): 240, np.int64(0): 240, np.int64(7): 240, np.int64(8): 240, np.int64(4): 240, np.int64(10): 240, np.int64(9): 240})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 117ms/step - accuracy: 0.9808 - loss: 0.0567 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 2/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 128ms/step - accuracy: 0.9907 - loss: 0.0267 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 3/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 128ms/step - accuracy: 0.9940 - loss: 0.0205 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 4/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 127ms/step - accuracy: 0.9931 - loss: 0.0209 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 5/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 73ms/step - accuracy: 0.9949 - loss: 0.0152 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 6/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 99ms/step - accuracy: 0.9897 - loss: 0.0261 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 7/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 109ms/step - accuracy: 0.9978 - loss: 0.0099 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 8/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 100ms/step - accuracy: 0.9969 - loss: 0.0131 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 9/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 126ms/step - accuracy: 0.9987 - loss: 0.0050 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 10/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 124ms/step - accuracy: 0.9972 - loss: 0.0060 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 11/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 106ms/step - accuracy: 0.9942 - loss: 0.0273 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 12/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 105ms/step - accuracy: 0.9966 - loss: 0.0110 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 13/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 105ms/step - accuracy: 0.9961 - loss: 0.0139 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 14/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 105ms/step - accuracy: 0.9979 - loss: 0.0084 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 15/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 109ms/step - accuracy: 0.9963 - loss: 0.0129 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 16/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 107ms/step - accuracy: 0.9970 - loss: 0.0089 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 17/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 113ms/step - accuracy: 0.9985 - loss: 0.0102 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 18/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 107ms/step - accuracy: 0.9981 - loss: 0.0066 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 19/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 107ms/step - accuracy: 0.9972 - loss: 0.0060 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 20/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 111ms/step - accuracy: 0.9993 - loss: 0.0042 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 21/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 112ms/step - accuracy: 0.9950 - loss: 0.0102 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 22/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 107ms/step - accuracy: 0.9964 - loss: 0.0075 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 23/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 111ms/step - accuracy: 0.9952 - loss: 0.0087 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 24/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step - accuracy: 0.9995 - loss: 0.0025 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 25/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 121ms/step - accuracy: 0.9971 - loss: 0.0101 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 26/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 133ms/step - accuracy: 0.9985 - loss: 0.0067 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 27/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 117ms/step - accuracy: 0.9971 - loss: 0.0164 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 28/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 112ms/step - accuracy: 0.9985 - loss: 0.0041 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 29/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 117ms/step - accuracy: 0.9989 - loss: 0.0111 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 30/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 105ms/step - accuracy: 0.9995 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 31/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 98ms/step - accuracy: 0.9989 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\n",
      "Training fold 7\n",
      "\n",
      "Generating upsampling and SMOTE...\n",
      "2640 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({np.int64(2): 240, np.int64(3): 240, np.int64(6): 240, np.int64(5): 240, np.int64(1): 240, np.int64(0): 240, np.int64(7): 240, np.int64(8): 240, np.int64(4): 240, np.int64(10): 240, np.int64(9): 240})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 123ms/step - accuracy: 0.9879 - loss: 0.0455 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 2/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 108ms/step - accuracy: 0.9909 - loss: 0.0339 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 3/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 106ms/step - accuracy: 0.9949 - loss: 0.0152 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 4/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 108ms/step - accuracy: 0.9954 - loss: 0.0152 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 5/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 109ms/step - accuracy: 0.9971 - loss: 0.0146 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 6/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 109ms/step - accuracy: 0.9972 - loss: 0.0106 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 7/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 107ms/step - accuracy: 0.9980 - loss: 0.0096 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 8/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 107ms/step - accuracy: 0.9963 - loss: 0.0112 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 9/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 107ms/step - accuracy: 0.9945 - loss: 0.0122 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 10/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 112ms/step - accuracy: 0.9980 - loss: 0.0069 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 11/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 107ms/step - accuracy: 0.9949 - loss: 0.0204 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 12/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 109ms/step - accuracy: 0.9987 - loss: 0.0060 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 13/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 139ms/step - accuracy: 0.9970 - loss: 0.0075 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 14/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 123ms/step - accuracy: 0.9950 - loss: 0.0152 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 15/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 114ms/step - accuracy: 0.9965 - loss: 0.0073 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 16/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 115ms/step - accuracy: 0.9982 - loss: 0.0076 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 17/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 123ms/step - accuracy: 0.9941 - loss: 0.0221 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 18/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 128ms/step - accuracy: 0.9987 - loss: 0.0078 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 19/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 110ms/step - accuracy: 0.9990 - loss: 0.0041 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 20/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 105ms/step - accuracy: 0.9981 - loss: 0.0038 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 21/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 105ms/step - accuracy: 0.9987 - loss: 0.0031 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 22/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 105ms/step - accuracy: 0.9966 - loss: 0.0064 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 23/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 107ms/step - accuracy: 0.9987 - loss: 0.0023 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 24/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 100ms/step - accuracy: 0.9989 - loss: 0.0043 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 25/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 106ms/step - accuracy: 0.9997 - loss: 0.0042 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 26/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 104ms/step - accuracy: 0.9976 - loss: 0.0063 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 27/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 115ms/step - accuracy: 0.9942 - loss: 0.0310 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 28/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 110ms/step - accuracy: 0.9994 - loss: 0.0038 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 29/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 110ms/step - accuracy: 0.9972 - loss: 0.0124 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 30/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 103ms/step - accuracy: 0.9975 - loss: 0.0062 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 31/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 120ms/step - accuracy: 0.9982 - loss: 0.0046 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\n",
      "Training fold 8\n",
      "\n",
      "Generating upsampling and SMOTE...\n",
      "2640 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({np.int64(3): 240, np.int64(4): 240, np.int64(0): 240, np.int64(6): 240, np.int64(7): 240, np.int64(5): 240, np.int64(1): 240, np.int64(2): 240, np.int64(8): 240, np.int64(10): 240, np.int64(9): 240})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 119ms/step - accuracy: 0.9945 - loss: 0.0188 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 2/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 117ms/step - accuracy: 0.9920 - loss: 0.0261 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 3/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 124ms/step - accuracy: 0.9960 - loss: 0.0107 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 4/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 115ms/step - accuracy: 0.9969 - loss: 0.0092 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 5/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 119ms/step - accuracy: 0.9963 - loss: 0.0164 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 6/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 132ms/step - accuracy: 0.9975 - loss: 0.0053 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 7/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 147ms/step - accuracy: 0.9942 - loss: 0.0187 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 8/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 143ms/step - accuracy: 0.9956 - loss: 0.0088 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 9/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 134ms/step - accuracy: 0.9964 - loss: 0.0097 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 10/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 133ms/step - accuracy: 0.9998 - loss: 0.0019 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 11/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 125ms/step - accuracy: 0.9988 - loss: 0.0059 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 12/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 117ms/step - accuracy: 0.9981 - loss: 0.0044 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 13/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 111ms/step - accuracy: 0.9953 - loss: 0.0160 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 14/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 99ms/step - accuracy: 0.9989 - loss: 0.0035 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 15/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 103ms/step - accuracy: 0.9977 - loss: 0.0093 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 16/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 107ms/step - accuracy: 0.9998 - loss: 0.0025 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 17/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 101ms/step - accuracy: 0.9997 - loss: 0.0013 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 18/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 108ms/step - accuracy: 0.9974 - loss: 0.0058 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 19/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 108ms/step - accuracy: 0.9976 - loss: 0.0038 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 20/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 102ms/step - accuracy: 0.9974 - loss: 0.0102 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 21/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 102ms/step - accuracy: 0.9962 - loss: 0.0182 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 22/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 103ms/step - accuracy: 0.9993 - loss: 0.0053 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 23/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 104ms/step - accuracy: 0.9971 - loss: 0.0065 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 24/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 102ms/step - accuracy: 0.9957 - loss: 0.0169 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 25/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 108ms/step - accuracy: 0.9998 - loss: 0.0014 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 26/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 114ms/step - accuracy: 0.9995 - loss: 0.0017 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 27/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 107ms/step - accuracy: 0.9998 - loss: 0.0034 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 28/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 105ms/step - accuracy: 0.9985 - loss: 0.0085 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 29/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 108ms/step - accuracy: 0.9991 - loss: 0.0037 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 30/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 104ms/step - accuracy: 0.9967 - loss: 0.0232 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 31/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 108ms/step - accuracy: 0.9987 - loss: 0.0028 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\n",
      "Training fold 9\n",
      "\n",
      "Generating upsampling and SMOTE...\n",
      "2640 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({np.int64(3): 240, np.int64(4): 240, np.int64(0): 240, np.int64(6): 240, np.int64(7): 240, np.int64(9): 240, np.int64(5): 240, np.int64(1): 240, np.int64(2): 240, np.int64(8): 240, np.int64(10): 240})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 230ms/step - accuracy: 0.9938 - loss: 0.0238 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 2/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 112ms/step - accuracy: 0.9901 - loss: 0.0238 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 3/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 105ms/step - accuracy: 0.9942 - loss: 0.0197 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 4/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 102ms/step - accuracy: 0.9950 - loss: 0.0162 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 5/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 119ms/step - accuracy: 0.9938 - loss: 0.0191 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 6/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 120ms/step - accuracy: 0.9948 - loss: 0.0090 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 7/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 106ms/step - accuracy: 0.9959 - loss: 0.0082 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 8/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 114ms/step - accuracy: 0.9935 - loss: 0.0203 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 9/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 108ms/step - accuracy: 0.9956 - loss: 0.0110 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 10/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 123ms/step - accuracy: 0.9942 - loss: 0.0194 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 11/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 127ms/step - accuracy: 0.9969 - loss: 0.0120 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 12/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 108ms/step - accuracy: 0.9969 - loss: 0.0073 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 13/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 107ms/step - accuracy: 0.9986 - loss: 0.0037 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 14/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 112ms/step - accuracy: 0.9966 - loss: 0.0206 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 15/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 108ms/step - accuracy: 0.9981 - loss: 0.0045 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 16/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 108ms/step - accuracy: 0.9961 - loss: 0.0086 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 17/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 120ms/step - accuracy: 0.9994 - loss: 0.0031 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 18/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 128ms/step - accuracy: 0.9984 - loss: 0.0060 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 19/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 121ms/step - accuracy: 0.9971 - loss: 0.0043 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 20/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 113ms/step - accuracy: 0.9986 - loss: 0.0017 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 21/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 140ms/step - accuracy: 0.9997 - loss: 0.0018 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 22/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 123ms/step - accuracy: 0.9982 - loss: 0.0074 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 23/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 101ms/step - accuracy: 0.9989 - loss: 0.0027 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 24/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 102ms/step - accuracy: 0.9955 - loss: 0.0171 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 25/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 108ms/step - accuracy: 0.9968 - loss: 0.0057 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 26/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 3.0539e-04 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 27/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 105ms/step - accuracy: 0.9994 - loss: 0.0019 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 28/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 109ms/step - accuracy: 0.9990 - loss: 0.0025 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 29/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 110ms/step - accuracy: 0.9989 - loss: 0.0081 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 30/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 105ms/step - accuracy: 0.9987 - loss: 0.0055 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 31/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 110ms/step - accuracy: 0.9989 - loss: 0.0039 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\n",
      "Training fold 10\n",
      "\n",
      "Generating upsampling and SMOTE...\n",
      "2640 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({np.int64(3): 240, np.int64(4): 240, np.int64(0): 240, np.int64(6): 240, np.int64(7): 240, np.int64(9): 240, np.int64(5): 240, np.int64(1): 240, np.int64(2): 240, np.int64(8): 240, np.int64(10): 240})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 137ms/step - accuracy: 0.9953 - loss: 0.0180 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 2/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 130ms/step - accuracy: 0.9936 - loss: 0.0128 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 3/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 128ms/step - accuracy: 0.9912 - loss: 0.0263 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 4/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 132ms/step - accuracy: 0.9912 - loss: 0.0278 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 5/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 135ms/step - accuracy: 0.9931 - loss: 0.0196 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 6/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 147ms/step - accuracy: 0.9937 - loss: 0.0224 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 7/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 119ms/step - accuracy: 0.9951 - loss: 0.0167 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 8/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 110ms/step - accuracy: 0.9957 - loss: 0.0119 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 9/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 112ms/step - accuracy: 0.9965 - loss: 0.0126 - val_accuracy: 1.0000 - val_loss: 8.8303e-09\n",
      "Epoch 10/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 106ms/step - accuracy: 0.9973 - loss: 0.0093 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 11/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 113ms/step - accuracy: 0.9984 - loss: 0.0055 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 12/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 109ms/step - accuracy: 0.9987 - loss: 0.0047 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 13/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 106ms/step - accuracy: 0.9997 - loss: 0.0021 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 14/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 111ms/step - accuracy: 0.9983 - loss: 0.0035 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 15/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 119ms/step - accuracy: 0.9976 - loss: 0.0051 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 16/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 109ms/step - accuracy: 0.9981 - loss: 0.0058 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 17/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 112ms/step - accuracy: 0.9968 - loss: 0.0131 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 18/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 111ms/step - accuracy: 0.9989 - loss: 0.0054 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 19/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 115ms/step - accuracy: 0.9983 - loss: 0.0057 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 20/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 141ms/step - accuracy: 0.9964 - loss: 0.0123 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 21/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 125ms/step - accuracy: 0.9996 - loss: 0.0014 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 22/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 131ms/step - accuracy: 0.9960 - loss: 0.0078 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 23/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 121ms/step - accuracy: 0.9977 - loss: 0.0092 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 24/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 135ms/step - accuracy: 0.9991 - loss: 0.0051 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 25/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 119ms/step - accuracy: 0.9993 - loss: 0.0027 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 26/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 114ms/step - accuracy: 0.9986 - loss: 0.0050 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 27/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 125ms/step - accuracy: 0.9996 - loss: 0.0039 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 28/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 117ms/step - accuracy: 0.9991 - loss: 0.0025 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 29/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 5.3797e-04 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 30/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 128ms/step - accuracy: 0.9983 - loss: 0.0074 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 31/300\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 129ms/step - accuracy: 0.9994 - loss: 0.0017 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\n",
      "Time taken for training:  00:58:57\n",
      "\n",
      "\n",
      "Fold 1 - Train Accuracy 0.9992 - Test Accuracy 0.1458\n",
      "Fold 2 - Train Accuracy 0.9985 - Test Accuracy 0.7083\n",
      "Fold 3 - Train Accuracy 1.0000 - Test Accuracy 0.9375\n",
      "Fold 4 - Train Accuracy 1.0000 - Test Accuracy 0.9583\n",
      "Fold 5 - Train Accuracy 1.0000 - Test Accuracy 1.0000\n",
      "Fold 6 - Train Accuracy 1.0000 - Test Accuracy 1.0000\n",
      "Fold 7 - Train Accuracy 1.0000 - Test Accuracy 1.0000\n",
      "Fold 8 - Train Accuracy 0.9992 - Test Accuracy 1.0000\n",
      "Fold 9 - Train Accuracy 1.0000 - Test Accuracy 1.0000\n",
      "Fold 10 - Train Accuracy 1.0000 - Test Accuracy 0.9792\n",
      "\n",
      "Mean Train Accuracy: 0.9997 \n",
      "Mean Test Accuracy: 0.8729 \n",
      "\n",
      "Evaluate other metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.87      0.89       120\n",
      "           1       1.00      0.79      0.88        19\n",
      "           2       1.00      0.88      0.94        25\n",
      "           3       0.91      0.84      0.88        58\n",
      "           4       0.72      0.89      0.79        54\n",
      "           5       0.83      0.91      0.87        77\n",
      "           6       0.85      0.88      0.86        57\n",
      "           7       0.88      0.91      0.89        32\n",
      "           8       1.00      0.83      0.91        24\n",
      "           9       1.00      0.90      0.95        10\n",
      "          10       1.00      0.75      0.86         4\n",
      "\n",
      "    accuracy                           0.87       480\n",
      "   macro avg       0.92      0.86      0.88       480\n",
      "weighted avg       0.88      0.87      0.87       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def create_v2():\n",
    "    act_function = \"relu\"\n",
    "    kernel_init = \"he_uniform\"\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(number_of_steps, number_of_features)))\n",
    "    model.add(Conv1D(filters = 64, kernel_size = 3, activation = act_function,\n",
    "                     kernel_initializer = kernel_init))\n",
    "    model.add(Conv1D(filters = 32, kernel_size = 3, activation = act_function,\n",
    "                     kernel_initializer = kernel_init))\n",
    "    model.add(Conv1D(filters = 16, kernel_size = 3, activation = act_function,\n",
    "                     kernel_initializer = kernel_init))\n",
    "    model.add(MaxPooling1D(pool_size = 2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation = act_function, kernel_initializer = kernel_init))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(11, activation = 'softmax'))\n",
    "    opt = AdamW(learning_rate = 0.001)\n",
    "    model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = opt, metrics = [\"accuracy\"])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "X_list, y_list = build_time_window_structure(df)\n",
    "X_arr = np.array(X_list)\n",
    "y_arr = np.array(y_list)\n",
    "\n",
    "model = create_v2()\n",
    "history_by_fold = train_cnn_model(model, X_arr, y_arr, quantity_of_resample = len(y_arr) * 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48119eaf",
   "metadata": {},
   "source": [
    "#### Show loss history by epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89a10b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Plot loss history\n",
    "for i in range(len(history_by_fold)):\n",
    "    plt.plot(history_by_fold[i].history[\"val_loss\"], label = \"Fold {}\".format(i + 1))\n",
    "plt.title(\"Validation Loss vs Number of epochs\", fontsize = 12)\n",
    "plt.xlabel(\"Epochs\", fontsize = 12)\n",
    "plt.ylabel(\"Loss\", fontsize = 12)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26847b22",
   "metadata": {},
   "source": [
    "#### Show accuracy history by epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a7e0aca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Plot accuracy history\n",
    "for i in range(len(history_by_fold)):\n",
    "    plt.plot(history_by_fold[i].history[\"val_accuracy\"], label = \"Fold {}\".format(i + 1))\n",
    "plt.title(\"Validation Accuracy vs Number of epochs\", fontsize = 12)\n",
    "plt.xlabel('Epochs', fontsize = 12)\n",
    "plt.ylabel('Accuracy', fontsize = 12)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
