{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdbe460f",
   "metadata": {},
   "source": [
    "#### Import libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "077b6c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Input\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras.optimizers import AdamW\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.utils import resample\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42175028",
   "metadata": {},
   "source": [
    "#### Load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b43ccbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv('../dataset/original-sam-dataset.csv', sep='|',\n",
    "                 dtype = {'recordNumber': 'int8',\n",
    "                          'CZ': 'float64', 'FZ': 'float64', 'Fp1': 'float64', 'F7': 'float64',\n",
    "                          'F3': 'float64', 'FC1': 'float64', 'C3': 'float64', 'FC5': 'float64', 'FT9': 'float64',\n",
    "                          'T7': 'float64', 'CP5': 'float64', 'CP1': 'float64', 'P3': 'float64', 'P7': 'float64',\n",
    "                          'PO9': 'float64', 'O1': 'float64', 'PZ': 'float64', 'OZ': 'float64', 'O2': 'float64',\n",
    "                          'PO10': 'float64', 'P8': 'float64', 'P4': 'float64', 'CP2': 'float64', 'CP6': 'float64',\n",
    "                          'T8': 'float64', 'FT10': 'float64', 'FC6': 'float64', 'C4': 'float64', 'FC2': 'float64',\n",
    "                          'F4': 'float64', 'F8': 'float64', 'Fp2': 'float64', \n",
    "                          'Scale': 'int8'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d03541",
   "metadata": {},
   "source": [
    "#### Display the dataset size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d243cc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1536000, 34)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3579e10b",
   "metadata": {},
   "source": [
    "#### Build a helper function to convert the set data to the required format to perform the undersampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "859f6e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_time_window_structure(df):\n",
    "    # Splits the dataset into \"time windows\" to be used as a time series list.\n",
    "    # The function groups each 128 dataset records (CSV lines) into one record.\n",
    "    # Each record contains 128 steps and each step contains 32 feature values.\n",
    "    # Parameters:\n",
    "    #    df: Dataframe to be splitted.\n",
    "    # Return:\n",
    "    #    X_array (list): First list contains all time windows.\n",
    "    #    y_array (list): Second list contains all target values.\n",
    "    print(\"\\nStarting build_time_window_structure function...\")\n",
    "    steps_number = 1280\n",
    "    first_feat_index = 1\n",
    "    last_feat_index = 33\n",
    "    df_values = df.iloc[:, first_feat_index:last_feat_index].values\n",
    "    scale_values = df[\"Scale\"].values\n",
    "    num_segments = len(scale_values) // steps_number  \n",
    "    X_array = np.empty((num_segments, steps_number * (last_feat_index - first_feat_index)), dtype = df_values.dtype)\n",
    "    y_array = np.empty(num_segments, dtype = scale_values.dtype)\n",
    "    for i in range(num_segments):\n",
    "        start_idx = i * steps_number\n",
    "        end_idx = start_idx + steps_number\n",
    "        sub_matrix_values = df_values[start_idx:end_idx].flatten()\n",
    "        X_array[i] = sub_matrix_values\n",
    "        y_array[i] = scale_values[start_idx]\n",
    "    X_array = X_array.tolist()\n",
    "    y_array = y_array.tolist()\n",
    "    print(\"Quantity of samples (features) => \", len(X_array))\n",
    "    print(\"Quantity os samples (labels) => \", len(y_array))\n",
    "    print(\"Finishing build_time_window_structure function.\")\n",
    "    return X_array, y_array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09daa21c",
   "metadata": {},
   "source": [
    "#### Define a function to performe SMOTE to balance the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd2e2c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def apply_smote_resample(X_array, y_array, apply_resample = False, quantity_of_resample = 0):\n",
    "    # Apply SMOTE to balance the dataset and resample for data augmentation.\n",
    "    # Parameters:\n",
    "    #    X_array (np.array): array of features values.\n",
    "    #    y_array (np.array): array of target values.\n",
    "    #    apply_resample (boolean): resample will be performe if True.\n",
    "    #    quantity_of_resample (int): number of samples generated by resample.\n",
    "    # Return:\n",
    "    #    X_oversampled (np.array): array of features values.\n",
    "    #    y_oversampled (np.array): array of target values.\n",
    "    print(\"\\nGenerating upsampling using SMOTE...\")\n",
    "    smote = SMOTE(sampling_strategy = \"auto\", k_neighbors = 5, random_state = 42)\n",
    "    X_array_res, y_array_res = smote.fit_resample(X_array, y_array)\n",
    "    if apply_resample is True:\n",
    "        X_oversampled, y_oversampled = resample(X_array_res,\n",
    "                                                y_array_res,\n",
    "                                                replace = True,\n",
    "                                                n_samples = quantity_of_resample,\n",
    "                                                stratify = y_array_res,\n",
    "                                                random_state = 42)\n",
    "    else:\n",
    "        X_oversampled, y_oversampled = X_array_res, y_array_res\n",
    "    print(\"{} samples after upsampling.\".format(len(y_oversampled)))\n",
    "    print(f\"Class distribution for training after upsampling: {Counter(y_oversampled)}\")\n",
    "    print(\"Finishing upsampling.\\n\")\n",
    "    return X_oversampled, y_oversampled\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020af4fd",
   "metadata": {},
   "source": [
    "#### Define a function to train a CNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b7ce9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "number_of_steps = 1280\n",
    "number_of_features = 32\n",
    "\n",
    "# Define the number of folds (10 k-Fold).\n",
    "skf = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "# Normalize data using RobustScaler.\n",
    "pt = RobustScaler()\n",
    "\n",
    "es = EarlyStopping(monitor = \"val_loss\", mode = \"min\", verbose = 1, patience = 30, restore_best_weights = True)\n",
    "\n",
    "def train_cnn_model(cnn_model, X_arr, y_arr, apply_smote = False, apply_resample = False, quantity_of_resample = 0):\n",
    "    # Train a CNN model.\n",
    "    # Parameters:\n",
    "    #    cnn_model (Sequential): model to be trained.\n",
    "    #    X_arr (np.array): array of features values.\n",
    "    #    y_arr (np.array): array of target values.\n",
    "    #    apply_smote (boolean): SMOTE will be performe if True.\n",
    "    #    apply_resample (boolean): resample will be performe if True.\n",
    "    #    quantity_of_resample (int): number of samples generated by resample.\n",
    "    # Returns:\n",
    "    #    history (History object): history of training metrics.\n",
    "    train_accuracy_by_fold = []\n",
    "    test_accuracy_by_fold = []\n",
    "    history_by_fold = []\n",
    "    y_predclass_for_report = []\n",
    "    y_testclass_for_report = []\n",
    "    fold_number = 1\n",
    "    start_time = time.time()\n",
    "    print(\"\\nStarting training...\")\n",
    "    for train_index, test_index in skf.split(X_arr, y_arr):\n",
    "        print(\"\\nTraining fold {}\".format(fold_number))\n",
    "        if apply_smote is True:\n",
    "            X_oversampled, y_oversampled = apply_smote_resample(X_arr[train_index], y_arr[train_index],\n",
    "                                                                apply_resample, quantity_of_resample)\n",
    "        else:\n",
    "            X_oversampled, y_oversampled = X_arr[train_index], y_arr[train_index]\n",
    "        X_train_scaled = pt.fit_transform(X_oversampled)\n",
    "        X_test_scaled = pt.transform(X_arr[test_index])\n",
    "        # Reshape the structure data to be compatible with pattern [samples, timesteps, features].\n",
    "        X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], number_of_steps, number_of_features))\n",
    "        X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], number_of_steps, number_of_features))\n",
    "        history = cnn_model.fit(X_train_reshaped, y_oversampled, validation_split = 0.01,\n",
    "                                epochs = 300, batch_size = 32, verbose = 1, callbacks = [es])\n",
    "        _, train_accuracy = cnn_model.evaluate(X_train_reshaped, y_oversampled, verbose = 0)\n",
    "        _, test_accuracy = cnn_model.evaluate(X_test_reshaped, y_arr[test_index], verbose = 0)\n",
    "        train_accuracy_by_fold.append(train_accuracy)\n",
    "        test_accuracy_by_fold.append(test_accuracy)\n",
    "        history_by_fold.append(history)\n",
    "        y_predclass_for_report.extend(np.argmax(cnn_model.predict(X_test_reshaped), axis = 1))\n",
    "        y_testclass_for_report.extend(y_arr[test_index])\n",
    "        fold_number += 1\n",
    "    elapsed_seconds = time.time() - start_time\n",
    "    print(\"\\nTime taken for training: \", time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_seconds)))\n",
    "    print(\"\\n\")\n",
    "    # Show metrics.\n",
    "    for i in range(len(history_by_fold)):\n",
    "        print(\"Fold {} - Train Accuracy {:.4f} - Test Accuracy {:.4f}\".format((i + 1),\n",
    "              train_accuracy_by_fold[i], test_accuracy_by_fold[i]))\n",
    "    print(\"\\nMean Train Accuracy: {:.4f} \".format(np.mean(train_accuracy_by_fold)))\n",
    "    print(\"Mean Test Accuracy: {:.4f} \".format(np.mean(test_accuracy_by_fold)))\n",
    "    print(\"\\nEvaluate other metrics:\")\n",
    "    print(classification_report(y_testclass_for_report, y_predclass_for_report, zero_division = 0))\n",
    "    return history_by_fold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258715ac",
   "metadata": {},
   "source": [
    "#### Train a Convolutional Neural Network model and evaluate the metrics.\n",
    "- Layer architecture => Conv1D (64) + Conv1D (32) + Conv1D (16) + MaxPooling1D + Dense (32) + Dense (11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e887613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting build_time_window_structure function...\n",
      "Quantity of samples (features) =>  1200\n",
      "Quantity os samples (labels) =>  1200\n",
      "Finishing build_time_window_structure function.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1278</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1276</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,176</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1274</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,552</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">637</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10192</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">326,176</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">363</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1278\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │         \u001b[38;5;34m6,208\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1276\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │         \u001b[38;5;34m6,176\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1274\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │         \u001b[38;5;34m1,552\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m637\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10192\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │       \u001b[38;5;34m326,176\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m)             │           \u001b[38;5;34m363\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">340,475</span> (1.30 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m340,475\u001b[0m (1.30 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">340,475</span> (1.30 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m340,475\u001b[0m (1.30 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training...\n",
      "\n",
      "Training fold 1\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "2970 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({np.int64(6): 270, np.int64(7): 270, np.int64(4): 270, np.int64(3): 270, np.int64(5): 270, np.int64(8): 270, np.int64(9): 270, np.int64(2): 270, np.int64(10): 270, np.int64(1): 270, np.int64(0): 270})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.2097 - loss: 2.6342 - val_accuracy: 1.0000 - val_loss: 0.0198\n",
      "Epoch 2/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.7652 - loss: 0.8288 - val_accuracy: 1.0000 - val_loss: 0.0195\n",
      "Epoch 3/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.9595 - loss: 0.1808 - val_accuracy: 1.0000 - val_loss: 4.3679e-04\n",
      "Epoch 4/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9937 - loss: 0.0537 - val_accuracy: 1.0000 - val_loss: 0.0023\n",
      "Epoch 5/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0130 - val_accuracy: 1.0000 - val_loss: 4.4749e-05\n",
      "Epoch 6/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 1.0000 - val_loss: 4.0105e-05\n",
      "Epoch 7/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 1.0000 - val_loss: 2.1016e-05\n",
      "Epoch 8/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 1.0000 - val_loss: 2.0174e-05\n",
      "Epoch 9/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 9.6239e-04 - val_accuracy: 1.0000 - val_loss: 1.8878e-05\n",
      "Epoch 10/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 7.1915e-04 - val_accuracy: 1.0000 - val_loss: 1.6284e-05\n",
      "Epoch 11/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 5.9135e-04 - val_accuracy: 1.0000 - val_loss: 1.2239e-05\n",
      "Epoch 12/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 5.1451e-04 - val_accuracy: 1.0000 - val_loss: 1.0725e-05\n",
      "Epoch 13/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 4.0808e-04 - val_accuracy: 1.0000 - val_loss: 1.4345e-05\n",
      "Epoch 14/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 3.5812e-04 - val_accuracy: 1.0000 - val_loss: 1.1003e-05\n",
      "Epoch 15/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 3.0018e-04 - val_accuracy: 1.0000 - val_loss: 1.1074e-05\n",
      "Epoch 16/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 2.6164e-04 - val_accuracy: 1.0000 - val_loss: 8.3684e-06\n",
      "Epoch 17/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 2.2584e-04 - val_accuracy: 1.0000 - val_loss: 8.1697e-06\n",
      "Epoch 18/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 1.9267e-04 - val_accuracy: 1.0000 - val_loss: 7.2558e-06\n",
      "Epoch 19/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 1.8625e-04 - val_accuracy: 1.0000 - val_loss: 6.3618e-06\n",
      "Epoch 20/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 1.6847e-04 - val_accuracy: 1.0000 - val_loss: 5.1538e-06\n",
      "Epoch 21/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.4262e-04 - val_accuracy: 1.0000 - val_loss: 5.3763e-06\n",
      "Epoch 22/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 1.3497e-04 - val_accuracy: 1.0000 - val_loss: 5.2611e-06\n",
      "Epoch 23/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 1.1028e-04 - val_accuracy: 1.0000 - val_loss: 5.6902e-06\n",
      "Epoch 24/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 1.0770e-04 - val_accuracy: 1.0000 - val_loss: 3.6001e-06\n",
      "Epoch 25/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 9.7772e-05 - val_accuracy: 1.0000 - val_loss: 3.4372e-06\n",
      "Epoch 26/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 9.4488e-05 - val_accuracy: 1.0000 - val_loss: 3.8187e-06\n",
      "Epoch 27/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 8.3474e-05 - val_accuracy: 1.0000 - val_loss: 3.3259e-06\n",
      "Epoch 28/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 7.5652e-05 - val_accuracy: 1.0000 - val_loss: 3.0597e-06\n",
      "Epoch 29/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 7.0181e-05 - val_accuracy: 1.0000 - val_loss: 2.9127e-06\n",
      "Epoch 30/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 6.2895e-05 - val_accuracy: 1.0000 - val_loss: 2.7418e-06\n",
      "Epoch 31/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 5.5984e-05 - val_accuracy: 1.0000 - val_loss: 2.7617e-06\n",
      "Epoch 32/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 5.9333e-05 - val_accuracy: 1.0000 - val_loss: 2.2213e-06\n",
      "Epoch 33/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 5.2372e-05 - val_accuracy: 1.0000 - val_loss: 2.1815e-06\n",
      "Epoch 34/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 4.9133e-05 - val_accuracy: 1.0000 - val_loss: 2.2689e-06\n",
      "Epoch 35/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 4.5762e-05 - val_accuracy: 1.0000 - val_loss: 1.6967e-06\n",
      "Epoch 36/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 4.1057e-05 - val_accuracy: 1.0000 - val_loss: 1.9868e-06\n",
      "Epoch 37/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 3.8876e-05 - val_accuracy: 1.0000 - val_loss: 1.5775e-06\n",
      "Epoch 38/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 3.4486e-05 - val_accuracy: 1.0000 - val_loss: 1.6769e-06\n",
      "Epoch 39/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 3.2829e-05 - val_accuracy: 1.0000 - val_loss: 1.6371e-06\n",
      "Epoch 40/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 3.0195e-05 - val_accuracy: 1.0000 - val_loss: 1.1563e-06\n",
      "Epoch 41/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 2.8982e-05 - val_accuracy: 1.0000 - val_loss: 1.2199e-06\n",
      "Epoch 42/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 2.7409e-05 - val_accuracy: 1.0000 - val_loss: 1.0649e-06\n",
      "Epoch 43/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 2.5855e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-06\n",
      "Epoch 44/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 2.3775e-05 - val_accuracy: 1.0000 - val_loss: 8.7817e-07\n",
      "Epoch 45/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 2.3501e-05 - val_accuracy: 1.0000 - val_loss: 8.9009e-07\n",
      "Epoch 46/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 2.0889e-05 - val_accuracy: 1.0000 - val_loss: 9.9738e-07\n",
      "Epoch 47/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 1.9991e-05 - val_accuracy: 1.0000 - val_loss: 9.8944e-07\n",
      "Epoch 48/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 2.0337e-05 - val_accuracy: 1.0000 - val_loss: 7.1923e-07\n",
      "Epoch 49/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 1.8601e-05 - val_accuracy: 1.0000 - val_loss: 6.3976e-07\n",
      "Epoch 50/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 1.6407e-05 - val_accuracy: 1.0000 - val_loss: 7.5102e-07\n",
      "Epoch 51/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 1.5966e-05 - val_accuracy: 1.0000 - val_loss: 7.0731e-07\n",
      "Epoch 52/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 1.4954e-05 - val_accuracy: 1.0000 - val_loss: 6.6757e-07\n",
      "Epoch 53/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 1.3742e-05 - val_accuracy: 1.0000 - val_loss: 5.8015e-07\n",
      "Epoch 54/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 1.3543e-05 - val_accuracy: 1.0000 - val_loss: 6.1989e-07\n",
      "Epoch 55/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.3177e-05 - val_accuracy: 1.0000 - val_loss: 5.4836e-07\n",
      "Epoch 56/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 1.2106e-05 - val_accuracy: 1.0000 - val_loss: 5.1260e-07\n",
      "Epoch 57/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 1.1594e-05 - val_accuracy: 1.0000 - val_loss: 4.8876e-07\n",
      "Epoch 58/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 1.0733e-05 - val_accuracy: 1.0000 - val_loss: 5.0465e-07\n",
      "Epoch 59/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 9.2804e-06 - val_accuracy: 1.0000 - val_loss: 4.6492e-07\n",
      "Epoch 60/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 9.4789e-06 - val_accuracy: 1.0000 - val_loss: 4.0134e-07\n",
      "Epoch 61/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 8.7588e-06 - val_accuracy: 1.0000 - val_loss: 3.7750e-07\n",
      "Epoch 62/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 8.3260e-06 - val_accuracy: 1.0000 - val_loss: 4.1723e-07\n",
      "Epoch 63/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 7.9980e-06 - val_accuracy: 1.0000 - val_loss: 3.0994e-07\n",
      "Epoch 64/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 7.4042e-06 - val_accuracy: 1.0000 - val_loss: 2.9405e-07\n",
      "Epoch 65/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 7.0584e-06 - val_accuracy: 1.0000 - val_loss: 3.1392e-07\n",
      "Epoch 66/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 6.8870e-06 - val_accuracy: 1.0000 - val_loss: 2.8610e-07\n",
      "Epoch 67/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 6.2892e-06 - val_accuracy: 1.0000 - val_loss: 3.0597e-07\n",
      "Epoch 68/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 6.0041e-06 - val_accuracy: 1.0000 - val_loss: 2.6226e-07\n",
      "Epoch 69/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 6.1471e-06 - val_accuracy: 1.0000 - val_loss: 2.2650e-07\n",
      "Epoch 70/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 5.5551e-06 - val_accuracy: 1.0000 - val_loss: 2.7021e-07\n",
      "Epoch 71/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 5.4527e-06 - val_accuracy: 1.0000 - val_loss: 2.0663e-07\n",
      "Epoch 72/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 4.8743e-06 - val_accuracy: 1.0000 - val_loss: 2.1855e-07\n",
      "Epoch 73/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 4.4891e-06 - val_accuracy: 1.0000 - val_loss: 2.0266e-07\n",
      "Epoch 74/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 4.3080e-06 - val_accuracy: 1.0000 - val_loss: 2.3047e-07\n",
      "Epoch 75/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 3.9809e-06 - val_accuracy: 1.0000 - val_loss: 1.9868e-07\n",
      "Epoch 76/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 4.1408e-06 - val_accuracy: 1.0000 - val_loss: 1.4702e-07\n",
      "Epoch 77/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 3.6698e-06 - val_accuracy: 1.0000 - val_loss: 1.7087e-07\n",
      "Epoch 78/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 3.5382e-06 - val_accuracy: 1.0000 - val_loss: 1.5497e-07\n",
      "Epoch 79/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 3.4466e-06 - val_accuracy: 1.0000 - val_loss: 1.7087e-07\n",
      "Epoch 80/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 3.4105e-06 - val_accuracy: 1.0000 - val_loss: 1.4305e-07\n",
      "Epoch 81/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 2.9120e-06 - val_accuracy: 1.0000 - val_loss: 1.5497e-07\n",
      "Epoch 82/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 2.9717e-06 - val_accuracy: 1.0000 - val_loss: 1.3908e-07\n",
      "Epoch 83/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 2.9370e-06 - val_accuracy: 1.0000 - val_loss: 1.2318e-07\n",
      "Epoch 84/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 2.6635e-06 - val_accuracy: 1.0000 - val_loss: 1.1126e-07\n",
      "Epoch 85/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 2.5891e-06 - val_accuracy: 1.0000 - val_loss: 1.3908e-07\n",
      "Epoch 86/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 2.4284e-06 - val_accuracy: 1.0000 - val_loss: 1.1524e-07\n",
      "Epoch 87/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 2.1982e-06 - val_accuracy: 1.0000 - val_loss: 9.9341e-08\n",
      "Epoch 88/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 2.2101e-06 - val_accuracy: 1.0000 - val_loss: 8.7420e-08\n",
      "Epoch 89/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.9768e-06 - val_accuracy: 1.0000 - val_loss: 8.3446e-08\n",
      "Epoch 90/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.8996e-06 - val_accuracy: 1.0000 - val_loss: 9.1394e-08\n",
      "Epoch 91/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.8006e-06 - val_accuracy: 1.0000 - val_loss: 8.7420e-08\n",
      "Epoch 92/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.7016e-06 - val_accuracy: 1.0000 - val_loss: 7.9473e-08\n",
      "Epoch 93/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.7118e-06 - val_accuracy: 1.0000 - val_loss: 8.3446e-08\n",
      "Epoch 94/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.5900e-06 - val_accuracy: 1.0000 - val_loss: 7.1526e-08\n",
      "Epoch 95/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.4905e-06 - val_accuracy: 1.0000 - val_loss: 6.7552e-08\n",
      "Epoch 96/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.4502e-06 - val_accuracy: 1.0000 - val_loss: 5.9605e-08\n",
      "Epoch 97/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 1.3403e-06 - val_accuracy: 1.0000 - val_loss: 5.1657e-08\n",
      "Epoch 98/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.2980e-06 - val_accuracy: 1.0000 - val_loss: 5.1657e-08\n",
      "Epoch 99/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.2239e-06 - val_accuracy: 1.0000 - val_loss: 5.9605e-08\n",
      "Epoch 100/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 1.1272e-06 - val_accuracy: 1.0000 - val_loss: 5.1657e-08\n",
      "Epoch 101/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.0113e-06 - val_accuracy: 1.0000 - val_loss: 5.1657e-08\n",
      "Epoch 102/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.0348e-06 - val_accuracy: 1.0000 - val_loss: 5.1657e-08\n",
      "Epoch 103/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 9.6251e-07 - val_accuracy: 1.0000 - val_loss: 4.3710e-08\n",
      "Epoch 104/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 1.0261e-06 - val_accuracy: 1.0000 - val_loss: 3.9736e-08\n",
      "Epoch 105/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 8.7475e-07 - val_accuracy: 1.0000 - val_loss: 3.5763e-08\n",
      "Epoch 106/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 8.4404e-07 - val_accuracy: 1.0000 - val_loss: 3.9736e-08\n",
      "Epoch 107/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 7.7286e-07 - val_accuracy: 1.0000 - val_loss: 3.5763e-08\n",
      "Epoch 108/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 7.8913e-07 - val_accuracy: 1.0000 - val_loss: 1.9868e-08\n",
      "Epoch 109/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 7.6771e-07 - val_accuracy: 1.0000 - val_loss: 3.5763e-08\n",
      "Epoch 110/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 7.1581e-07 - val_accuracy: 1.0000 - val_loss: 2.7815e-08\n",
      "Epoch 111/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 6.7598e-07 - val_accuracy: 1.0000 - val_loss: 1.9868e-08\n",
      "Epoch 112/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 6.4079e-07 - val_accuracy: 1.0000 - val_loss: 1.9868e-08\n",
      "Epoch 113/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 6.1660e-07 - val_accuracy: 1.0000 - val_loss: 1.9868e-08\n",
      "Epoch 114/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 5.6183e-07 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 115/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 5.1798e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 116/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 5.3930e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 117/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 4.9504e-07 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 118/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 4.8017e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 119/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 4.2946e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 120/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 4.0135e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 121/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 3.7362e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 122/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 3.9309e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 123/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 3.3494e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 124/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 3.4192e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 125/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 3.1793e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 126/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 3.0732e-07 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 127/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 2.9127e-07 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 128/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 2.7656e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 129/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 2.7001e-07 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 130/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 2.5557e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 131/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 2.4660e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 132/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 2.1710e-07 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 133/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 2.1964e-07 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 134/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 2.0757e-07 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 135/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.9587e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 136/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 1.8052e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 137/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 1.6844e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 138/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.6682e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 139/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 1.6596e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 140/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.4921e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 141/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.4811e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 142/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 1.3400e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 143/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.2732e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 144/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.2196e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 145/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 1.1599e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 146/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.0927e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 147/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.0690e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 148/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 9.7010e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 149/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 9.6632e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 150/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 9.5303e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 151/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 8.4126e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 152/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 8.2948e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 153/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 8.0590e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 154/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 7.6220e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 155/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 7.4414e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 156/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 6.6305e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 157/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 6.3662e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 158/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 6.0081e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 159/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 6.0073e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 160/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 5.4923e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 161/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 5.2662e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 161: early stopping\n",
      "Restoring model weights from the end of the best epoch: 131.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\n",
      "Training fold 2\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "2970 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({np.int64(6): 270, np.int64(7): 270, np.int64(4): 270, np.int64(3): 270, np.int64(5): 270, np.int64(8): 270, np.int64(9): 270, np.int64(2): 270, np.int64(10): 270, np.int64(1): 270, np.int64(0): 270})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.2935 - loss: 5.9184 - val_accuracy: 1.0000 - val_loss: 2.0474e-04\n",
      "Epoch 2/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.7851 - loss: 0.6910 - val_accuracy: 1.0000 - val_loss: 0.0259\n",
      "Epoch 3/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9070 - loss: 0.2918 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
      "Epoch 4/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9684 - loss: 0.1131 - val_accuracy: 1.0000 - val_loss: 1.4462e-04\n",
      "Epoch 5/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9929 - loss: 0.0406 - val_accuracy: 1.0000 - val_loss: 4.5194e-04\n",
      "Epoch 6/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9982 - loss: 0.0122 - val_accuracy: 1.0000 - val_loss: 1.1078e-05\n",
      "Epoch 7/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.9999 - loss: 0.0047 - val_accuracy: 1.0000 - val_loss: 4.3431e-06\n",
      "Epoch 8/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.9996 - loss: 0.0027 - val_accuracy: 1.0000 - val_loss: 7.3668e-06\n",
      "Epoch 9/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 1.0000 - val_loss: 1.1423e-05\n",
      "Epoch 10/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 1.0000 - val_loss: 7.7798e-06\n",
      "Epoch 11/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 6.4714e-04 - val_accuracy: 1.0000 - val_loss: 5.6740e-06\n",
      "Epoch 12/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 5.6214e-04 - val_accuracy: 1.0000 - val_loss: 4.7443e-06\n",
      "Epoch 13/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 4.0458e-04 - val_accuracy: 1.0000 - val_loss: 4.6728e-06\n",
      "Epoch 14/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 3.3306e-04 - val_accuracy: 1.0000 - val_loss: 4.5774e-06\n",
      "Epoch 15/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 2.7726e-04 - val_accuracy: 1.0000 - val_loss: 3.3894e-06\n",
      "Epoch 16/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 2.4126e-04 - val_accuracy: 1.0000 - val_loss: 3.4013e-06\n",
      "Epoch 17/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 2.1450e-04 - val_accuracy: 1.0000 - val_loss: 3.2503e-06\n",
      "Epoch 18/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.7823e-04 - val_accuracy: 1.0000 - val_loss: 2.8451e-06\n",
      "Epoch 19/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.3686e-04 - val_accuracy: 1.0000 - val_loss: 2.5431e-06\n",
      "Epoch 20/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.1669e-04 - val_accuracy: 1.0000 - val_loss: 2.3444e-06\n",
      "Epoch 21/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 9.7084e-05 - val_accuracy: 1.0000 - val_loss: 2.1139e-06\n",
      "Epoch 22/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 7.6446e-05 - val_accuracy: 1.0000 - val_loss: 1.7285e-06\n",
      "Epoch 23/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 6.9665e-05 - val_accuracy: 1.0000 - val_loss: 1.5020e-06\n",
      "Epoch 24/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 5.0030e-05 - val_accuracy: 1.0000 - val_loss: 1.3351e-06\n",
      "Epoch 25/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 4.5885e-05 - val_accuracy: 1.0000 - val_loss: 1.2080e-06\n",
      "Epoch 26/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 3.5978e-05 - val_accuracy: 1.0000 - val_loss: 1.0649e-06\n",
      "Epoch 27/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 2.9231e-05 - val_accuracy: 1.0000 - val_loss: 9.0598e-07\n",
      "Epoch 28/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 2.3820e-05 - val_accuracy: 1.0000 - val_loss: 7.7485e-07\n",
      "Epoch 29/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.8132e-05 - val_accuracy: 1.0000 - val_loss: 6.0796e-07\n",
      "Epoch 30/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 1.4089e-05 - val_accuracy: 1.0000 - val_loss: 4.8478e-07\n",
      "Epoch 31/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 1.2949e-05 - val_accuracy: 1.0000 - val_loss: 4.3313e-07\n",
      "Epoch 32/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.1734e-05 - val_accuracy: 1.0000 - val_loss: 3.3378e-07\n",
      "Epoch 33/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.0215e-05 - val_accuracy: 1.0000 - val_loss: 2.9802e-07\n",
      "Epoch 34/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 8.4125e-06 - val_accuracy: 1.0000 - val_loss: 2.4239e-07\n",
      "Epoch 35/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 7.1903e-06 - val_accuracy: 1.0000 - val_loss: 2.2252e-07\n",
      "Epoch 36/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 5.3350e-06 - val_accuracy: 1.0000 - val_loss: 1.9868e-07\n",
      "Epoch 37/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 5.5409e-06 - val_accuracy: 1.0000 - val_loss: 1.8676e-07\n",
      "Epoch 38/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 4.3352e-06 - val_accuracy: 1.0000 - val_loss: 1.7881e-07\n",
      "Epoch 39/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 3.8088e-06 - val_accuracy: 1.0000 - val_loss: 1.7484e-07\n",
      "Epoch 40/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 3.7949e-06 - val_accuracy: 1.0000 - val_loss: 1.6689e-07\n",
      "Epoch 41/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 3.6067e-06 - val_accuracy: 1.0000 - val_loss: 1.6292e-07\n",
      "Epoch 42/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 3.1557e-06 - val_accuracy: 1.0000 - val_loss: 1.6689e-07\n",
      "Epoch 43/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 2.8983e-06 - val_accuracy: 1.0000 - val_loss: 1.7087e-07\n",
      "Epoch 44/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 2.6576e-06 - val_accuracy: 1.0000 - val_loss: 1.5895e-07\n",
      "Epoch 45/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 2.3257e-06 - val_accuracy: 1.0000 - val_loss: 1.7087e-07\n",
      "Epoch 46/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 2.1979e-06 - val_accuracy: 1.0000 - val_loss: 1.7881e-07\n",
      "Epoch 47/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.9784e-06 - val_accuracy: 1.0000 - val_loss: 1.9471e-07\n",
      "Epoch 48/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 2.0315e-06 - val_accuracy: 1.0000 - val_loss: 2.1458e-07\n",
      "Epoch 49/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 1.6301e-06 - val_accuracy: 1.0000 - val_loss: 2.3842e-07\n",
      "Epoch 50/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 1.5726e-06 - val_accuracy: 1.0000 - val_loss: 2.4637e-07\n",
      "Epoch 51/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.6881e-06 - val_accuracy: 1.0000 - val_loss: 2.9008e-07\n",
      "Epoch 52/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.4668e-06 - val_accuracy: 1.0000 - val_loss: 3.3378e-07\n",
      "Epoch 53/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.3833e-06 - val_accuracy: 1.0000 - val_loss: 3.5365e-07\n",
      "Epoch 54/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 1.2507e-06 - val_accuracy: 1.0000 - val_loss: 4.0928e-07\n",
      "Epoch 55/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 1.1877e-06 - val_accuracy: 1.0000 - val_loss: 4.4902e-07\n",
      "Epoch 56/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.0713e-06 - val_accuracy: 1.0000 - val_loss: 4.3312e-07\n",
      "Epoch 57/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.0506e-06 - val_accuracy: 1.0000 - val_loss: 5.5233e-07\n",
      "Epoch 58/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 9.0592e-07 - val_accuracy: 1.0000 - val_loss: 5.6823e-07\n",
      "Epoch 59/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 8.7954e-07 - val_accuracy: 1.0000 - val_loss: 6.1591e-07\n",
      "Epoch 60/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 8.4252e-07 - val_accuracy: 1.0000 - val_loss: 6.8743e-07\n",
      "Epoch 61/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 8.0951e-07 - val_accuracy: 1.0000 - val_loss: 7.8280e-07\n",
      "Epoch 62/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 7.5889e-07 - val_accuracy: 1.0000 - val_loss: 7.9869e-07\n",
      "Epoch 63/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 7.3968e-07 - val_accuracy: 1.0000 - val_loss: 7.8280e-07\n",
      "Epoch 64/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 6.3601e-07 - val_accuracy: 1.0000 - val_loss: 9.0201e-07\n",
      "Epoch 65/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 6.5193e-07 - val_accuracy: 1.0000 - val_loss: 9.8545e-07\n",
      "Epoch 66/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 6.0571e-07 - val_accuracy: 1.0000 - val_loss: 9.9340e-07\n",
      "Epoch 67/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 6.0359e-07 - val_accuracy: 1.0000 - val_loss: 1.0252e-06\n",
      "Epoch 68/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 5.6362e-07 - val_accuracy: 1.0000 - val_loss: 1.0967e-06\n",
      "Epoch 69/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 5.0383e-07 - val_accuracy: 1.0000 - val_loss: 1.2994e-06\n",
      "Epoch 70/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 5.0345e-07 - val_accuracy: 1.0000 - val_loss: 1.3550e-06\n",
      "Epoch 71/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 4.5413e-07 - val_accuracy: 1.0000 - val_loss: 1.5258e-06\n",
      "Epoch 72/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 4.8588e-07 - val_accuracy: 1.0000 - val_loss: 1.4225e-06\n",
      "Epoch 73/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 4.4063e-07 - val_accuracy: 1.0000 - val_loss: 1.7245e-06\n",
      "Epoch 74/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 4.3579e-07 - val_accuracy: 1.0000 - val_loss: 1.6371e-06\n",
      "Epoch 74: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\n",
      "Training fold 3\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "2970 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({np.int64(6): 270, np.int64(7): 270, np.int64(4): 270, np.int64(3): 270, np.int64(5): 270, np.int64(8): 270, np.int64(9): 270, np.int64(2): 270, np.int64(10): 270, np.int64(1): 270, np.int64(0): 270})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.8135 - loss: 0.7501 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
      "Epoch 2/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9449 - loss: 0.1734 - val_accuracy: 1.0000 - val_loss: 7.0456e-04\n",
      "Epoch 3/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9862 - loss: 0.0457 - val_accuracy: 1.0000 - val_loss: 1.2237e-04\n",
      "Epoch 4/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9998 - loss: 0.0103 - val_accuracy: 1.0000 - val_loss: 4.2001e-05\n",
      "Epoch 5/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9997 - loss: 0.0017 - val_accuracy: 1.0000 - val_loss: 5.7414e-06\n",
      "Epoch 6/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 1.0000 - val_loss: 9.9093e-06\n",
      "Epoch 7/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 4.5309e-04 - val_accuracy: 1.0000 - val_loss: 9.8416e-06\n",
      "Epoch 8/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 3.2772e-04 - val_accuracy: 1.0000 - val_loss: 1.0481e-05\n",
      "Epoch 9/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.9964e-04 - val_accuracy: 1.0000 - val_loss: 1.1442e-05\n",
      "Epoch 10/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.7354e-04 - val_accuracy: 1.0000 - val_loss: 1.0600e-05\n",
      "Epoch 11/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.6949e-04 - val_accuracy: 1.0000 - val_loss: 9.4561e-06\n",
      "Epoch 12/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 9.3705e-05 - val_accuracy: 1.0000 - val_loss: 8.9516e-06\n",
      "Epoch 13/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.0655e-04 - val_accuracy: 1.0000 - val_loss: 8.7887e-06\n",
      "Epoch 14/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 7.4799e-05 - val_accuracy: 1.0000 - val_loss: 7.2512e-06\n",
      "Epoch 15/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 7.4394e-05 - val_accuracy: 1.0000 - val_loss: 6.8102e-06\n",
      "Epoch 16/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 6.2125e-05 - val_accuracy: 1.0000 - val_loss: 6.0514e-06\n",
      "Epoch 17/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 6.3364e-05 - val_accuracy: 1.0000 - val_loss: 5.5707e-06\n",
      "Epoch 18/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 4.9587e-05 - val_accuracy: 1.0000 - val_loss: 5.2449e-06\n",
      "Epoch 19/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 4.4726e-05 - val_accuracy: 1.0000 - val_loss: 4.3747e-06\n",
      "Epoch 20/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 3.9318e-05 - val_accuracy: 1.0000 - val_loss: 4.0291e-06\n",
      "Epoch 21/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 3.0373e-05 - val_accuracy: 1.0000 - val_loss: 3.7509e-06\n",
      "Epoch 22/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 2.9085e-05 - val_accuracy: 1.0000 - val_loss: 3.4490e-06\n",
      "Epoch 23/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 2.7585e-05 - val_accuracy: 1.0000 - val_loss: 3.0834e-06\n",
      "Epoch 24/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 2.9022e-05 - val_accuracy: 1.0000 - val_loss: 2.8212e-06\n",
      "Epoch 25/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 2.1185e-05 - val_accuracy: 1.0000 - val_loss: 2.6026e-06\n",
      "Epoch 26/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 2.3302e-05 - val_accuracy: 1.0000 - val_loss: 2.2609e-06\n",
      "Epoch 27/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 2.1323e-05 - val_accuracy: 1.0000 - val_loss: 2.1497e-06\n",
      "Epoch 28/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 2.0591e-05 - val_accuracy: 1.0000 - val_loss: 1.9590e-06\n",
      "Epoch 29/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.7165e-05 - val_accuracy: 1.0000 - val_loss: 1.7881e-06\n",
      "Epoch 30/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.8902e-05 - val_accuracy: 1.0000 - val_loss: 1.6967e-06\n",
      "Epoch 31/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.3616e-05 - val_accuracy: 1.0000 - val_loss: 1.5934e-06\n",
      "Epoch 32/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.3549e-05 - val_accuracy: 1.0000 - val_loss: 1.5338e-06\n",
      "Epoch 33/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.2806e-05 - val_accuracy: 1.0000 - val_loss: 1.4146e-06\n",
      "Epoch 34/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 1.0768e-05 - val_accuracy: 1.0000 - val_loss: 1.2437e-06\n",
      "Epoch 35/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.3812e-05 - val_accuracy: 1.0000 - val_loss: 1.1643e-06\n",
      "Epoch 36/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 1.2550e-05 - val_accuracy: 1.0000 - val_loss: 1.1206e-06\n",
      "Epoch 37/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 8.1833e-06 - val_accuracy: 1.0000 - val_loss: 1.0172e-06\n",
      "Epoch 38/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 7.8460e-06 - val_accuracy: 1.0000 - val_loss: 9.2982e-07\n",
      "Epoch 39/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 8.4077e-06 - val_accuracy: 1.0000 - val_loss: 8.3048e-07\n",
      "Epoch 40/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 8.3518e-06 - val_accuracy: 1.0000 - val_loss: 7.7883e-07\n",
      "Epoch 41/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 7.5369e-06 - val_accuracy: 1.0000 - val_loss: 6.7949e-07\n",
      "Epoch 42/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 6.1256e-06 - val_accuracy: 1.0000 - val_loss: 6.5565e-07\n",
      "Epoch 43/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 6.3098e-06 - val_accuracy: 1.0000 - val_loss: 5.5631e-07\n",
      "Epoch 44/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 5.6436e-06 - val_accuracy: 1.0000 - val_loss: 5.0862e-07\n",
      "Epoch 45/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 5.3054e-06 - val_accuracy: 1.0000 - val_loss: 4.6889e-07\n",
      "Epoch 46/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 4.7683e-06 - val_accuracy: 1.0000 - val_loss: 4.1326e-07\n",
      "Epoch 47/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 4.5071e-06 - val_accuracy: 1.0000 - val_loss: 3.6160e-07\n",
      "Epoch 48/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 4.6164e-06 - val_accuracy: 1.0000 - val_loss: 3.4173e-07\n",
      "Epoch 49/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 4.0025e-06 - val_accuracy: 1.0000 - val_loss: 3.0994e-07\n",
      "Epoch 50/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 3.8612e-06 - val_accuracy: 1.0000 - val_loss: 2.8213e-07\n",
      "Epoch 51/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 3.4361e-06 - val_accuracy: 1.0000 - val_loss: 2.5431e-07\n",
      "Epoch 52/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 3.0681e-06 - val_accuracy: 1.0000 - val_loss: 2.3842e-07\n",
      "Epoch 53/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 3.3995e-06 - val_accuracy: 1.0000 - val_loss: 2.1458e-07\n",
      "Epoch 54/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 2.9665e-06 - val_accuracy: 1.0000 - val_loss: 1.8676e-07\n",
      "Epoch 55/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 2.9355e-06 - val_accuracy: 1.0000 - val_loss: 1.8279e-07\n",
      "Epoch 56/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 2.5061e-06 - val_accuracy: 1.0000 - val_loss: 1.5895e-07\n",
      "Epoch 57/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 2.5704e-06 - val_accuracy: 1.0000 - val_loss: 1.5100e-07\n",
      "Epoch 58/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 2.6558e-06 - val_accuracy: 1.0000 - val_loss: 1.3908e-07\n",
      "Epoch 59/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 2.3117e-06 - val_accuracy: 1.0000 - val_loss: 1.3113e-07\n",
      "Epoch 60/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 2.2834e-06 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 61/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 2.1490e-06 - val_accuracy: 1.0000 - val_loss: 1.0729e-07\n",
      "Epoch 62/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.9573e-06 - val_accuracy: 1.0000 - val_loss: 1.0331e-07\n",
      "Epoch 63/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.9249e-06 - val_accuracy: 1.0000 - val_loss: 9.1394e-08\n",
      "Epoch 64/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.7475e-06 - val_accuracy: 1.0000 - val_loss: 8.7420e-08\n",
      "Epoch 65/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.7038e-06 - val_accuracy: 1.0000 - val_loss: 7.9473e-08\n",
      "Epoch 66/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.7119e-06 - val_accuracy: 1.0000 - val_loss: 7.1526e-08\n",
      "Epoch 67/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.4679e-06 - val_accuracy: 1.0000 - val_loss: 7.1526e-08\n",
      "Epoch 68/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.4205e-06 - val_accuracy: 1.0000 - val_loss: 6.3578e-08\n",
      "Epoch 69/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.3085e-06 - val_accuracy: 1.0000 - val_loss: 5.9605e-08\n",
      "Epoch 70/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.2040e-06 - val_accuracy: 1.0000 - val_loss: 5.1657e-08\n",
      "Epoch 71/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.1274e-06 - val_accuracy: 1.0000 - val_loss: 5.1657e-08\n",
      "Epoch 72/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 1.2850e-06 - val_accuracy: 1.0000 - val_loss: 4.7684e-08\n",
      "Epoch 73/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.1698e-06 - val_accuracy: 1.0000 - val_loss: 4.3710e-08\n",
      "Epoch 74/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.0022e-06 - val_accuracy: 1.0000 - val_loss: 4.3710e-08\n",
      "Epoch 75/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 9.9820e-07 - val_accuracy: 1.0000 - val_loss: 3.9736e-08\n",
      "Epoch 76/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 1.0046e-06 - val_accuracy: 1.0000 - val_loss: 3.9736e-08\n",
      "Epoch 77/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 1.0014e-06 - val_accuracy: 1.0000 - val_loss: 3.5763e-08\n",
      "Epoch 78/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 7.5943e-07 - val_accuracy: 1.0000 - val_loss: 3.5763e-08\n",
      "Epoch 79/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 8.1771e-07 - val_accuracy: 1.0000 - val_loss: 3.1789e-08\n",
      "Epoch 80/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 7.9566e-07 - val_accuracy: 1.0000 - val_loss: 3.1789e-08\n",
      "Epoch 81/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 7.4858e-07 - val_accuracy: 1.0000 - val_loss: 3.1789e-08\n",
      "Epoch 82/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 6.0945e-07 - val_accuracy: 1.0000 - val_loss: 2.7815e-08\n",
      "Epoch 83/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 6.1381e-07 - val_accuracy: 1.0000 - val_loss: 2.7815e-08\n",
      "Epoch 84/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 6.3764e-07 - val_accuracy: 1.0000 - val_loss: 2.3842e-08\n",
      "Epoch 85/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 6.1357e-07 - val_accuracy: 1.0000 - val_loss: 2.3842e-08\n",
      "Epoch 86/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 5.0251e-07 - val_accuracy: 1.0000 - val_loss: 2.3842e-08\n",
      "Epoch 87/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 5.5053e-07 - val_accuracy: 1.0000 - val_loss: 1.9868e-08\n",
      "Epoch 88/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 5.4747e-07 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 89/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 4.6807e-07 - val_accuracy: 1.0000 - val_loss: 1.9868e-08\n",
      "Epoch 90/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 4.1099e-07 - val_accuracy: 1.0000 - val_loss: 1.9868e-08\n",
      "Epoch 91/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 3.9935e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 92/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 4.0262e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 93/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 4.2132e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 94/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 3.7884e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 95/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 3.8822e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 96/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 3.2820e-07 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 97/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 3.0142e-07 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 98/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 3.0740e-07 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 99/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 2.8097e-07 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 100/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 2.4867e-07 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 101/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 2.5998e-07 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 102/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 2.2807e-07 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 103/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 2.2987e-07 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 104/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 2.1996e-07 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 105/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 2.3901e-07 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 106/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 2.0311e-07 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 107/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.8609e-07 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 108/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.7039e-07 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 109/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.5618e-07 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 110/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.7181e-07 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 111/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.5190e-07 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 112/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.4749e-07 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 113/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.2384e-07 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 114/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.2662e-07 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 115/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.1753e-07 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 116/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.2333e-07 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 117/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.1877e-07 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 118/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 1.2036e-07 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 119/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.0112e-07 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 120/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.0023e-07 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 121/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 9.4166e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 122/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 9.7974e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 123/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 8.7647e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 124/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 7.9248e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 125/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 8.3517e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 126/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 7.3770e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 127/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 7.1494e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 128/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 6.9431e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 129/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 6.9932e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 130/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 6.4658e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 131/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 5.6664e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 132/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 5.4501e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 133/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 4.9726e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 134/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 5.2092e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 135/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 4.6178e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 136/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 4.4525e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 137/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 4.2131e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 138/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 4.4935e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 139/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 3.9508e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 140/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 3.6588e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 141/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 3.7414e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 142/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 3.3842e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 143/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 3.2640e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 144/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 3.2229e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 145/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 2.8982e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 146/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 2.9391e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 147/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 2.6916e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 148/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 2.7434e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 149/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 2.5037e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 150/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 2.3665e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 151/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 2.3224e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 152/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 2.2147e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 153/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 2.1326e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 154/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 1.9021e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 154: early stopping\n",
      "Restoring model weights from the end of the best epoch: 124.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\n",
      "Training fold 4\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "2970 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({np.int64(6): 270, np.int64(7): 270, np.int64(4): 270, np.int64(3): 270, np.int64(5): 270, np.int64(8): 270, np.int64(9): 270, np.int64(2): 270, np.int64(10): 270, np.int64(1): 270, np.int64(0): 270})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.8975 - loss: 0.3615 - val_accuracy: 1.0000 - val_loss: 9.2033e-04\n",
      "Epoch 2/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9715 - loss: 0.0953 - val_accuracy: 1.0000 - val_loss: 6.3735e-05\n",
      "Epoch 3/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9940 - loss: 0.0209 - val_accuracy: 1.0000 - val_loss: 5.1655e-06\n",
      "Epoch 4/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9994 - loss: 0.0046 - val_accuracy: 1.0000 - val_loss: 1.5378e-06\n",
      "Epoch 5/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 8.2812e-04 - val_accuracy: 1.0000 - val_loss: 1.6729e-06\n",
      "Epoch 6/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 4.8199e-04 - val_accuracy: 1.0000 - val_loss: 1.1841e-06\n",
      "Epoch 7/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 3.1458e-04 - val_accuracy: 1.0000 - val_loss: 6.3578e-07\n",
      "Epoch 8/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 2.6603e-04 - val_accuracy: 1.0000 - val_loss: 4.3710e-07\n",
      "Epoch 9/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 2.0164e-04 - val_accuracy: 1.0000 - val_loss: 2.9007e-07\n",
      "Epoch 10/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 1.4176e-04 - val_accuracy: 1.0000 - val_loss: 3.0200e-07\n",
      "Epoch 11/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 1.3581e-04 - val_accuracy: 1.0000 - val_loss: 3.2981e-07\n",
      "Epoch 12/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 1.2856e-04 - val_accuracy: 1.0000 - val_loss: 3.0200e-07\n",
      "Epoch 13/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 8.2064e-05 - val_accuracy: 1.0000 - val_loss: 2.9007e-07\n",
      "Epoch 14/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 7.3654e-05 - val_accuracy: 1.0000 - val_loss: 2.9802e-07\n",
      "Epoch 15/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 6.7345e-05 - val_accuracy: 1.0000 - val_loss: 3.0200e-07\n",
      "Epoch 16/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 5.7236e-05 - val_accuracy: 1.0000 - val_loss: 2.6226e-07\n",
      "Epoch 17/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 5.9178e-05 - val_accuracy: 1.0000 - val_loss: 2.5829e-07\n",
      "Epoch 18/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 5.2444e-05 - val_accuracy: 1.0000 - val_loss: 2.2252e-07\n",
      "Epoch 19/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 4.5697e-05 - val_accuracy: 1.0000 - val_loss: 2.2650e-07\n",
      "Epoch 20/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 4.1157e-05 - val_accuracy: 1.0000 - val_loss: 2.3047e-07\n",
      "Epoch 21/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 3.6628e-05 - val_accuracy: 1.0000 - val_loss: 2.0663e-07\n",
      "Epoch 22/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 3.7460e-05 - val_accuracy: 1.0000 - val_loss: 2.0663e-07\n",
      "Epoch 23/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 3.4257e-05 - val_accuracy: 1.0000 - val_loss: 1.8676e-07\n",
      "Epoch 24/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 2.8588e-05 - val_accuracy: 1.0000 - val_loss: 1.6292e-07\n",
      "Epoch 25/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 2.9944e-05 - val_accuracy: 1.0000 - val_loss: 1.5100e-07\n",
      "Epoch 26/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 2.7322e-05 - val_accuracy: 1.0000 - val_loss: 1.5100e-07\n",
      "Epoch 27/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 2.2463e-05 - val_accuracy: 1.0000 - val_loss: 1.2318e-07\n",
      "Epoch 28/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 2.6437e-05 - val_accuracy: 1.0000 - val_loss: 1.2318e-07\n",
      "Epoch 29/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 1.9979e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 30/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 1.8049e-05 - val_accuracy: 1.0000 - val_loss: 1.1524e-07\n",
      "Epoch 31/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 1.6590e-05 - val_accuracy: 1.0000 - val_loss: 9.9341e-08\n",
      "Epoch 32/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.7262e-05 - val_accuracy: 1.0000 - val_loss: 9.5367e-08\n",
      "Epoch 33/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.6005e-05 - val_accuracy: 1.0000 - val_loss: 9.1394e-08\n",
      "Epoch 34/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.4878e-05 - val_accuracy: 1.0000 - val_loss: 7.9473e-08\n",
      "Epoch 35/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.3073e-05 - val_accuracy: 1.0000 - val_loss: 7.9473e-08\n",
      "Epoch 36/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 1.2085e-05 - val_accuracy: 1.0000 - val_loss: 7.1525e-08\n",
      "Epoch 37/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 1.2020e-05 - val_accuracy: 1.0000 - val_loss: 6.7552e-08\n",
      "Epoch 38/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 1.0450e-05 - val_accuracy: 1.0000 - val_loss: 5.5631e-08\n",
      "Epoch 39/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 1.0641e-05 - val_accuracy: 1.0000 - val_loss: 5.5631e-08\n",
      "Epoch 40/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.1375e-05 - val_accuracy: 1.0000 - val_loss: 5.1657e-08\n",
      "Epoch 41/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 8.5757e-06 - val_accuracy: 1.0000 - val_loss: 4.7684e-08\n",
      "Epoch 42/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 7.8772e-06 - val_accuracy: 1.0000 - val_loss: 4.7684e-08\n",
      "Epoch 43/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 7.6265e-06 - val_accuracy: 1.0000 - val_loss: 3.9736e-08\n",
      "Epoch 44/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 7.4357e-06 - val_accuracy: 1.0000 - val_loss: 3.5763e-08\n",
      "Epoch 45/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 7.9162e-06 - val_accuracy: 1.0000 - val_loss: 3.5763e-08\n",
      "Epoch 46/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 7.1303e-06 - val_accuracy: 1.0000 - val_loss: 3.1789e-08\n",
      "Epoch 47/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 6.9880e-06 - val_accuracy: 1.0000 - val_loss: 3.1789e-08\n",
      "Epoch 48/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 6.9067e-06 - val_accuracy: 1.0000 - val_loss: 2.7815e-08\n",
      "Epoch 49/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 6.0380e-06 - val_accuracy: 1.0000 - val_loss: 2.3842e-08\n",
      "Epoch 50/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 6.2877e-06 - val_accuracy: 1.0000 - val_loss: 1.9868e-08\n",
      "Epoch 51/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 5.5199e-06 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 52/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 5.3187e-06 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 53/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 4.6861e-06 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 54/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 4.7778e-06 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 55/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 4.9016e-06 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 56/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 4.0432e-06 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 57/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 3.8056e-06 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 58/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 3.8144e-06 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 59/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 3.4088e-06 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 60/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 3.3339e-06 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 61/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 3.2627e-06 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 62/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 2.9514e-06 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 63/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 2.8233e-06 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 64/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 2.9052e-06 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 65/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 2.8246e-06 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 66/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 2.4062e-06 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 67/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 2.3510e-06 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 68/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 2.0757e-06 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 69/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 2.0115e-06 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 70/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.9546e-06 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 71/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.9288e-06 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 72/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.8116e-06 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 73/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.6520e-06 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 74/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.6104e-06 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 75/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.4263e-06 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 76/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.2634e-06 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 77/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.3746e-06 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 78/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.2809e-06 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 79/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 1.1853e-06 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 80/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 1.2041e-06 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 81/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 1.1762e-06 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 82/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 1.0908e-06 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 83/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 1.0813e-06 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 84/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 8.9437e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 85/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 8.7973e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 86/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 8.5861e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 87/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 8.4224e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 88/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 7.5058e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 89/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 8.2733e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 90/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 6.7902e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 91/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 6.5119e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 92/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 6.4858e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 93/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 5.9838e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 94/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 6.0411e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 95/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 5.0156e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 96/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 5.0007e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 97/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 4.9014e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 97: early stopping\n",
      "Restoring model weights from the end of the best epoch: 67.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\n",
      "Training fold 5\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "2970 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({np.int64(6): 270, np.int64(7): 270, np.int64(4): 270, np.int64(3): 270, np.int64(5): 270, np.int64(8): 270, np.int64(9): 270, np.int64(2): 270, np.int64(10): 270, np.int64(1): 270, np.int64(0): 270})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9240 - loss: 0.2814 - val_accuracy: 1.0000 - val_loss: 6.0556e-06\n",
      "Epoch 2/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9712 - loss: 0.1136 - val_accuracy: 1.0000 - val_loss: 2.8239e-05\n",
      "Epoch 3/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9982 - loss: 0.0089 - val_accuracy: 1.0000 - val_loss: 2.0729e-05\n",
      "Epoch 4/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 2.9603e-06\n",
      "Epoch 5/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 4.2608e-04 - val_accuracy: 1.0000 - val_loss: 1.1325e-06\n",
      "Epoch 6/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 2.7934e-04 - val_accuracy: 1.0000 - val_loss: 6.9936e-07\n",
      "Epoch 7/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.8540e-04 - val_accuracy: 1.0000 - val_loss: 4.6889e-07\n",
      "Epoch 8/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 1.6369e-04 - val_accuracy: 1.0000 - val_loss: 3.6557e-07\n",
      "Epoch 9/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 1.1236e-04 - val_accuracy: 1.0000 - val_loss: 3.0200e-07\n",
      "Epoch 10/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 1.0535e-04 - val_accuracy: 1.0000 - val_loss: 2.5034e-07\n",
      "Epoch 11/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 8.5616e-05 - val_accuracy: 1.0000 - val_loss: 2.1060e-07\n",
      "Epoch 12/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 7.8712e-05 - val_accuracy: 1.0000 - val_loss: 1.7484e-07\n",
      "Epoch 13/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 6.0074e-05 - val_accuracy: 1.0000 - val_loss: 1.5100e-07\n",
      "Epoch 14/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 6.5181e-05 - val_accuracy: 1.0000 - val_loss: 1.3908e-07\n",
      "Epoch 15/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 5.5794e-05 - val_accuracy: 1.0000 - val_loss: 1.1524e-07\n",
      "Epoch 16/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 3.8569e-05 - val_accuracy: 1.0000 - val_loss: 1.0729e-07\n",
      "Epoch 17/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 4.1367e-05 - val_accuracy: 1.0000 - val_loss: 9.1394e-08\n",
      "Epoch 18/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 4.1013e-05 - val_accuracy: 1.0000 - val_loss: 7.9473e-08\n",
      "Epoch 19/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 3.5753e-05 - val_accuracy: 1.0000 - val_loss: 7.1526e-08\n",
      "Epoch 20/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 3.0325e-05 - val_accuracy: 1.0000 - val_loss: 6.3578e-08\n",
      "Epoch 21/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 3.1846e-05 - val_accuracy: 1.0000 - val_loss: 5.9605e-08\n",
      "Epoch 22/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 2.3523e-05 - val_accuracy: 1.0000 - val_loss: 5.1657e-08\n",
      "Epoch 23/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 2.2476e-05 - val_accuracy: 1.0000 - val_loss: 4.3710e-08\n",
      "Epoch 24/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 2.2049e-05 - val_accuracy: 1.0000 - val_loss: 3.9736e-08\n",
      "Epoch 25/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 2.0373e-05 - val_accuracy: 1.0000 - val_loss: 3.5763e-08\n",
      "Epoch 26/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 1.9169e-05 - val_accuracy: 1.0000 - val_loss: 3.1789e-08\n",
      "Epoch 27/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 1.8572e-05 - val_accuracy: 1.0000 - val_loss: 3.1789e-08\n",
      "Epoch 28/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 1.8350e-05 - val_accuracy: 1.0000 - val_loss: 2.7815e-08\n",
      "Epoch 29/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 1.4888e-05 - val_accuracy: 1.0000 - val_loss: 2.3842e-08\n",
      "Epoch 30/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 1.4758e-05 - val_accuracy: 1.0000 - val_loss: 1.9868e-08\n",
      "Epoch 31/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 1.4990e-05 - val_accuracy: 1.0000 - val_loss: 1.9868e-08\n",
      "Epoch 32/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 1.1608e-05 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 33/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 1.0780e-05 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 34/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 1.1256e-05 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 35/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 9.2316e-06 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 36/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 1.0489e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 37/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 1.0998e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 38/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 9.3426e-06 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 39/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 8.1760e-06 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 40/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 7.5383e-06 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 41/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 6.6526e-06 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 42/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 7.1418e-06 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 43/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 9.0779e-06 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 44/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 6.0508e-06 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 45/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 6.0618e-06 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 46/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 6.0128e-06 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 47/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 4.4048e-06 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 48/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 5.1925e-06 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 49/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 3.9691e-06 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 50/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 4.4648e-06 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 51/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 4.2922e-06 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 52/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 3.4347e-06 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 53/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 3.4165e-06 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 54/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 4.0381e-06 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 55/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 3.4416e-06 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 56/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 2.9458e-06 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 57/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 2.9401e-06 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 58/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 2.8900e-06 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 59/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 3.3442e-06 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 60/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 2.8091e-06 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 61/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 2.4727e-06 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 62/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 2.7999e-06 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 63/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 2.3500e-06 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 64/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 2.2795e-06 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 65/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 2.1417e-06 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 66/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 1.7971e-06 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 67/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 1.6857e-06 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 68/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 1.6978e-06 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 69/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 1.5812e-06 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 70/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 1.7823e-06 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 71/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 1.4739e-06 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 72/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 1.3551e-06 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 73/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 1.2880e-06 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 74/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 1.3271e-06 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 75/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 1.1882e-06 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 76/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 1.2807e-06 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 77/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 1.2673e-06 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 78/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 9.9586e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 79/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 1.0334e-06 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 80/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 9.9362e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 81/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 9.1367e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 82/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 9.1418e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 83/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 7.3045e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 84/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 7.3509e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 85/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 6.4946e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 85: early stopping\n",
      "Restoring model weights from the end of the best epoch: 55.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\n",
      "Training fold 6\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "2970 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({np.int64(6): 270, np.int64(7): 270, np.int64(4): 270, np.int64(3): 270, np.int64(5): 270, np.int64(8): 270, np.int64(9): 270, np.int64(2): 270, np.int64(10): 270, np.int64(1): 270, np.int64(0): 270})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9459 - loss: 0.1956 - val_accuracy: 1.0000 - val_loss: 7.4303e-06\n",
      "Epoch 2/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9777 - loss: 0.0838 - val_accuracy: 1.0000 - val_loss: 2.3444e-07\n",
      "Epoch 3/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9952 - loss: 0.0119 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 4/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9999 - loss: 0.0017 - val_accuracy: 1.0000 - val_loss: 1.1126e-07\n",
      "Epoch 5/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9998 - loss: 5.6850e-04 - val_accuracy: 1.0000 - val_loss: 6.7552e-08\n",
      "Epoch 6/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 9.1951e-04 - val_accuracy: 1.0000 - val_loss: 4.7684e-08\n",
      "Epoch 7/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 2.2924e-04 - val_accuracy: 1.0000 - val_loss: 3.5763e-08\n",
      "Epoch 8/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 5.4233e-04 - val_accuracy: 1.0000 - val_loss: 1.9868e-08\n",
      "Epoch 9/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 2.2287e-04 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 10/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 1.3426e-04 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 11/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 1.7930e-04 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 12/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 1.9256e-04 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 13/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 1.2053e-04 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 14/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 5.5872e-05 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 15/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 6.9757e-05 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 16/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 7.7498e-05 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 17/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 5.2136e-05 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 18/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 4.7750e-05 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 19/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 4.0405e-05 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 20/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 5.6324e-05 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 21/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 3.1518e-05 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 22/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 2.4027e-05 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 23/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 2.6163e-05 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 24/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 2.3904e-05 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 25/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 2.0066e-05 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 26/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 3.9697e-05 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 27/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 2.0190e-05 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 28/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 2.0321e-05 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 29/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 2.6075e-05 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 30/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 1.6699e-05 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 31/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 2.4946e-05 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 32/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 2.3995e-05 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 33/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 1.4862e-05 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 34/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 1.3699e-05 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 35/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 1.4060e-05 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 36/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 1.3704e-05 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 37/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 1.1314e-05 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 38/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 1.1573e-05 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 39/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 1.3259e-05 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 40/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 9.3431e-06 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 41/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 9.6209e-06 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 42/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 9.9067e-06 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 43/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 8.1279e-06 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 44/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 7.4634e-06 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\n",
      "Training fold 7\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "2970 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({np.int64(6): 270, np.int64(7): 270, np.int64(4): 270, np.int64(3): 270, np.int64(5): 270, np.int64(8): 270, np.int64(9): 270, np.int64(2): 270, np.int64(10): 270, np.int64(1): 270, np.int64(0): 270})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9761 - loss: 0.0762 - val_accuracy: 1.0000 - val_loss: 2.5430e-06\n",
      "Epoch 2/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9902 - loss: 0.0272 - val_accuracy: 1.0000 - val_loss: 1.9628e-05\n",
      "Epoch 3/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9973 - loss: 0.0079 - val_accuracy: 1.0000 - val_loss: 5.5631e-08\n",
      "Epoch 4/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 8.0236e-04 - val_accuracy: 1.0000 - val_loss: 1.2716e-07\n",
      "Epoch 5/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 8.3368e-05 - val_accuracy: 1.0000 - val_loss: 1.3908e-07\n",
      "Epoch 6/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 5.6899e-05 - val_accuracy: 1.0000 - val_loss: 1.1524e-07\n",
      "Epoch 7/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 3.4496e-05 - val_accuracy: 1.0000 - val_loss: 9.9341e-08\n",
      "Epoch 8/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 2.7075e-05 - val_accuracy: 1.0000 - val_loss: 9.1394e-08\n",
      "Epoch 9/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 3.0467e-05 - val_accuracy: 1.0000 - val_loss: 8.3446e-08\n",
      "Epoch 10/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 1.9664e-05 - val_accuracy: 1.0000 - val_loss: 7.9473e-08\n",
      "Epoch 11/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 2.1695e-05 - val_accuracy: 1.0000 - val_loss: 7.5499e-08\n",
      "Epoch 12/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 1.8364e-05 - val_accuracy: 1.0000 - val_loss: 7.5499e-08\n",
      "Epoch 13/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 1.5129e-05 - val_accuracy: 1.0000 - val_loss: 7.1526e-08\n",
      "Epoch 14/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 1.5448e-05 - val_accuracy: 1.0000 - val_loss: 7.1526e-08\n",
      "Epoch 15/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 1.1554e-05 - val_accuracy: 1.0000 - val_loss: 7.1526e-08\n",
      "Epoch 16/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 1.0802e-05 - val_accuracy: 1.0000 - val_loss: 6.7552e-08\n",
      "Epoch 17/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 1.0001e-05 - val_accuracy: 1.0000 - val_loss: 7.1526e-08\n",
      "Epoch 18/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 7.5594e-06 - val_accuracy: 1.0000 - val_loss: 6.7552e-08\n",
      "Epoch 19/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 7.0520e-06 - val_accuracy: 1.0000 - val_loss: 7.1526e-08\n",
      "Epoch 20/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 9.2624e-06 - val_accuracy: 1.0000 - val_loss: 7.1526e-08\n",
      "Epoch 21/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 6.7787e-06 - val_accuracy: 1.0000 - val_loss: 7.1526e-08\n",
      "Epoch 22/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 8.0134e-06 - val_accuracy: 1.0000 - val_loss: 7.1526e-08\n",
      "Epoch 23/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 4.8663e-06 - val_accuracy: 1.0000 - val_loss: 7.5499e-08\n",
      "Epoch 24/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 4.7553e-06 - val_accuracy: 1.0000 - val_loss: 7.5499e-08\n",
      "Epoch 25/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 4.6314e-06 - val_accuracy: 1.0000 - val_loss: 7.5499e-08\n",
      "Epoch 26/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 3.1757e-06 - val_accuracy: 1.0000 - val_loss: 7.1526e-08\n",
      "Epoch 27/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 2.8853e-06 - val_accuracy: 1.0000 - val_loss: 7.1526e-08\n",
      "Epoch 28/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 2.9691e-06 - val_accuracy: 1.0000 - val_loss: 7.1526e-08\n",
      "Epoch 29/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 2.2528e-06 - val_accuracy: 1.0000 - val_loss: 6.3578e-08\n",
      "Epoch 30/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 2.5426e-06 - val_accuracy: 1.0000 - val_loss: 6.3578e-08\n",
      "Epoch 31/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 2.2775e-06 - val_accuracy: 1.0000 - val_loss: 5.9605e-08\n",
      "Epoch 32/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 1.9360e-06 - val_accuracy: 1.0000 - val_loss: 5.9605e-08\n",
      "Epoch 33/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 2.2907e-06 - val_accuracy: 1.0000 - val_loss: 5.9605e-08\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\n",
      "Training fold 8\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "2970 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({np.int64(6): 270, np.int64(7): 270, np.int64(4): 270, np.int64(3): 270, np.int64(5): 270, np.int64(8): 270, np.int64(9): 270, np.int64(2): 270, np.int64(10): 270, np.int64(1): 270, np.int64(0): 270})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9918 - loss: 0.0337 - val_accuracy: 1.0000 - val_loss: 5.0322e-05\n",
      "Epoch 2/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9837 - loss: 0.0510 - val_accuracy: 1.0000 - val_loss: 1.5378e-06\n",
      "Epoch 3/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9968 - loss: 0.0170 - val_accuracy: 1.0000 - val_loss: 1.8770e-05\n",
      "Epoch 4/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9986 - loss: 0.0073 - val_accuracy: 1.0000 - val_loss: 3.3776e-07\n",
      "Epoch 5/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 1.2936e-04 - val_accuracy: 1.0000 - val_loss: 2.5034e-07\n",
      "Epoch 6/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 8.4799e-05 - val_accuracy: 1.0000 - val_loss: 1.6292e-07\n",
      "Epoch 7/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 6.0149e-05 - val_accuracy: 1.0000 - val_loss: 1.1524e-07\n",
      "Epoch 8/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 4.5548e-05 - val_accuracy: 1.0000 - val_loss: 9.9341e-08\n",
      "Epoch 9/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 3.9742e-05 - val_accuracy: 1.0000 - val_loss: 7.5499e-08\n",
      "Epoch 10/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 4.5901e-05 - val_accuracy: 1.0000 - val_loss: 6.3578e-08\n",
      "Epoch 11/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 3.7072e-05 - val_accuracy: 1.0000 - val_loss: 5.1657e-08\n",
      "Epoch 12/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 5.8384e-05 - val_accuracy: 1.0000 - val_loss: 4.3710e-08\n",
      "Epoch 13/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 2.7788e-05 - val_accuracy: 1.0000 - val_loss: 3.9736e-08\n",
      "Epoch 14/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 3.1065e-05 - val_accuracy: 1.0000 - val_loss: 3.1789e-08\n",
      "Epoch 15/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 1.9071e-05 - val_accuracy: 1.0000 - val_loss: 1.9868e-08\n",
      "Epoch 16/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 2.4527e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 17/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 1.8385e-05 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 18/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 1.5713e-05 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 19/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 1.2177e-05 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 20/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 1.3415e-05 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 21/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 1.1165e-05 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 22/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 1.0945e-05 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 23/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 8.9142e-06 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 24/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 1.2241e-05 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 25/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 6.7541e-06 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 26/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 4.2494e-06 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 27/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 1.6144e-06 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 28/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 3.1931e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 29/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 1.5892e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 30/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 1.3976e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 31/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 8.2038e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 32/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 7.4018e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 33/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 4.6912e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 34/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 4.6974e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 35/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 4.1004e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 36/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 1.9516e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 37/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 2.6790e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 38/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 2.4085e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 39/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 2.2894e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 40/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 2.4436e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 41/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 1.7826e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 42/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 1.3880e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 43/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 1.2825e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 44/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.1376e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 45/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 1.0647e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 46/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 7.9098e-09 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 47/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 8.8933e-09 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 48/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 7.6384e-09 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 49/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 6.2559e-09 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 50/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 1.0179e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 51/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 6.7894e-09 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 52/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 5.2247e-09 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 53/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 5.2265e-09 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\n",
      "Training fold 9\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "2970 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({np.int64(6): 270, np.int64(7): 270, np.int64(4): 270, np.int64(3): 270, np.int64(5): 270, np.int64(8): 270, np.int64(9): 270, np.int64(2): 270, np.int64(10): 270, np.int64(1): 270, np.int64(0): 270})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9873 - loss: 0.0529 - val_accuracy: 1.0000 - val_loss: 2.3842e-08\n",
      "Epoch 2/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9955 - loss: 0.0194 - val_accuracy: 1.0000 - val_loss: 5.8412e-07\n",
      "Epoch 3/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9916 - loss: 0.0204 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 4/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9986 - loss: 0.0103 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 5/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 1.1668e-04 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 6/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 2.6183e-05 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 7/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 2.3943e-05 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 8/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 1.8411e-05 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 9/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 1.1644e-05 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 10/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 7.0949e-06 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 11/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 6.8650e-06 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 12/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 2.8697e-06 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 13/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 2.1386e-06 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 14/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 1.6640e-06 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 15/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 1.0962e-06 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 16/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 1.2385e-06 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 17/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 1.1080e-06 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 18/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.2226e-06 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 19/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 5.2087e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 20/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 5.3263e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 21/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 4.5792e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 22/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 3.3033e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 23/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 2.8449e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 24/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 2.9933e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 25/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 4.5714e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 26/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 3.0018e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 27/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 2.0699e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 28/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 2.2110e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 29/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 2.0246e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 30/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 1.5521e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 31/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 1.9445e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 32/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 1.6086e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 33/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 1.2482e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\n",
      "Training fold 10\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "2970 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({np.int64(6): 270, np.int64(7): 270, np.int64(4): 270, np.int64(3): 270, np.int64(5): 270, np.int64(8): 270, np.int64(9): 270, np.int64(2): 270, np.int64(10): 270, np.int64(1): 270, np.int64(0): 270})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9784 - loss: 0.0941 - val_accuracy: 1.0000 - val_loss: 1.2008e-04\n",
      "Epoch 2/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9911 - loss: 0.0189 - val_accuracy: 1.0000 - val_loss: 0.0217\n",
      "Epoch 3/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9989 - loss: 0.0026 - val_accuracy: 1.0000 - val_loss: 2.9008e-07\n",
      "Epoch 4/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 5.5097e-04 - val_accuracy: 1.0000 - val_loss: 2.1060e-07\n",
      "Epoch 5/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 2.1298e-04 - val_accuracy: 1.0000 - val_loss: 9.1394e-08\n",
      "Epoch 6/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 9.9830e-05 - val_accuracy: 1.0000 - val_loss: 6.3578e-08\n",
      "Epoch 7/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 8.7541e-05 - val_accuracy: 1.0000 - val_loss: 5.1657e-08\n",
      "Epoch 8/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 5.9010e-05 - val_accuracy: 1.0000 - val_loss: 3.1789e-08\n",
      "Epoch 9/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 6.5688e-05 - val_accuracy: 1.0000 - val_loss: 2.3842e-08\n",
      "Epoch 10/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 4.7548e-05 - val_accuracy: 1.0000 - val_loss: 1.9868e-08\n",
      "Epoch 11/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 5.1668e-05 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 12/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 2.9946e-05 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 13/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 3.0249e-05 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 14/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 2.4610e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 15/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 2.1693e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 16/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 2.4787e-05 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 17/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 1.9865e-05 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 18/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 1.7053e-05 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 19/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 1.7548e-05 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 20/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 1.5679e-05 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 21/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 1.6275e-05 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 22/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 1.2985e-05 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 23/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 1.4573e-05 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 24/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 1.1526e-05 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 25/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 9.4045e-06 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 26/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 7.3063e-06 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 27/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 9.2705e-06 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 28/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 7.6386e-06 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 29/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 7.3006e-06 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 30/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 7.1144e-06 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 31/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 6.6175e-06 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 32/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 7.9496e-06 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 33/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 5.5900e-06 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 34/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 5.1176e-06 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 35/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 5.1735e-06 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 36/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 4.6313e-06 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 37/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 4.2641e-06 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 38/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 4.9266e-06 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 39/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 5.0792e-06 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 40/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 4.5973e-06 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 41/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 3.9327e-06 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 42/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 4.2189e-06 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 43/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 2.7925e-06 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 44/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 3.3679e-06 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 45/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 2.8526e-06 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 46/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 2.3234e-06 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 47/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 2.9367e-06 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 48/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 2.0085e-06 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 49/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 2.0542e-06 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 50/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 2.4282e-06 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 51/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 2.4170e-06 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 52/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 1.9656e-06 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 53/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 1.8603e-06 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 54/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 1.9214e-06 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 55/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 1.4922e-06 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 56/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 1.5949e-06 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\n",
      "Time taken for training:  00:38:13\n",
      "\n",
      "\n",
      "Fold 1 - Train Accuracy 1.0000 - Test Accuracy 0.1833\n",
      "Fold 2 - Train Accuracy 1.0000 - Test Accuracy 0.0667\n",
      "Fold 3 - Train Accuracy 1.0000 - Test Accuracy 0.5167\n",
      "Fold 4 - Train Accuracy 1.0000 - Test Accuracy 0.6500\n",
      "Fold 5 - Train Accuracy 1.0000 - Test Accuracy 0.8667\n",
      "Fold 6 - Train Accuracy 1.0000 - Test Accuracy 0.9417\n",
      "Fold 7 - Train Accuracy 0.9987 - Test Accuracy 0.9750\n",
      "Fold 8 - Train Accuracy 1.0000 - Test Accuracy 0.9500\n",
      "Fold 9 - Train Accuracy 0.9983 - Test Accuracy 0.9667\n",
      "Fold 10 - Train Accuracy 1.0000 - Test Accuracy 1.0000\n",
      "\n",
      "Mean Train Accuracy: 0.9997 \n",
      "Mean Test Accuracy: 0.7117 \n",
      "\n",
      "Evaluate other metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.79      0.73       300\n",
      "           1       0.73      0.66      0.69        50\n",
      "           2       0.82      0.65      0.73        57\n",
      "           3       0.65      0.72      0.68       145\n",
      "           4       0.73      0.68      0.71       132\n",
      "           5       0.69      0.71      0.70       191\n",
      "           6       0.76      0.68      0.72       150\n",
      "           7       0.75      0.70      0.72        79\n",
      "           8       0.83      0.64      0.72        61\n",
      "           9       0.80      0.64      0.71        25\n",
      "          10       1.00      0.60      0.75        10\n",
      "\n",
      "    accuracy                           0.71      1200\n",
      "   macro avg       0.77      0.68      0.71      1200\n",
      "weighted avg       0.72      0.71      0.71      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def create_baseline():\n",
    "    act_function = \"relu\"\n",
    "    kernel_init = \"he_uniform\"\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(number_of_steps, number_of_features)))\n",
    "    model.add(Conv1D(filters = 64, kernel_size = 3, activation = act_function,\n",
    "                     kernel_initializer = kernel_init))\n",
    "    model.add(Conv1D(filters = 32, kernel_size = 3, activation = act_function,\n",
    "                     kernel_initializer = kernel_init))\n",
    "    model.add(Conv1D(filters = 16, kernel_size = 3, activation = act_function,\n",
    "                     kernel_initializer = kernel_init))\n",
    "    model.add(MaxPooling1D(pool_size = 2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(32, activation = act_function))\n",
    "    model.add(Dense(11, activation = 'softmax'))\n",
    "    opt = AdamW(learning_rate = 0.001)\n",
    "    model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = opt, metrics = [\"accuracy\"])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "X_list, y_list = build_time_window_structure(df)\n",
    "X_arr = np.array(X_list)\n",
    "y_arr = np.array(y_list)\n",
    "\n",
    "model = create_baseline()\n",
    "history_by_fold = train_cnn_model(model, X_arr, y_arr, apply_smote = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ad099f",
   "metadata": {},
   "source": [
    "#### Train a Convolutional Neural Network model and evaluate the metrics.\n",
    "- Layer architecture => Conv1D (64) + Conv1D (32) + Conv1D (16) + MaxPooling1D + Dense (32) + Dense(32) + Dense(32) + Dense (11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aaf55fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting build_time_window_structure function...\n",
      "Quantity of samples (features) =>  1200\n",
      "Quantity os samples (labels) =>  1200\n",
      "Finishing build_time_window_structure function.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1278</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1276</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,176</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1274</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,552</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">637</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10192</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">326,176</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">363</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1278\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │         \u001b[38;5;34m6,208\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1276\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │         \u001b[38;5;34m6,176\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1274\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │         \u001b[38;5;34m1,552\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m637\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10192\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │       \u001b[38;5;34m326,176\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m1,056\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m1,056\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m)             │           \u001b[38;5;34m363\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">342,587</span> (1.31 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m342,587\u001b[0m (1.31 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">342,587</span> (1.31 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m342,587\u001b[0m (1.31 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training...\n",
      "\n",
      "Training fold 1\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "2970 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({np.int64(6): 270, np.int64(7): 270, np.int64(4): 270, np.int64(3): 270, np.int64(5): 270, np.int64(8): 270, np.int64(9): 270, np.int64(2): 270, np.int64(10): 270, np.int64(1): 270, np.int64(0): 270})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.1363 - loss: 2.7108 - val_accuracy: 1.0000 - val_loss: 0.1157\n",
      "Epoch 2/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.6885 - loss: 0.9939 - val_accuracy: 1.0000 - val_loss: 0.0191\n",
      "Epoch 3/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9021 - loss: 0.3091 - val_accuracy: 1.0000 - val_loss: 0.0042\n",
      "Epoch 4/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9672 - loss: 0.1256 - val_accuracy: 1.0000 - val_loss: 0.0140\n",
      "Epoch 5/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9810 - loss: 0.0711 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
      "Epoch 6/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9939 - loss: 0.0355 - val_accuracy: 1.0000 - val_loss: 4.7403e-05\n",
      "Epoch 7/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9985 - loss: 0.0111 - val_accuracy: 1.0000 - val_loss: 1.0736e-05\n",
      "Epoch 8/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9969 - loss: 0.0184 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
      "Epoch 9/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9996 - loss: 0.0058 - val_accuracy: 1.0000 - val_loss: 0.0010\n",
      "Epoch 10/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9979 - loss: 0.0127 - val_accuracy: 1.0000 - val_loss: 1.4424e-06\n",
      "Epoch 11/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9990 - loss: 0.0096 - val_accuracy: 1.0000 - val_loss: 9.6757e-06\n",
      "Epoch 12/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9913 - loss: 0.0287 - val_accuracy: 1.0000 - val_loss: 6.4237e-05\n",
      "Epoch 13/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9897 - loss: 0.0392 - val_accuracy: 1.0000 - val_loss: 3.8628e-05\n",
      "Epoch 14/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9848 - loss: 0.0674 - val_accuracy: 1.0000 - val_loss: 1.3617e-04\n",
      "Epoch 15/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9930 - loss: 0.0308 - val_accuracy: 1.0000 - val_loss: 5.3621e-04\n",
      "Epoch 16/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9904 - loss: 0.0261 - val_accuracy: 1.0000 - val_loss: 2.9081e-05\n",
      "Epoch 17/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9976 - loss: 0.0152 - val_accuracy: 1.0000 - val_loss: 1.1272e-05\n",
      "Epoch 18/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9963 - loss: 0.0109 - val_accuracy: 1.0000 - val_loss: 7.6609e-06\n",
      "Epoch 19/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 4.4553e-04 - val_accuracy: 1.0000 - val_loss: 3.9735e-06\n",
      "Epoch 20/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 2.1095e-04 - val_accuracy: 1.0000 - val_loss: 2.4398e-06\n",
      "Epoch 21/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 1.2739e-04 - val_accuracy: 1.0000 - val_loss: 1.6888e-06\n",
      "Epoch 22/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 1.0380e-04 - val_accuracy: 1.0000 - val_loss: 1.3828e-06\n",
      "Epoch 23/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 8.9801e-05 - val_accuracy: 1.0000 - val_loss: 1.1404e-06\n",
      "Epoch 24/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 7.1103e-05 - val_accuracy: 1.0000 - val_loss: 9.6161e-07\n",
      "Epoch 25/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 6.4648e-05 - val_accuracy: 1.0000 - val_loss: 8.2254e-07\n",
      "Epoch 26/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 5.6855e-05 - val_accuracy: 1.0000 - val_loss: 7.4307e-07\n",
      "Epoch 27/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 4.6400e-05 - val_accuracy: 1.0000 - val_loss: 6.7154e-07\n",
      "Epoch 28/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 4.9139e-05 - val_accuracy: 1.0000 - val_loss: 5.7618e-07\n",
      "Epoch 29/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 3.9371e-05 - val_accuracy: 1.0000 - val_loss: 5.3247e-07\n",
      "Epoch 30/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 3.7586e-05 - val_accuracy: 1.0000 - val_loss: 4.6491e-07\n",
      "Epoch 31/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 3.6508e-05 - val_accuracy: 1.0000 - val_loss: 4.3313e-07\n",
      "Epoch 32/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 3.0204e-05 - val_accuracy: 1.0000 - val_loss: 4.0531e-07\n",
      "Epoch 33/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 2.8080e-05 - val_accuracy: 1.0000 - val_loss: 3.6160e-07\n",
      "Epoch 34/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 2.5331e-05 - val_accuracy: 1.0000 - val_loss: 3.3379e-07\n",
      "Epoch 35/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 2.5843e-05 - val_accuracy: 1.0000 - val_loss: 3.0994e-07\n",
      "Epoch 36/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 2.2059e-05 - val_accuracy: 1.0000 - val_loss: 2.8610e-07\n",
      "Epoch 37/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 2.2187e-05 - val_accuracy: 1.0000 - val_loss: 2.7021e-07\n",
      "Epoch 38/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 2.0440e-05 - val_accuracy: 1.0000 - val_loss: 2.5829e-07\n",
      "Epoch 39/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 2.1204e-05 - val_accuracy: 1.0000 - val_loss: 2.3842e-07\n",
      "Epoch 40/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.7921e-05 - val_accuracy: 1.0000 - val_loss: 2.3047e-07\n",
      "Epoch 41/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.7090e-05 - val_accuracy: 1.0000 - val_loss: 2.1060e-07\n",
      "Epoch 42/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.6356e-05 - val_accuracy: 1.0000 - val_loss: 2.0266e-07\n",
      "Epoch 43/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.5439e-05 - val_accuracy: 1.0000 - val_loss: 1.8676e-07\n",
      "Epoch 44/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.3892e-05 - val_accuracy: 1.0000 - val_loss: 1.7881e-07\n",
      "Epoch 45/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.3900e-05 - val_accuracy: 1.0000 - val_loss: 1.7087e-07\n",
      "Epoch 46/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.3756e-05 - val_accuracy: 1.0000 - val_loss: 1.6689e-07\n",
      "Epoch 47/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.2028e-05 - val_accuracy: 1.0000 - val_loss: 1.5895e-07\n",
      "Epoch 48/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.3178e-05 - val_accuracy: 1.0000 - val_loss: 1.4305e-07\n",
      "Epoch 49/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.0507e-05 - val_accuracy: 1.0000 - val_loss: 1.3908e-07\n",
      "Epoch 50/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 9.7956e-06 - val_accuracy: 1.0000 - val_loss: 1.3113e-07\n",
      "Epoch 51/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 9.8632e-06 - val_accuracy: 1.0000 - val_loss: 1.2716e-07\n",
      "Epoch 52/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 9.4010e-06 - val_accuracy: 1.0000 - val_loss: 1.2716e-07\n",
      "Epoch 53/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 9.3026e-06 - val_accuracy: 1.0000 - val_loss: 1.2318e-07\n",
      "Epoch 54/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 8.2949e-06 - val_accuracy: 1.0000 - val_loss: 1.1524e-07\n",
      "Epoch 55/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 7.4031e-06 - val_accuracy: 1.0000 - val_loss: 1.1126e-07\n",
      "Epoch 56/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 7.5894e-06 - val_accuracy: 1.0000 - val_loss: 1.1126e-07\n",
      "Epoch 57/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 7.2899e-06 - val_accuracy: 1.0000 - val_loss: 1.0729e-07\n",
      "Epoch 58/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 6.6276e-06 - val_accuracy: 1.0000 - val_loss: 9.9341e-08\n",
      "Epoch 59/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 6.5200e-06 - val_accuracy: 1.0000 - val_loss: 9.9341e-08\n",
      "Epoch 60/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 5.9603e-06 - val_accuracy: 1.0000 - val_loss: 9.5367e-08\n",
      "Epoch 61/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 5.4765e-06 - val_accuracy: 1.0000 - val_loss: 9.1394e-08\n",
      "Epoch 62/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 5.3656e-06 - val_accuracy: 1.0000 - val_loss: 8.7420e-08\n",
      "Epoch 63/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 5.6307e-06 - val_accuracy: 1.0000 - val_loss: 8.3446e-08\n",
      "Epoch 64/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 5.1706e-06 - val_accuracy: 1.0000 - val_loss: 8.3446e-08\n",
      "Epoch 65/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 5.2560e-06 - val_accuracy: 1.0000 - val_loss: 7.9473e-08\n",
      "Epoch 66/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 4.8947e-06 - val_accuracy: 1.0000 - val_loss: 7.5499e-08\n",
      "Epoch 67/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 4.9396e-06 - val_accuracy: 1.0000 - val_loss: 7.1526e-08\n",
      "Epoch 68/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 4.1534e-06 - val_accuracy: 1.0000 - val_loss: 7.1526e-08\n",
      "Epoch 69/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 4.4422e-06 - val_accuracy: 1.0000 - val_loss: 6.7552e-08\n",
      "Epoch 70/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 3.9076e-06 - val_accuracy: 1.0000 - val_loss: 6.7552e-08\n",
      "Epoch 71/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 3.7074e-06 - val_accuracy: 1.0000 - val_loss: 6.3578e-08\n",
      "Epoch 72/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 3.5814e-06 - val_accuracy: 1.0000 - val_loss: 6.3578e-08\n",
      "Epoch 73/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 3.2733e-06 - val_accuracy: 1.0000 - val_loss: 6.3578e-08\n",
      "Epoch 74/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 3.3071e-06 - val_accuracy: 1.0000 - val_loss: 5.9605e-08\n",
      "Epoch 75/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 3.2640e-06 - val_accuracy: 1.0000 - val_loss: 5.5631e-08\n",
      "Epoch 76/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 3.1378e-06 - val_accuracy: 1.0000 - val_loss: 5.5631e-08\n",
      "Epoch 77/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 2.8964e-06 - val_accuracy: 1.0000 - val_loss: 5.1657e-08\n",
      "Epoch 78/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 3.0852e-06 - val_accuracy: 1.0000 - val_loss: 5.1657e-08\n",
      "Epoch 79/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 2.8054e-06 - val_accuracy: 1.0000 - val_loss: 5.1657e-08\n",
      "Epoch 80/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 2.4355e-06 - val_accuracy: 1.0000 - val_loss: 4.7684e-08\n",
      "Epoch 81/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 2.2793e-06 - val_accuracy: 1.0000 - val_loss: 4.7684e-08\n",
      "Epoch 82/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 2.2492e-06 - val_accuracy: 1.0000 - val_loss: 4.7684e-08\n",
      "Epoch 83/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 2.2269e-06 - val_accuracy: 1.0000 - val_loss: 4.7684e-08\n",
      "Epoch 84/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 2.2680e-06 - val_accuracy: 1.0000 - val_loss: 4.3710e-08\n",
      "Epoch 85/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.9497e-06 - val_accuracy: 1.0000 - val_loss: 4.3710e-08\n",
      "Epoch 86/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.9369e-06 - val_accuracy: 1.0000 - val_loss: 3.9736e-08\n",
      "Epoch 87/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.8722e-06 - val_accuracy: 1.0000 - val_loss: 3.9736e-08\n",
      "Epoch 88/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 1.7544e-06 - val_accuracy: 1.0000 - val_loss: 3.5763e-08\n",
      "Epoch 89/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.7120e-06 - val_accuracy: 1.0000 - val_loss: 3.5763e-08\n",
      "Epoch 90/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 1.5837e-06 - val_accuracy: 1.0000 - val_loss: 3.5763e-08\n",
      "Epoch 91/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.4655e-06 - val_accuracy: 1.0000 - val_loss: 3.5763e-08\n",
      "Epoch 92/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.4674e-06 - val_accuracy: 1.0000 - val_loss: 3.5763e-08\n",
      "Epoch 93/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.4487e-06 - val_accuracy: 1.0000 - val_loss: 3.5763e-08\n",
      "Epoch 94/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 1.2538e-06 - val_accuracy: 1.0000 - val_loss: 3.5763e-08\n",
      "Epoch 95/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 1.3628e-06 - val_accuracy: 1.0000 - val_loss: 3.5763e-08\n",
      "Epoch 96/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.2386e-06 - val_accuracy: 1.0000 - val_loss: 3.1789e-08\n",
      "Epoch 97/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.1661e-06 - val_accuracy: 1.0000 - val_loss: 3.1789e-08\n",
      "Epoch 98/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 9.6324e-07 - val_accuracy: 1.0000 - val_loss: 2.7815e-08\n",
      "Epoch 99/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 1.0973e-06 - val_accuracy: 1.0000 - val_loss: 2.3842e-08\n",
      "Epoch 100/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 9.9469e-07 - val_accuracy: 1.0000 - val_loss: 2.3842e-08\n",
      "Epoch 101/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 9.5024e-07 - val_accuracy: 1.0000 - val_loss: 2.3842e-08\n",
      "Epoch 102/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 8.8253e-07 - val_accuracy: 1.0000 - val_loss: 2.3842e-08\n",
      "Epoch 103/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 9.1944e-07 - val_accuracy: 1.0000 - val_loss: 2.3842e-08\n",
      "Epoch 104/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 7.8582e-07 - val_accuracy: 1.0000 - val_loss: 2.3842e-08\n",
      "Epoch 105/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 7.6318e-07 - val_accuracy: 1.0000 - val_loss: 2.3842e-08\n",
      "Epoch 106/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 7.9156e-07 - val_accuracy: 1.0000 - val_loss: 2.3842e-08\n",
      "Epoch 107/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 7.2224e-07 - val_accuracy: 1.0000 - val_loss: 2.3842e-08\n",
      "Epoch 108/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 6.9996e-07 - val_accuracy: 1.0000 - val_loss: 2.3842e-08\n",
      "Epoch 109/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 6.7310e-07 - val_accuracy: 1.0000 - val_loss: 1.9868e-08\n",
      "Epoch 110/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 6.6743e-07 - val_accuracy: 1.0000 - val_loss: 1.9868e-08\n",
      "Epoch 111/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 6.3129e-07 - val_accuracy: 1.0000 - val_loss: 1.9868e-08\n",
      "Epoch 112/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 5.7848e-07 - val_accuracy: 1.0000 - val_loss: 1.9868e-08\n",
      "Epoch 113/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 5.4424e-07 - val_accuracy: 1.0000 - val_loss: 1.9868e-08\n",
      "Epoch 114/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 5.2464e-07 - val_accuracy: 1.0000 - val_loss: 1.9868e-08\n",
      "Epoch 115/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 4.7803e-07 - val_accuracy: 1.0000 - val_loss: 1.9868e-08\n",
      "Epoch 116/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 4.9412e-07 - val_accuracy: 1.0000 - val_loss: 1.9868e-08\n",
      "Epoch 117/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 4.8598e-07 - val_accuracy: 1.0000 - val_loss: 1.9868e-08\n",
      "Epoch 118/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 4.3621e-07 - val_accuracy: 1.0000 - val_loss: 1.9868e-08\n",
      "Epoch 119/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 4.4800e-07 - val_accuracy: 1.0000 - val_loss: 1.9868e-08\n",
      "Epoch 120/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 4.1522e-07 - val_accuracy: 1.0000 - val_loss: 1.9868e-08\n",
      "Epoch 121/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 3.7073e-07 - val_accuracy: 1.0000 - val_loss: 1.9868e-08\n",
      "Epoch 122/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 3.8710e-07 - val_accuracy: 1.0000 - val_loss: 1.9868e-08\n",
      "Epoch 123/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 3.5257e-07 - val_accuracy: 1.0000 - val_loss: 1.9868e-08\n",
      "Epoch 124/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 3.3183e-07 - val_accuracy: 1.0000 - val_loss: 1.9868e-08\n",
      "Epoch 125/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 3.3379e-07 - val_accuracy: 1.0000 - val_loss: 1.9868e-08\n",
      "Epoch 126/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 3.1247e-07 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 127/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 2.8809e-07 - val_accuracy: 1.0000 - val_loss: 1.9868e-08\n",
      "Epoch 128/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 2.8216e-07 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 129/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 2.6510e-07 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 130/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 2.5110e-07 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 131/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 2.3283e-07 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 132/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 2.3961e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 133/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 2.2174e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 134/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 2.1271e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 135/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.9650e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 136/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.9193e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 137/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.7413e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 138/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.6750e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 139/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.5497e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 140/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 1.6122e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 141/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.5005e-07 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 142/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 1.3916e-07 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 143/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 1.3783e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 144/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.3973e-07 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 145/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.2913e-07 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 146/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 1.2020e-07 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 147/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.1459e-07 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 148/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.0656e-07 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 149/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.0472e-07 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 150/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.0004e-07 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 151/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 9.4841e-08 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 152/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 8.9807e-08 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 153/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 9.0732e-08 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 154/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 8.1528e-08 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 155/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 7.8468e-08 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 156/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 6.5954e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 157/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 7.0012e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 158/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 6.6001e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 159/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 6.3172e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 160/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 6.2088e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 161/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 5.6034e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 162/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 5.5870e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 163/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 5.7042e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 164/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 4.9726e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 165/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 4.4072e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 166/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 4.3902e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 167/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 4.4346e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 168/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 4.3676e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 169/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 3.7693e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 170/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 3.8306e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 171/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 4.1906e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 172/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 3.3665e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 173/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 3.3577e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 174/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 3.0465e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 175/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 3.2021e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 176/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 2.6567e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 177/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 2.6618e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 178/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 2.5927e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 179/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 2.4190e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 180/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 2.4339e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 181/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 2.1214e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 182/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 2.1225e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 183/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 2.1149e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 184/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.9422e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 185/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.9775e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 186/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.8477e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 186: early stopping\n",
      "Restoring model weights from the end of the best epoch: 156.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\n",
      "Training fold 2\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "2970 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({np.int64(6): 270, np.int64(7): 270, np.int64(4): 270, np.int64(3): 270, np.int64(5): 270, np.int64(8): 270, np.int64(9): 270, np.int64(2): 270, np.int64(10): 270, np.int64(1): 270, np.int64(0): 270})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.5330 - loss: 1.9896 - val_accuracy: 1.0000 - val_loss: 0.0045\n",
      "Epoch 2/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.8331 - loss: 0.5630 - val_accuracy: 1.0000 - val_loss: 0.0034\n",
      "Epoch 3/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9426 - loss: 0.2042 - val_accuracy: 1.0000 - val_loss: 6.8116e-04\n",
      "Epoch 4/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9853 - loss: 0.0640 - val_accuracy: 1.0000 - val_loss: 6.8130e-04\n",
      "Epoch 5/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9907 - loss: 0.0294 - val_accuracy: 1.0000 - val_loss: 0.0030\n",
      "Epoch 6/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.9981 - loss: 0.0097 - val_accuracy: 1.0000 - val_loss: 0.0025\n",
      "Epoch 7/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 1.0000 - val_loss: 2.2915e-04\n",
      "Epoch 8/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 7.2857e-04 - val_accuracy: 1.0000 - val_loss: 1.3904e-04\n",
      "Epoch 9/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 4.5835e-04 - val_accuracy: 1.0000 - val_loss: 9.5868e-05\n",
      "Epoch 10/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 4.0136e-04 - val_accuracy: 1.0000 - val_loss: 7.7476e-05\n",
      "Epoch 11/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 2.8048e-04 - val_accuracy: 1.0000 - val_loss: 5.6762e-05\n",
      "Epoch 12/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 2.5524e-04 - val_accuracy: 1.0000 - val_loss: 4.9427e-05\n",
      "Epoch 13/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.9914e-04 - val_accuracy: 1.0000 - val_loss: 4.2726e-05\n",
      "Epoch 14/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.9812e-04 - val_accuracy: 1.0000 - val_loss: 3.7302e-05\n",
      "Epoch 15/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.6710e-04 - val_accuracy: 1.0000 - val_loss: 3.4003e-05\n",
      "Epoch 16/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.4519e-04 - val_accuracy: 1.0000 - val_loss: 2.8856e-05\n",
      "Epoch 17/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.3623e-04 - val_accuracy: 1.0000 - val_loss: 2.8038e-05\n",
      "Epoch 18/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.1246e-04 - val_accuracy: 1.0000 - val_loss: 2.5755e-05\n",
      "Epoch 19/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.0317e-04 - val_accuracy: 1.0000 - val_loss: 2.3391e-05\n",
      "Epoch 20/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 9.0425e-05 - val_accuracy: 1.0000 - val_loss: 2.1886e-05\n",
      "Epoch 21/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 8.5114e-05 - val_accuracy: 1.0000 - val_loss: 1.9412e-05\n",
      "Epoch 22/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 8.3100e-05 - val_accuracy: 1.0000 - val_loss: 1.8061e-05\n",
      "Epoch 23/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 7.3085e-05 - val_accuracy: 1.0000 - val_loss: 1.7143e-05\n",
      "Epoch 24/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 6.6222e-05 - val_accuracy: 1.0000 - val_loss: 1.5431e-05\n",
      "Epoch 25/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 6.5973e-05 - val_accuracy: 1.0000 - val_loss: 1.3699e-05\n",
      "Epoch 26/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 6.3776e-05 - val_accuracy: 1.0000 - val_loss: 1.3167e-05\n",
      "Epoch 27/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 5.1420e-05 - val_accuracy: 1.0000 - val_loss: 1.1614e-05\n",
      "Epoch 28/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 5.0231e-05 - val_accuracy: 1.0000 - val_loss: 1.0184e-05\n",
      "Epoch 29/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 4.5196e-05 - val_accuracy: 1.0000 - val_loss: 9.3135e-06\n",
      "Epoch 30/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 4.3554e-05 - val_accuracy: 1.0000 - val_loss: 8.8407e-06\n",
      "Epoch 31/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 4.0838e-05 - val_accuracy: 1.0000 - val_loss: 8.0302e-06\n",
      "Epoch 32/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 3.7062e-05 - val_accuracy: 1.0000 - val_loss: 7.3548e-06\n",
      "Epoch 33/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 3.4244e-05 - val_accuracy: 1.0000 - val_loss: 7.0250e-06\n",
      "Epoch 34/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 3.2671e-05 - val_accuracy: 1.0000 - val_loss: 6.5244e-06\n",
      "Epoch 35/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 3.1388e-05 - val_accuracy: 1.0000 - val_loss: 6.0118e-06\n",
      "Epoch 36/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 2.9947e-05 - val_accuracy: 1.0000 - val_loss: 5.5072e-06\n",
      "Epoch 37/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 2.6633e-05 - val_accuracy: 1.0000 - val_loss: 5.1377e-06\n",
      "Epoch 38/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 2.4877e-05 - val_accuracy: 1.0000 - val_loss: 4.7523e-06\n",
      "Epoch 39/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 2.3332e-05 - val_accuracy: 1.0000 - val_loss: 4.3748e-06\n",
      "Epoch 40/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 2.2497e-05 - val_accuracy: 1.0000 - val_loss: 4.0768e-06\n",
      "Epoch 41/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 2.0678e-05 - val_accuracy: 1.0000 - val_loss: 3.6755e-06\n",
      "Epoch 42/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 2.0064e-05 - val_accuracy: 1.0000 - val_loss: 3.4451e-06\n",
      "Epoch 43/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 2.0784e-05 - val_accuracy: 1.0000 - val_loss: 3.0914e-06\n",
      "Epoch 44/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.7569e-05 - val_accuracy: 1.0000 - val_loss: 2.9722e-06\n",
      "Epoch 45/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 1.6636e-05 - val_accuracy: 1.0000 - val_loss: 2.6504e-06\n",
      "Epoch 46/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 1.5314e-05 - val_accuracy: 1.0000 - val_loss: 2.4755e-06\n",
      "Epoch 47/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.4806e-05 - val_accuracy: 1.0000 - val_loss: 2.2411e-06\n",
      "Epoch 48/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 1.4817e-05 - val_accuracy: 1.0000 - val_loss: 2.1418e-06\n",
      "Epoch 49/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 1.2578e-05 - val_accuracy: 1.0000 - val_loss: 1.9947e-06\n",
      "Epoch 50/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 1.1995e-05 - val_accuracy: 1.0000 - val_loss: 1.8437e-06\n",
      "Epoch 51/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.1945e-05 - val_accuracy: 1.0000 - val_loss: 1.6689e-06\n",
      "Epoch 52/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.0163e-05 - val_accuracy: 1.0000 - val_loss: 1.5855e-06\n",
      "Epoch 53/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 1.0124e-05 - val_accuracy: 1.0000 - val_loss: 1.4384e-06\n",
      "Epoch 54/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 9.5511e-06 - val_accuracy: 1.0000 - val_loss: 1.3312e-06\n",
      "Epoch 55/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 8.6143e-06 - val_accuracy: 1.0000 - val_loss: 1.2755e-06\n",
      "Epoch 56/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 8.7172e-06 - val_accuracy: 1.0000 - val_loss: 1.1881e-06\n",
      "Epoch 57/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 7.9662e-06 - val_accuracy: 1.0000 - val_loss: 1.1245e-06\n",
      "Epoch 58/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 7.9154e-06 - val_accuracy: 1.0000 - val_loss: 1.0331e-06\n",
      "Epoch 59/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 6.7508e-06 - val_accuracy: 1.0000 - val_loss: 9.4175e-07\n",
      "Epoch 60/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 7.1300e-06 - val_accuracy: 1.0000 - val_loss: 8.8214e-07\n",
      "Epoch 61/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 6.6775e-06 - val_accuracy: 1.0000 - val_loss: 8.3843e-07\n",
      "Epoch 62/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 6.0546e-06 - val_accuracy: 1.0000 - val_loss: 7.9075e-07\n",
      "Epoch 63/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 6.2299e-06 - val_accuracy: 1.0000 - val_loss: 7.3909e-07\n",
      "Epoch 64/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 5.6449e-06 - val_accuracy: 1.0000 - val_loss: 6.9538e-07\n",
      "Epoch 65/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 5.3961e-06 - val_accuracy: 1.0000 - val_loss: 6.4770e-07\n",
      "Epoch 66/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 5.3304e-06 - val_accuracy: 1.0000 - val_loss: 6.1194e-07\n",
      "Epoch 67/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 4.9166e-06 - val_accuracy: 1.0000 - val_loss: 5.7618e-07\n",
      "Epoch 68/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 4.7108e-06 - val_accuracy: 1.0000 - val_loss: 5.5233e-07\n",
      "Epoch 69/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 4.3558e-06 - val_accuracy: 1.0000 - val_loss: 5.3644e-07\n",
      "Epoch 70/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 3.8538e-06 - val_accuracy: 1.0000 - val_loss: 4.8876e-07\n",
      "Epoch 71/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 4.0377e-06 - val_accuracy: 1.0000 - val_loss: 4.6492e-07\n",
      "Epoch 72/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 3.8340e-06 - val_accuracy: 1.0000 - val_loss: 4.2518e-07\n",
      "Epoch 73/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 3.1949e-06 - val_accuracy: 1.0000 - val_loss: 4.1326e-07\n",
      "Epoch 74/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 3.1676e-06 - val_accuracy: 1.0000 - val_loss: 3.9339e-07\n",
      "Epoch 75/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 3.1826e-06 - val_accuracy: 1.0000 - val_loss: 3.4968e-07\n",
      "Epoch 76/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 3.1570e-06 - val_accuracy: 1.0000 - val_loss: 3.2981e-07\n",
      "Epoch 77/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 2.7402e-06 - val_accuracy: 1.0000 - val_loss: 3.1392e-07\n",
      "Epoch 78/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 2.6825e-06 - val_accuracy: 1.0000 - val_loss: 2.8213e-07\n",
      "Epoch 79/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 2.5854e-06 - val_accuracy: 1.0000 - val_loss: 2.6623e-07\n",
      "Epoch 80/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 2.4578e-06 - val_accuracy: 1.0000 - val_loss: 2.5034e-07\n",
      "Epoch 81/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 2.4487e-06 - val_accuracy: 1.0000 - val_loss: 2.4637e-07\n",
      "Epoch 82/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 2.1053e-06 - val_accuracy: 1.0000 - val_loss: 2.2252e-07\n",
      "Epoch 83/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 2.1116e-06 - val_accuracy: 1.0000 - val_loss: 2.1060e-07\n",
      "Epoch 84/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 2.1197e-06 - val_accuracy: 1.0000 - val_loss: 1.9471e-07\n",
      "Epoch 85/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.8011e-06 - val_accuracy: 1.0000 - val_loss: 1.8279e-07\n",
      "Epoch 86/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 1.7739e-06 - val_accuracy: 1.0000 - val_loss: 1.7484e-07\n",
      "Epoch 87/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.7037e-06 - val_accuracy: 1.0000 - val_loss: 1.5895e-07\n",
      "Epoch 88/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 1.5664e-06 - val_accuracy: 1.0000 - val_loss: 1.5100e-07\n",
      "Epoch 89/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.4312e-06 - val_accuracy: 1.0000 - val_loss: 1.3510e-07\n",
      "Epoch 90/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 1.4834e-06 - val_accuracy: 1.0000 - val_loss: 1.3113e-07\n",
      "Epoch 91/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.3305e-06 - val_accuracy: 1.0000 - val_loss: 1.2716e-07\n",
      "Epoch 92/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 1.2797e-06 - val_accuracy: 1.0000 - val_loss: 1.2318e-07\n",
      "Epoch 93/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.2423e-06 - val_accuracy: 1.0000 - val_loss: 1.1126e-07\n",
      "Epoch 94/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.1268e-06 - val_accuracy: 1.0000 - val_loss: 1.0729e-07\n",
      "Epoch 95/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 1.1220e-06 - val_accuracy: 1.0000 - val_loss: 9.9341e-08\n",
      "Epoch 96/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.0796e-06 - val_accuracy: 1.0000 - val_loss: 9.5367e-08\n",
      "Epoch 97/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 9.9451e-07 - val_accuracy: 1.0000 - val_loss: 7.9473e-08\n",
      "Epoch 98/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 9.9391e-07 - val_accuracy: 1.0000 - val_loss: 7.9473e-08\n",
      "Epoch 99/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 9.9073e-07 - val_accuracy: 1.0000 - val_loss: 7.5499e-08\n",
      "Epoch 100/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 8.6134e-07 - val_accuracy: 1.0000 - val_loss: 7.1526e-08\n",
      "Epoch 101/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 8.3483e-07 - val_accuracy: 1.0000 - val_loss: 6.3578e-08\n",
      "Epoch 102/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 7.3575e-07 - val_accuracy: 1.0000 - val_loss: 5.9605e-08\n",
      "Epoch 103/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 8.6106e-07 - val_accuracy: 1.0000 - val_loss: 5.1657e-08\n",
      "Epoch 104/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 7.6664e-07 - val_accuracy: 1.0000 - val_loss: 5.1657e-08\n",
      "Epoch 105/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 6.9446e-07 - val_accuracy: 1.0000 - val_loss: 4.3710e-08\n",
      "Epoch 106/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 6.7865e-07 - val_accuracy: 1.0000 - val_loss: 4.3710e-08\n",
      "Epoch 107/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 6.0849e-07 - val_accuracy: 1.0000 - val_loss: 4.3710e-08\n",
      "Epoch 108/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 6.1406e-07 - val_accuracy: 1.0000 - val_loss: 3.5763e-08\n",
      "Epoch 109/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 6.2712e-07 - val_accuracy: 1.0000 - val_loss: 3.5763e-08\n",
      "Epoch 110/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 5.0057e-07 - val_accuracy: 1.0000 - val_loss: 3.5763e-08\n",
      "Epoch 111/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 4.7070e-07 - val_accuracy: 1.0000 - val_loss: 2.7815e-08\n",
      "Epoch 112/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 4.8080e-07 - val_accuracy: 1.0000 - val_loss: 2.7815e-08\n",
      "Epoch 113/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 4.8312e-07 - val_accuracy: 1.0000 - val_loss: 2.7815e-08\n",
      "Epoch 114/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 4.2008e-07 - val_accuracy: 1.0000 - val_loss: 2.7815e-08\n",
      "Epoch 115/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 4.0703e-07 - val_accuracy: 1.0000 - val_loss: 2.7815e-08\n",
      "Epoch 116/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 3.9583e-07 - val_accuracy: 1.0000 - val_loss: 2.7815e-08\n",
      "Epoch 117/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 3.7529e-07 - val_accuracy: 1.0000 - val_loss: 2.3842e-08\n",
      "Epoch 118/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 3.6744e-07 - val_accuracy: 1.0000 - val_loss: 2.3842e-08\n",
      "Epoch 119/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 3.4753e-07 - val_accuracy: 1.0000 - val_loss: 2.3842e-08\n",
      "Epoch 120/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 3.2461e-07 - val_accuracy: 1.0000 - val_loss: 2.3842e-08\n",
      "Epoch 121/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 3.0091e-07 - val_accuracy: 1.0000 - val_loss: 2.3842e-08\n",
      "Epoch 122/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 3.0063e-07 - val_accuracy: 1.0000 - val_loss: 2.3842e-08\n",
      "Epoch 123/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 2.8810e-07 - val_accuracy: 1.0000 - val_loss: 2.3842e-08\n",
      "Epoch 124/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 2.7700e-07 - val_accuracy: 1.0000 - val_loss: 1.9868e-08\n",
      "Epoch 125/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 2.5249e-07 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 126/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 2.4815e-07 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 127/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 2.4156e-07 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 128/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 2.2379e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 129/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 2.0260e-07 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 130/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 2.0477e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 131/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 1.8833e-07 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 132/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 1.7271e-07 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 133/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.7255e-07 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 134/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.6302e-07 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 135/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.5954e-07 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 136/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.5685e-07 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 137/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.4336e-07 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 138/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.4831e-07 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 139/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.3536e-07 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 140/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.2111e-07 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 141/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.2314e-07 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 142/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.0895e-07 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 143/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.0438e-07 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 144/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 9.8232e-08 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 145/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 9.5750e-08 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 146/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 9.0083e-08 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 147/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 8.7301e-08 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 148/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 8.5595e-08 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 149/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 8.1325e-08 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 150/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 7.6477e-08 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 151/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 7.8527e-08 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 152/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 7.1711e-08 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 153/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 6.3202e-08 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 154/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 6.4202e-08 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 155/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 5.6828e-08 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 156/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 5.6986e-08 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 157/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 5.5683e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 158/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 4.9717e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 159/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 4.9619e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 160/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 4.1999e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 161/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 4.1632e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 162/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 4.4566e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 163/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 4.0773e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 164/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 3.8890e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 165/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 3.5431e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 166/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 3.4572e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 167/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 3.5084e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 168/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 3.1842e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 169/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 2.9651e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 170/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 2.8545e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 171/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 2.9297e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 172/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 2.7736e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 173/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 2.3989e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 174/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 2.2989e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 175/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 2.3661e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 176/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 2.0803e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 177/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 2.1679e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 178/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 2.0240e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 179/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 2.0276e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 180/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.6906e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 181/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 1.8951e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 182/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.6720e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 183/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 1.6500e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 184/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.5222e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 185/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 1.5713e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 186/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 1.4858e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 187/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.3463e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 188/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 1.1878e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 189/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 1.3573e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 190/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.2517e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 191/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 1.2144e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 192/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 1.1700e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 193/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 1.0761e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 194/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 9.1422e-09 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 195/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 1.0520e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 196/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 8.7740e-09 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 197/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 1.1741e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 198/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 9.1528e-09 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 199/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 9.1076e-09 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 200/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 8.4351e-09 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 201/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 7.6956e-09 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 202/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 6.7747e-09 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 203/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 7.4818e-09 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 204/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 6.5067e-09 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 205/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 7.3842e-09 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 206/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 6.2885e-09 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 207/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 6.6239e-09 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 208/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 6.0952e-09 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 209/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 7.0352e-09 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 210/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 6.0952e-09 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 211/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 5.5373e-09 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 212/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 4.7541e-09 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 213/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 4.6153e-09 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 214/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 4.2086e-09 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 214: early stopping\n",
      "Restoring model weights from the end of the best epoch: 184.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Training fold 3\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "2970 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({np.int64(6): 270, np.int64(7): 270, np.int64(4): 270, np.int64(3): 270, np.int64(5): 270, np.int64(8): 270, np.int64(9): 270, np.int64(2): 270, np.int64(10): 270, np.int64(1): 270, np.int64(0): 270})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.8185 - loss: 0.8643 - val_accuracy: 1.0000 - val_loss: 0.0038\n",
      "Epoch 2/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9614 - loss: 0.1449 - val_accuracy: 1.0000 - val_loss: 0.0133\n",
      "Epoch 3/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.9924 - loss: 0.0338 - val_accuracy: 1.0000 - val_loss: 8.3217e-04\n",
      "Epoch 4/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9992 - loss: 0.0067 - val_accuracy: 1.0000 - val_loss: 2.7559e-04\n",
      "Epoch 5/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9999 - loss: 0.0027 - val_accuracy: 1.0000 - val_loss: 1.8082e-04\n",
      "Epoch 6/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 7.6643e-04 - val_accuracy: 1.0000 - val_loss: 8.9930e-05\n",
      "Epoch 7/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 4.7158e-04 - val_accuracy: 1.0000 - val_loss: 5.9184e-05\n",
      "Epoch 8/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 2.9240e-04 - val_accuracy: 1.0000 - val_loss: 4.5848e-05\n",
      "Epoch 9/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.9575e-04 - val_accuracy: 1.0000 - val_loss: 3.5547e-05\n",
      "Epoch 10/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.7041e-04 - val_accuracy: 1.0000 - val_loss: 2.8865e-05\n",
      "Epoch 11/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.5195e-04 - val_accuracy: 1.0000 - val_loss: 2.4066e-05\n",
      "Epoch 12/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.2864e-04 - val_accuracy: 1.0000 - val_loss: 2.0653e-05\n",
      "Epoch 13/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.1031e-04 - val_accuracy: 1.0000 - val_loss: 1.7979e-05\n",
      "Epoch 14/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.1687e-04 - val_accuracy: 1.0000 - val_loss: 1.5421e-05\n",
      "Epoch 15/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 8.4805e-05 - val_accuracy: 1.0000 - val_loss: 1.3605e-05\n",
      "Epoch 16/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 8.0174e-05 - val_accuracy: 1.0000 - val_loss: 1.2178e-05\n",
      "Epoch 17/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 8.0582e-05 - val_accuracy: 1.0000 - val_loss: 1.0585e-05\n",
      "Epoch 18/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 6.8190e-05 - val_accuracy: 1.0000 - val_loss: 9.5402e-06\n",
      "Epoch 19/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 6.9821e-05 - val_accuracy: 1.0000 - val_loss: 8.4555e-06\n",
      "Epoch 20/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 5.6959e-05 - val_accuracy: 1.0000 - val_loss: 7.7205e-06\n",
      "Epoch 21/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 5.2313e-05 - val_accuracy: 1.0000 - val_loss: 6.9576e-06\n",
      "Epoch 22/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.9237e-05 - val_accuracy: 1.0000 - val_loss: 6.2503e-06\n",
      "Epoch 23/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 4.2906e-05 - val_accuracy: 1.0000 - val_loss: 5.6980e-06\n",
      "Epoch 24/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 4.1872e-05 - val_accuracy: 1.0000 - val_loss: 5.2411e-06\n",
      "Epoch 25/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 3.7509e-05 - val_accuracy: 1.0000 - val_loss: 4.7206e-06\n",
      "Epoch 26/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 3.8350e-05 - val_accuracy: 1.0000 - val_loss: 4.3709e-06\n",
      "Epoch 27/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 3.2588e-05 - val_accuracy: 1.0000 - val_loss: 4.0689e-06\n",
      "Epoch 28/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 3.0773e-05 - val_accuracy: 1.0000 - val_loss: 3.6795e-06\n",
      "Epoch 29/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 3.0541e-05 - val_accuracy: 1.0000 - val_loss: 3.3855e-06\n",
      "Epoch 30/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 2.9249e-05 - val_accuracy: 1.0000 - val_loss: 3.2265e-06\n",
      "Epoch 31/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 2.8053e-05 - val_accuracy: 1.0000 - val_loss: 2.8570e-06\n",
      "Epoch 32/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 2.6433e-05 - val_accuracy: 1.0000 - val_loss: 2.5987e-06\n",
      "Epoch 33/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.4466e-05 - val_accuracy: 1.0000 - val_loss: 2.4477e-06\n",
      "Epoch 34/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.2281e-05 - val_accuracy: 1.0000 - val_loss: 2.2491e-06\n",
      "Epoch 35/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 2.2002e-05 - val_accuracy: 1.0000 - val_loss: 2.0464e-06\n",
      "Epoch 36/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.9944e-05 - val_accuracy: 1.0000 - val_loss: 1.9391e-06\n",
      "Epoch 37/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.6804e-05 - val_accuracy: 1.0000 - val_loss: 1.7881e-06\n",
      "Epoch 38/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.6443e-05 - val_accuracy: 1.0000 - val_loss: 1.6530e-06\n",
      "Epoch 39/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 1.6997e-05 - val_accuracy: 1.0000 - val_loss: 1.5259e-06\n",
      "Epoch 40/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 1.7376e-05 - val_accuracy: 1.0000 - val_loss: 1.3828e-06\n",
      "Epoch 41/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 1.5464e-05 - val_accuracy: 1.0000 - val_loss: 1.3153e-06\n",
      "Epoch 42/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 1.4745e-05 - val_accuracy: 1.0000 - val_loss: 1.2199e-06\n",
      "Epoch 43/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.5776e-05 - val_accuracy: 1.0000 - val_loss: 1.1206e-06\n",
      "Epoch 44/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.3979e-05 - val_accuracy: 1.0000 - val_loss: 1.0570e-06\n",
      "Epoch 45/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.2605e-05 - val_accuracy: 1.0000 - val_loss: 9.8149e-07\n",
      "Epoch 46/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 1.2071e-05 - val_accuracy: 1.0000 - val_loss: 9.2585e-07\n",
      "Epoch 47/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.1132e-05 - val_accuracy: 1.0000 - val_loss: 8.7817e-07\n",
      "Epoch 48/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 1.0517e-05 - val_accuracy: 1.0000 - val_loss: 8.1459e-07\n",
      "Epoch 49/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.0359e-05 - val_accuracy: 1.0000 - val_loss: 7.7486e-07\n",
      "Epoch 50/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 8.6553e-06 - val_accuracy: 1.0000 - val_loss: 7.2717e-07\n",
      "Epoch 51/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 9.0637e-06 - val_accuracy: 1.0000 - val_loss: 6.9936e-07\n",
      "Epoch 52/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 8.2446e-06 - val_accuracy: 1.0000 - val_loss: 6.5168e-07\n",
      "Epoch 53/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 9.5013e-06 - val_accuracy: 1.0000 - val_loss: 6.3181e-07\n",
      "Epoch 54/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 8.0153e-06 - val_accuracy: 1.0000 - val_loss: 5.9207e-07\n",
      "Epoch 55/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 7.5007e-06 - val_accuracy: 1.0000 - val_loss: 5.4836e-07\n",
      "Epoch 56/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 6.7006e-06 - val_accuracy: 1.0000 - val_loss: 5.3247e-07\n",
      "Epoch 57/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 6.0615e-06 - val_accuracy: 1.0000 - val_loss: 4.9273e-07\n",
      "Epoch 58/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 6.0057e-06 - val_accuracy: 1.0000 - val_loss: 4.4902e-07\n",
      "Epoch 59/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 4.8000e-06 - val_accuracy: 1.0000 - val_loss: 4.2915e-07\n",
      "Epoch 60/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 6.3488e-06 - val_accuracy: 1.0000 - val_loss: 3.9736e-07\n",
      "Epoch 61/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 5.1622e-06 - val_accuracy: 1.0000 - val_loss: 3.6955e-07\n",
      "Epoch 62/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 5.0048e-06 - val_accuracy: 1.0000 - val_loss: 3.4968e-07\n",
      "Epoch 63/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 4.3250e-06 - val_accuracy: 1.0000 - val_loss: 3.2981e-07\n",
      "Epoch 64/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 4.6006e-06 - val_accuracy: 1.0000 - val_loss: 3.0597e-07\n",
      "Epoch 65/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 4.0215e-06 - val_accuracy: 1.0000 - val_loss: 2.9802e-07\n",
      "Epoch 66/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 3.7814e-06 - val_accuracy: 1.0000 - val_loss: 2.7815e-07\n",
      "Epoch 67/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 3.6698e-06 - val_accuracy: 1.0000 - val_loss: 2.7418e-07\n",
      "Epoch 68/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 3.5298e-06 - val_accuracy: 1.0000 - val_loss: 2.5431e-07\n",
      "Epoch 69/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 3.4707e-06 - val_accuracy: 1.0000 - val_loss: 2.4239e-07\n",
      "Epoch 70/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 3.0923e-06 - val_accuracy: 1.0000 - val_loss: 2.3444e-07\n",
      "Epoch 71/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 3.1935e-06 - val_accuracy: 1.0000 - val_loss: 2.2252e-07\n",
      "Epoch 72/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 2.8552e-06 - val_accuracy: 1.0000 - val_loss: 2.0663e-07\n",
      "Epoch 73/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 2.6668e-06 - val_accuracy: 1.0000 - val_loss: 1.9868e-07\n",
      "Epoch 74/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 2.7111e-06 - val_accuracy: 1.0000 - val_loss: 1.8676e-07\n",
      "Epoch 75/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 2.5781e-06 - val_accuracy: 1.0000 - val_loss: 1.7484e-07\n",
      "Epoch 76/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 2.3852e-06 - val_accuracy: 1.0000 - val_loss: 1.7087e-07\n",
      "Epoch 77/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 2.1137e-06 - val_accuracy: 1.0000 - val_loss: 1.6292e-07\n",
      "Epoch 78/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 2.0680e-06 - val_accuracy: 1.0000 - val_loss: 1.5100e-07\n",
      "Epoch 79/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.9188e-06 - val_accuracy: 1.0000 - val_loss: 1.3908e-07\n",
      "Epoch 80/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.8302e-06 - val_accuracy: 1.0000 - val_loss: 1.3113e-07\n",
      "Epoch 81/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 1.8119e-06 - val_accuracy: 1.0000 - val_loss: 1.2318e-07\n",
      "Epoch 82/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.8139e-06 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 83/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.6834e-06 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 84/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.6129e-06 - val_accuracy: 1.0000 - val_loss: 1.1126e-07\n",
      "Epoch 85/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.6231e-06 - val_accuracy: 1.0000 - val_loss: 9.9341e-08\n",
      "Epoch 86/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.4263e-06 - val_accuracy: 1.0000 - val_loss: 9.9341e-08\n",
      "Epoch 87/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.3384e-06 - val_accuracy: 1.0000 - val_loss: 9.1394e-08\n",
      "Epoch 88/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 1.3190e-06 - val_accuracy: 1.0000 - val_loss: 9.1394e-08\n",
      "Epoch 89/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.3448e-06 - val_accuracy: 1.0000 - val_loss: 9.1394e-08\n",
      "Epoch 90/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 1.1837e-06 - val_accuracy: 1.0000 - val_loss: 7.9473e-08\n",
      "Epoch 91/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 1.0503e-06 - val_accuracy: 1.0000 - val_loss: 7.9473e-08\n",
      "Epoch 92/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.0125e-06 - val_accuracy: 1.0000 - val_loss: 7.5499e-08\n",
      "Epoch 93/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 9.7387e-07 - val_accuracy: 1.0000 - val_loss: 7.1526e-08\n",
      "Epoch 94/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 9.3635e-07 - val_accuracy: 1.0000 - val_loss: 6.7552e-08\n",
      "Epoch 95/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 9.2409e-07 - val_accuracy: 1.0000 - val_loss: 5.5631e-08\n",
      "Epoch 96/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 9.5440e-07 - val_accuracy: 1.0000 - val_loss: 5.1657e-08\n",
      "Epoch 97/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 8.3042e-07 - val_accuracy: 1.0000 - val_loss: 5.1657e-08\n",
      "Epoch 98/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 8.1094e-07 - val_accuracy: 1.0000 - val_loss: 5.1657e-08\n",
      "Epoch 99/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 6.8042e-07 - val_accuracy: 1.0000 - val_loss: 4.7684e-08\n",
      "Epoch 100/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 7.2911e-07 - val_accuracy: 1.0000 - val_loss: 4.3710e-08\n",
      "Epoch 101/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 7.1495e-07 - val_accuracy: 1.0000 - val_loss: 3.9736e-08\n",
      "Epoch 102/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 6.7016e-07 - val_accuracy: 1.0000 - val_loss: 3.9736e-08\n",
      "Epoch 103/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 5.8597e-07 - val_accuracy: 1.0000 - val_loss: 3.1789e-08\n",
      "Epoch 104/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 5.8816e-07 - val_accuracy: 1.0000 - val_loss: 3.1789e-08\n",
      "Epoch 105/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 5.3616e-07 - val_accuracy: 1.0000 - val_loss: 3.1789e-08\n",
      "Epoch 106/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 5.6239e-07 - val_accuracy: 1.0000 - val_loss: 3.1789e-08\n",
      "Epoch 107/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 4.7710e-07 - val_accuracy: 1.0000 - val_loss: 3.1789e-08\n",
      "Epoch 108/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 5.1564e-07 - val_accuracy: 1.0000 - val_loss: 2.7815e-08\n",
      "Epoch 109/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 4.7341e-07 - val_accuracy: 1.0000 - val_loss: 2.3842e-08\n",
      "Epoch 110/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.2182e-07 - val_accuracy: 1.0000 - val_loss: 2.3842e-08\n",
      "Epoch 111/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 3.7502e-07 - val_accuracy: 1.0000 - val_loss: 2.3842e-08\n",
      "Epoch 112/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 3.7089e-07 - val_accuracy: 1.0000 - val_loss: 1.9868e-08\n",
      "Epoch 113/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.5754e-07 - val_accuracy: 1.0000 - val_loss: 1.9868e-08\n",
      "Epoch 114/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 3.8607e-07 - val_accuracy: 1.0000 - val_loss: 1.9868e-08\n",
      "Epoch 115/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 3.3369e-07 - val_accuracy: 1.0000 - val_loss: 1.9868e-08\n",
      "Epoch 116/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 3.1674e-07 - val_accuracy: 1.0000 - val_loss: 1.9868e-08\n",
      "Epoch 117/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 3.0764e-07 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 118/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 3.0201e-07 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 119/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 2.8467e-07 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 120/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 2.4227e-07 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 121/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 2.4794e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 122/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.5890e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 123/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 2.2587e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 124/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 2.2326e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 125/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 2.1760e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 126/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 1.8518e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 127/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.8817e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 128/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 1.6921e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 129/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.7060e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 130/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 1.6481e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 131/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.5295e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 132/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.4625e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 133/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.3704e-07 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 134/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.3024e-07 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 135/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 1.2406e-07 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 136/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.1988e-07 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 137/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.1266e-07 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 138/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.1227e-07 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 139/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 9.5962e-08 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 140/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 1.0549e-07 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 141/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 9.4540e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 142/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 8.7507e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 143/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 8.4735e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 144/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 8.2080e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 145/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 7.6425e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 146/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 6.8483e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 147/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 6.6763e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 148/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 6.9283e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 149/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 6.2648e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 150/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 5.9348e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 151/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 5.4073e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 152/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 5.4379e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 153/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 5.5797e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 154/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 4.7030e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 155/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 4.6790e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 156/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 4.4632e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 157/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 4.0407e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 158/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 4.1932e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 159/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 3.6482e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 160/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 3.4843e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 161/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 3.7485e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 162/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 3.4344e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 163/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 3.2998e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 164/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 2.8667e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 165/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 2.6737e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 166/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 2.5543e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 167/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 2.4972e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 168/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 2.4112e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 169/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 2.3904e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 170/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 2.1610e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 171/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 2.0821e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 172/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.8994e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 173/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 2.0475e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 174/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.7102e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 175/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 1.6462e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 176/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.6464e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 176: early stopping\n",
      "Restoring model weights from the end of the best epoch: 146.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\n",
      "Training fold 4\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "2970 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({np.int64(6): 270, np.int64(7): 270, np.int64(4): 270, np.int64(3): 270, np.int64(5): 270, np.int64(8): 270, np.int64(9): 270, np.int64(2): 270, np.int64(10): 270, np.int64(1): 270, np.int64(0): 270})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9074 - loss: 0.3942 - val_accuracy: 0.9333 - val_loss: 0.0901\n",
      "Epoch 2/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9795 - loss: 0.0731 - val_accuracy: 1.0000 - val_loss: 0.0095\n",
      "Epoch 3/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.9964 - loss: 0.0142 - val_accuracy: 1.0000 - val_loss: 1.2793e-04\n",
      "Epoch 4/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 9.5204e-04 - val_accuracy: 1.0000 - val_loss: 7.7918e-05\n",
      "Epoch 5/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 3.1721e-04 - val_accuracy: 1.0000 - val_loss: 5.7742e-05\n",
      "Epoch 6/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.9349e-04 - val_accuracy: 1.0000 - val_loss: 4.9000e-05\n",
      "Epoch 7/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 1.5629e-04 - val_accuracy: 1.0000 - val_loss: 4.6092e-05\n",
      "Epoch 8/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.4334e-04 - val_accuracy: 1.0000 - val_loss: 3.9781e-05\n",
      "Epoch 9/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 1.1380e-04 - val_accuracy: 1.0000 - val_loss: 3.6560e-05\n",
      "Epoch 10/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 8.7643e-05 - val_accuracy: 1.0000 - val_loss: 3.4657e-05\n",
      "Epoch 11/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 9.1757e-05 - val_accuracy: 1.0000 - val_loss: 3.1853e-05\n",
      "Epoch 12/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 6.5780e-05 - val_accuracy: 1.0000 - val_loss: 2.8830e-05\n",
      "Epoch 13/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 7.0999e-05 - val_accuracy: 1.0000 - val_loss: 2.6991e-05\n",
      "Epoch 14/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 6.3122e-05 - val_accuracy: 1.0000 - val_loss: 2.5100e-05\n",
      "Epoch 15/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 5.5786e-05 - val_accuracy: 1.0000 - val_loss: 2.2376e-05\n",
      "Epoch 16/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 5.1488e-05 - val_accuracy: 1.0000 - val_loss: 2.1529e-05\n",
      "Epoch 17/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 4.6070e-05 - val_accuracy: 1.0000 - val_loss: 2.0620e-05\n",
      "Epoch 18/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 4.2271e-05 - val_accuracy: 1.0000 - val_loss: 1.8999e-05\n",
      "Epoch 19/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 3.9372e-05 - val_accuracy: 1.0000 - val_loss: 1.8248e-05\n",
      "Epoch 20/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 3.9551e-05 - val_accuracy: 1.0000 - val_loss: 1.6882e-05\n",
      "Epoch 21/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 3.7133e-05 - val_accuracy: 1.0000 - val_loss: 1.6135e-05\n",
      "Epoch 22/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 3.1339e-05 - val_accuracy: 1.0000 - val_loss: 1.4864e-05\n",
      "Epoch 23/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 2.9713e-05 - val_accuracy: 1.0000 - val_loss: 1.2849e-05\n",
      "Epoch 24/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 2.9306e-05 - val_accuracy: 1.0000 - val_loss: 1.3072e-05\n",
      "Epoch 25/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 2.7138e-05 - val_accuracy: 1.0000 - val_loss: 1.1383e-05\n",
      "Epoch 26/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 2.5856e-05 - val_accuracy: 1.0000 - val_loss: 1.0835e-05\n",
      "Epoch 27/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 2.4657e-05 - val_accuracy: 1.0000 - val_loss: 9.8777e-06\n",
      "Epoch 28/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 2.2577e-05 - val_accuracy: 1.0000 - val_loss: 9.1188e-06\n",
      "Epoch 29/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 2.2684e-05 - val_accuracy: 1.0000 - val_loss: 7.9547e-06\n",
      "Epoch 30/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.9253e-05 - val_accuracy: 1.0000 - val_loss: 7.0767e-06\n",
      "Epoch 31/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.7559e-05 - val_accuracy: 1.0000 - val_loss: 7.0012e-06\n",
      "Epoch 32/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 1.8573e-05 - val_accuracy: 1.0000 - val_loss: 6.0834e-06\n",
      "Epoch 33/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.4843e-05 - val_accuracy: 1.0000 - val_loss: 5.4596e-06\n",
      "Epoch 34/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 1.6427e-05 - val_accuracy: 1.0000 - val_loss: 4.9311e-06\n",
      "Epoch 35/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.6672e-05 - val_accuracy: 1.0000 - val_loss: 4.5139e-06\n",
      "Epoch 36/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.3235e-05 - val_accuracy: 1.0000 - val_loss: 4.0212e-06\n",
      "Epoch 37/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 1.3435e-05 - val_accuracy: 1.0000 - val_loss: 3.9497e-06\n",
      "Epoch 38/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 1.2655e-05 - val_accuracy: 1.0000 - val_loss: 3.6358e-06\n",
      "Epoch 39/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.0985e-05 - val_accuracy: 1.0000 - val_loss: 3.4292e-06\n",
      "Epoch 40/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 1.1519e-05 - val_accuracy: 1.0000 - val_loss: 3.1272e-06\n",
      "Epoch 41/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.1557e-05 - val_accuracy: 1.0000 - val_loss: 3.0040e-06\n",
      "Epoch 42/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 9.8442e-06 - val_accuracy: 1.0000 - val_loss: 2.7696e-06\n",
      "Epoch 43/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 8.4709e-06 - val_accuracy: 1.0000 - val_loss: 2.4199e-06\n",
      "Epoch 44/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 9.4154e-06 - val_accuracy: 1.0000 - val_loss: 2.2610e-06\n",
      "Epoch 45/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 8.1034e-06 - val_accuracy: 1.0000 - val_loss: 2.0941e-06\n",
      "Epoch 46/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 7.9625e-06 - val_accuracy: 1.0000 - val_loss: 1.9471e-06\n",
      "Epoch 47/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 7.2050e-06 - val_accuracy: 1.0000 - val_loss: 1.7603e-06\n",
      "Epoch 48/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 8.2639e-06 - val_accuracy: 1.0000 - val_loss: 1.5537e-06\n",
      "Epoch 49/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 7.2362e-06 - val_accuracy: 1.0000 - val_loss: 1.4384e-06\n",
      "Epoch 50/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 6.3866e-06 - val_accuracy: 1.0000 - val_loss: 1.3590e-06\n",
      "Epoch 51/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 6.7737e-06 - val_accuracy: 1.0000 - val_loss: 1.2437e-06\n",
      "Epoch 52/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 6.1572e-06 - val_accuracy: 1.0000 - val_loss: 1.1245e-06\n",
      "Epoch 53/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 5.5979e-06 - val_accuracy: 1.0000 - val_loss: 1.0292e-06\n",
      "Epoch 54/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 5.3440e-06 - val_accuracy: 1.0000 - val_loss: 9.4970e-07\n",
      "Epoch 55/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 4.9187e-06 - val_accuracy: 1.0000 - val_loss: 9.2188e-07\n",
      "Epoch 56/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 5.0262e-06 - val_accuracy: 1.0000 - val_loss: 8.7420e-07\n",
      "Epoch 57/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 4.5990e-06 - val_accuracy: 1.0000 - val_loss: 8.4638e-07\n",
      "Epoch 58/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 4.1694e-06 - val_accuracy: 1.0000 - val_loss: 8.2254e-07\n",
      "Epoch 59/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 4.2404e-06 - val_accuracy: 1.0000 - val_loss: 7.6691e-07\n",
      "Epoch 60/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 4.1203e-06 - val_accuracy: 1.0000 - val_loss: 7.3512e-07\n",
      "Epoch 61/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 3.9813e-06 - val_accuracy: 1.0000 - val_loss: 7.1923e-07\n",
      "Epoch 62/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 3.5892e-06 - val_accuracy: 1.0000 - val_loss: 6.8744e-07\n",
      "Epoch 63/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.3162e-06 - val_accuracy: 1.0000 - val_loss: 6.8346e-07\n",
      "Epoch 64/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 3.1390e-06 - val_accuracy: 1.0000 - val_loss: 6.4770e-07\n",
      "Epoch 65/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 2.7605e-06 - val_accuracy: 1.0000 - val_loss: 6.1989e-07\n",
      "Epoch 66/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 3.1039e-06 - val_accuracy: 1.0000 - val_loss: 5.8810e-07\n",
      "Epoch 67/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 2.6781e-06 - val_accuracy: 1.0000 - val_loss: 5.6028e-07\n",
      "Epoch 68/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 2.8394e-06 - val_accuracy: 1.0000 - val_loss: 5.4836e-07\n",
      "Epoch 69/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 2.5082e-06 - val_accuracy: 1.0000 - val_loss: 5.2452e-07\n",
      "Epoch 70/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 2.4046e-06 - val_accuracy: 1.0000 - val_loss: 5.1260e-07\n",
      "Epoch 71/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 2.3537e-06 - val_accuracy: 1.0000 - val_loss: 5.0863e-07\n",
      "Epoch 72/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 2.1708e-06 - val_accuracy: 1.0000 - val_loss: 4.8478e-07\n",
      "Epoch 73/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 2.1385e-06 - val_accuracy: 1.0000 - val_loss: 4.7684e-07\n",
      "Epoch 74/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 1.8800e-06 - val_accuracy: 1.0000 - val_loss: 4.7286e-07\n",
      "Epoch 75/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.9802e-06 - val_accuracy: 1.0000 - val_loss: 4.5697e-07\n",
      "Epoch 76/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.8328e-06 - val_accuracy: 1.0000 - val_loss: 4.4902e-07\n",
      "Epoch 77/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 1.8136e-06 - val_accuracy: 1.0000 - val_loss: 4.2121e-07\n",
      "Epoch 78/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.5725e-06 - val_accuracy: 1.0000 - val_loss: 4.0531e-07\n",
      "Epoch 79/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.5242e-06 - val_accuracy: 1.0000 - val_loss: 4.0928e-07\n",
      "Epoch 80/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 1.5476e-06 - val_accuracy: 1.0000 - val_loss: 4.0928e-07\n",
      "Epoch 81/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.4576e-06 - val_accuracy: 1.0000 - val_loss: 3.9339e-07\n",
      "Epoch 82/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.3230e-06 - val_accuracy: 1.0000 - val_loss: 3.9339e-07\n",
      "Epoch 83/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.3253e-06 - val_accuracy: 1.0000 - val_loss: 3.7352e-07\n",
      "Epoch 84/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 1.3098e-06 - val_accuracy: 1.0000 - val_loss: 3.7352e-07\n",
      "Epoch 85/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 1.1678e-06 - val_accuracy: 1.0000 - val_loss: 3.6557e-07\n",
      "Epoch 86/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 1.0662e-06 - val_accuracy: 1.0000 - val_loss: 3.6557e-07\n",
      "Epoch 87/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 9.7086e-07 - val_accuracy: 1.0000 - val_loss: 3.2981e-07\n",
      "Epoch 88/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 1.0108e-06 - val_accuracy: 1.0000 - val_loss: 3.4968e-07\n",
      "Epoch 89/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 9.7286e-07 - val_accuracy: 1.0000 - val_loss: 3.2981e-07\n",
      "Epoch 90/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 9.6965e-07 - val_accuracy: 1.0000 - val_loss: 3.3379e-07\n",
      "Epoch 91/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 9.1811e-07 - val_accuracy: 1.0000 - val_loss: 3.0994e-07\n",
      "Epoch 92/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 9.0104e-07 - val_accuracy: 1.0000 - val_loss: 3.0200e-07\n",
      "Epoch 93/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 7.6098e-07 - val_accuracy: 1.0000 - val_loss: 2.7418e-07\n",
      "Epoch 94/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 7.8565e-07 - val_accuracy: 1.0000 - val_loss: 2.9008e-07\n",
      "Epoch 95/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 7.5554e-07 - val_accuracy: 1.0000 - val_loss: 2.7418e-07\n",
      "Epoch 96/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 6.3591e-07 - val_accuracy: 1.0000 - val_loss: 2.6226e-07\n",
      "Epoch 97/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 5.8521e-07 - val_accuracy: 1.0000 - val_loss: 2.5829e-07\n",
      "Epoch 98/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 6.0647e-07 - val_accuracy: 1.0000 - val_loss: 2.5034e-07\n",
      "Epoch 99/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 6.1807e-07 - val_accuracy: 1.0000 - val_loss: 2.3047e-07\n",
      "Epoch 100/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 5.6488e-07 - val_accuracy: 1.0000 - val_loss: 2.3444e-07\n",
      "Epoch 101/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 5.4758e-07 - val_accuracy: 1.0000 - val_loss: 2.1060e-07\n",
      "Epoch 102/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 5.5572e-07 - val_accuracy: 1.0000 - val_loss: 1.9868e-07\n",
      "Epoch 103/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 5.4498e-07 - val_accuracy: 1.0000 - val_loss: 2.0266e-07\n",
      "Epoch 104/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 4.4480e-07 - val_accuracy: 1.0000 - val_loss: 1.9073e-07\n",
      "Epoch 105/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 4.6383e-07 - val_accuracy: 1.0000 - val_loss: 1.8279e-07\n",
      "Epoch 106/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 3.9401e-07 - val_accuracy: 1.0000 - val_loss: 1.8279e-07\n",
      "Epoch 107/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 4.1162e-07 - val_accuracy: 1.0000 - val_loss: 1.6689e-07\n",
      "Epoch 108/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 3.7355e-07 - val_accuracy: 1.0000 - val_loss: 1.6689e-07\n",
      "Epoch 109/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.3506e-07 - val_accuracy: 1.0000 - val_loss: 1.5895e-07\n",
      "Epoch 110/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 3.0932e-07 - val_accuracy: 1.0000 - val_loss: 1.5497e-07\n",
      "Epoch 111/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 3.4464e-07 - val_accuracy: 1.0000 - val_loss: 1.5497e-07\n",
      "Epoch 112/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 3.0119e-07 - val_accuracy: 1.0000 - val_loss: 1.5100e-07\n",
      "Epoch 113/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 2.6183e-07 - val_accuracy: 1.0000 - val_loss: 1.5100e-07\n",
      "Epoch 114/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 2.8784e-07 - val_accuracy: 1.0000 - val_loss: 1.5100e-07\n",
      "Epoch 115/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 2.7729e-07 - val_accuracy: 1.0000 - val_loss: 1.4305e-07\n",
      "Epoch 116/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 2.8084e-07 - val_accuracy: 1.0000 - val_loss: 1.4305e-07\n",
      "Epoch 117/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 2.2963e-07 - val_accuracy: 1.0000 - val_loss: 1.3113e-07\n",
      "Epoch 118/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 2.4833e-07 - val_accuracy: 1.0000 - val_loss: 1.2716e-07\n",
      "Epoch 119/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 2.1814e-07 - val_accuracy: 1.0000 - val_loss: 1.2318e-07\n",
      "Epoch 120/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 2.0586e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 121/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 2.0672e-07 - val_accuracy: 1.0000 - val_loss: 1.1524e-07\n",
      "Epoch 122/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 1.8579e-07 - val_accuracy: 1.0000 - val_loss: 1.0331e-07\n",
      "Epoch 123/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.7919e-07 - val_accuracy: 1.0000 - val_loss: 1.0729e-07\n",
      "Epoch 124/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 1.5998e-07 - val_accuracy: 1.0000 - val_loss: 1.0331e-07\n",
      "Epoch 125/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.6433e-07 - val_accuracy: 1.0000 - val_loss: 1.0331e-07\n",
      "Epoch 126/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.3773e-07 - val_accuracy: 1.0000 - val_loss: 1.0331e-07\n",
      "Epoch 127/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.4398e-07 - val_accuracy: 1.0000 - val_loss: 9.9341e-08\n",
      "Epoch 128/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 1.2447e-07 - val_accuracy: 1.0000 - val_loss: 9.9341e-08\n",
      "Epoch 129/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.3987e-07 - val_accuracy: 1.0000 - val_loss: 9.9341e-08\n",
      "Epoch 130/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.4113e-07 - val_accuracy: 1.0000 - val_loss: 9.9341e-08\n",
      "Epoch 131/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.2301e-07 - val_accuracy: 1.0000 - val_loss: 9.9341e-08\n",
      "Epoch 132/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 1.1037e-07 - val_accuracy: 1.0000 - val_loss: 9.5367e-08\n",
      "Epoch 133/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 1.2150e-07 - val_accuracy: 1.0000 - val_loss: 9.5367e-08\n",
      "Epoch 134/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 1.0325e-07 - val_accuracy: 1.0000 - val_loss: 9.5367e-08\n",
      "Epoch 135/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.0671e-07 - val_accuracy: 1.0000 - val_loss: 9.5367e-08\n",
      "Epoch 136/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 8.9644e-08 - val_accuracy: 1.0000 - val_loss: 8.7420e-08\n",
      "Epoch 137/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 8.8705e-08 - val_accuracy: 1.0000 - val_loss: 8.3446e-08\n",
      "Epoch 138/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 9.4210e-08 - val_accuracy: 1.0000 - val_loss: 8.3446e-08\n",
      "Epoch 139/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 8.3485e-08 - val_accuracy: 1.0000 - val_loss: 7.9473e-08\n",
      "Epoch 140/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 8.0244e-08 - val_accuracy: 1.0000 - val_loss: 7.9473e-08\n",
      "Epoch 141/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 8.2846e-08 - val_accuracy: 1.0000 - val_loss: 7.5499e-08\n",
      "Epoch 142/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 7.6646e-08 - val_accuracy: 1.0000 - val_loss: 7.9473e-08\n",
      "Epoch 143/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 7.4457e-08 - val_accuracy: 1.0000 - val_loss: 7.5499e-08\n",
      "Epoch 144/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 6.8789e-08 - val_accuracy: 1.0000 - val_loss: 7.1526e-08\n",
      "Epoch 145/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 6.3982e-08 - val_accuracy: 1.0000 - val_loss: 6.7552e-08\n",
      "Epoch 146/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 6.5800e-08 - val_accuracy: 1.0000 - val_loss: 6.3578e-08\n",
      "Epoch 147/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 5.5126e-08 - val_accuracy: 1.0000 - val_loss: 6.7552e-08\n",
      "Epoch 148/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 6.1757e-08 - val_accuracy: 1.0000 - val_loss: 6.7552e-08\n",
      "Epoch 149/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 5.0825e-08 - val_accuracy: 1.0000 - val_loss: 6.7552e-08\n",
      "Epoch 150/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 4.2686e-08 - val_accuracy: 1.0000 - val_loss: 6.7552e-08\n",
      "Epoch 151/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 4.4107e-08 - val_accuracy: 1.0000 - val_loss: 6.7552e-08\n",
      "Epoch 152/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 4.4996e-08 - val_accuracy: 1.0000 - val_loss: 6.7552e-08\n",
      "Epoch 153/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 4.5420e-08 - val_accuracy: 1.0000 - val_loss: 6.3578e-08\n",
      "Epoch 154/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 3.7446e-08 - val_accuracy: 1.0000 - val_loss: 6.3578e-08\n",
      "Epoch 155/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.2501e-08 - val_accuracy: 1.0000 - val_loss: 6.3578e-08\n",
      "Epoch 156/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 3.6547e-08 - val_accuracy: 1.0000 - val_loss: 5.9605e-08\n",
      "Epoch 157/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 3.4809e-08 - val_accuracy: 1.0000 - val_loss: 6.3578e-08\n",
      "Epoch 158/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 3.6173e-08 - val_accuracy: 1.0000 - val_loss: 5.9605e-08\n",
      "Epoch 159/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 3.1815e-08 - val_accuracy: 1.0000 - val_loss: 5.9605e-08\n",
      "Epoch 160/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 3.1913e-08 - val_accuracy: 1.0000 - val_loss: 6.3578e-08\n",
      "Epoch 161/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 2.9307e-08 - val_accuracy: 1.0000 - val_loss: 6.3578e-08\n",
      "Epoch 162/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 2.8369e-08 - val_accuracy: 1.0000 - val_loss: 6.3578e-08\n",
      "Epoch 163/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 2.4027e-08 - val_accuracy: 1.0000 - val_loss: 5.9605e-08\n",
      "Epoch 164/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 2.8727e-08 - val_accuracy: 1.0000 - val_loss: 5.9605e-08\n",
      "Epoch 165/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 2.1484e-08 - val_accuracy: 1.0000 - val_loss: 5.5631e-08\n",
      "Epoch 166/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 2.1445e-08 - val_accuracy: 1.0000 - val_loss: 5.9605e-08\n",
      "Epoch 167/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 2.4010e-08 - val_accuracy: 1.0000 - val_loss: 5.5631e-08\n",
      "Epoch 168/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 2.2437e-08 - val_accuracy: 1.0000 - val_loss: 5.5631e-08\n",
      "Epoch 169/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 2.0451e-08 - val_accuracy: 1.0000 - val_loss: 5.5631e-08\n",
      "Epoch 170/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 2.0557e-08 - val_accuracy: 1.0000 - val_loss: 5.5631e-08\n",
      "Epoch 171/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.9208e-08 - val_accuracy: 1.0000 - val_loss: 5.1657e-08\n",
      "Epoch 172/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.8697e-08 - val_accuracy: 1.0000 - val_loss: 5.1657e-08\n",
      "Epoch 173/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 1.8668e-08 - val_accuracy: 1.0000 - val_loss: 5.1657e-08\n",
      "Epoch 174/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.5745e-08 - val_accuracy: 1.0000 - val_loss: 5.1657e-08\n",
      "Epoch 175/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.6865e-08 - val_accuracy: 1.0000 - val_loss: 5.1657e-08\n",
      "Epoch 176/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 1.5887e-08 - val_accuracy: 1.0000 - val_loss: 5.1657e-08\n",
      "Epoch 177/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.3761e-08 - val_accuracy: 1.0000 - val_loss: 5.1657e-08\n",
      "Epoch 178/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.2659e-08 - val_accuracy: 1.0000 - val_loss: 4.7684e-08\n",
      "Epoch 179/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 1.0665e-08 - val_accuracy: 1.0000 - val_loss: 4.3710e-08\n",
      "Epoch 180/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.2469e-08 - val_accuracy: 1.0000 - val_loss: 4.7684e-08\n",
      "Epoch 181/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 1.0483e-08 - val_accuracy: 1.0000 - val_loss: 4.3710e-08\n",
      "Epoch 182/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.0780e-08 - val_accuracy: 1.0000 - val_loss: 4.3710e-08\n",
      "Epoch 183/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 1.1292e-08 - val_accuracy: 1.0000 - val_loss: 4.3710e-08\n",
      "Epoch 184/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 8.0479e-09 - val_accuracy: 1.0000 - val_loss: 4.3710e-08\n",
      "Epoch 185/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 9.6369e-09 - val_accuracy: 1.0000 - val_loss: 4.3710e-08\n",
      "Epoch 186/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 8.9823e-09 - val_accuracy: 1.0000 - val_loss: 4.3710e-08\n",
      "Epoch 187/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 9.5513e-09 - val_accuracy: 1.0000 - val_loss: 4.3710e-08\n",
      "Epoch 188/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 7.7037e-09 - val_accuracy: 1.0000 - val_loss: 4.3710e-08\n",
      "Epoch 189/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 8.7124e-09 - val_accuracy: 1.0000 - val_loss: 3.9736e-08\n",
      "Epoch 190/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 8.3289e-09 - val_accuracy: 1.0000 - val_loss: 3.9736e-08\n",
      "Epoch 191/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 7.3688e-09 - val_accuracy: 1.0000 - val_loss: 3.9736e-08\n",
      "Epoch 192/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 7.0037e-09 - val_accuracy: 1.0000 - val_loss: 4.3710e-08\n",
      "Epoch 193/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 7.0045e-09 - val_accuracy: 1.0000 - val_loss: 3.5763e-08\n",
      "Epoch 194/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 5.9740e-09 - val_accuracy: 1.0000 - val_loss: 3.5763e-08\n",
      "Epoch 195/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 6.7127e-09 - val_accuracy: 1.0000 - val_loss: 3.5763e-08\n",
      "Epoch 196/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 6.3825e-09 - val_accuracy: 1.0000 - val_loss: 3.5763e-08\n",
      "Epoch 197/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 4.7260e-09 - val_accuracy: 1.0000 - val_loss: 3.5763e-08\n",
      "Epoch 198/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 5.4028e-09 - val_accuracy: 1.0000 - val_loss: 3.5763e-08\n",
      "Epoch 199/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 5.9702e-09 - val_accuracy: 1.0000 - val_loss: 3.5763e-08\n",
      "Epoch 200/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 4.2838e-09 - val_accuracy: 1.0000 - val_loss: 3.5763e-08\n",
      "Epoch 201/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 4.9824e-09 - val_accuracy: 1.0000 - val_loss: 3.5763e-08\n",
      "Epoch 202/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 3.7757e-09 - val_accuracy: 1.0000 - val_loss: 3.5763e-08\n",
      "Epoch 203/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 4.4677e-09 - val_accuracy: 1.0000 - val_loss: 3.1789e-08\n",
      "Epoch 204/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 3.8525e-09 - val_accuracy: 1.0000 - val_loss: 3.1789e-08\n",
      "Epoch 205/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 4.0589e-09 - val_accuracy: 1.0000 - val_loss: 3.1789e-08\n",
      "Epoch 206/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 3.9280e-09 - val_accuracy: 1.0000 - val_loss: 2.7815e-08\n",
      "Epoch 207/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 3.4577e-09 - val_accuracy: 1.0000 - val_loss: 3.1789e-08\n",
      "Epoch 208/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 3.4831e-09 - val_accuracy: 1.0000 - val_loss: 2.7815e-08\n",
      "Epoch 209/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 3.4287e-09 - val_accuracy: 1.0000 - val_loss: 3.1789e-08\n",
      "Epoch 210/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 3.1499e-09 - val_accuracy: 1.0000 - val_loss: 2.7815e-08\n",
      "Epoch 211/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 3.4841e-09 - val_accuracy: 1.0000 - val_loss: 2.7815e-08\n",
      "Epoch 212/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 3.1711e-09 - val_accuracy: 1.0000 - val_loss: 3.1789e-08\n",
      "Epoch 213/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 2.9073e-09 - val_accuracy: 1.0000 - val_loss: 2.7815e-08\n",
      "Epoch 214/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 2.8123e-09 - val_accuracy: 1.0000 - val_loss: 2.7815e-08\n",
      "Epoch 215/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 3.2155e-09 - val_accuracy: 1.0000 - val_loss: 2.7815e-08\n",
      "Epoch 216/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.5179e-09 - val_accuracy: 1.0000 - val_loss: 2.7815e-08\n",
      "Epoch 217/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 2.0655e-09 - val_accuracy: 1.0000 - val_loss: 2.7815e-08\n",
      "Epoch 218/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 2.5549e-09 - val_accuracy: 1.0000 - val_loss: 2.7815e-08\n",
      "Epoch 219/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 2.3491e-09 - val_accuracy: 1.0000 - val_loss: 2.7815e-08\n",
      "Epoch 220/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 2.1205e-09 - val_accuracy: 1.0000 - val_loss: 2.7815e-08\n",
      "Epoch 221/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 2.4724e-09 - val_accuracy: 1.0000 - val_loss: 2.7815e-08\n",
      "Epoch 222/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 2.2009e-09 - val_accuracy: 1.0000 - val_loss: 2.7815e-08\n",
      "Epoch 223/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.7224e-09 - val_accuracy: 1.0000 - val_loss: 2.7815e-08\n",
      "Epoch 224/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.9197e-09 - val_accuracy: 1.0000 - val_loss: 2.7815e-08\n",
      "Epoch 225/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.6752e-09 - val_accuracy: 1.0000 - val_loss: 2.7815e-08\n",
      "Epoch 226/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 1.2170e-09 - val_accuracy: 1.0000 - val_loss: 2.7815e-08\n",
      "Epoch 227/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 1.4323e-09 - val_accuracy: 1.0000 - val_loss: 2.7815e-08\n",
      "Epoch 228/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 1.2011e-09 - val_accuracy: 1.0000 - val_loss: 2.7815e-08\n",
      "Epoch 229/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 1.2688e-09 - val_accuracy: 1.0000 - val_loss: 2.7815e-08\n",
      "Epoch 230/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.3463e-09 - val_accuracy: 1.0000 - val_loss: 2.7815e-08\n",
      "Epoch 231/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 8.7543e-10 - val_accuracy: 1.0000 - val_loss: 2.7815e-08\n",
      "Epoch 232/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.2535e-09 - val_accuracy: 1.0000 - val_loss: 2.7815e-08\n",
      "Epoch 233/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 8.8001e-10 - val_accuracy: 1.0000 - val_loss: 2.7815e-08\n",
      "Epoch 234/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 8.7360e-10 - val_accuracy: 1.0000 - val_loss: 2.7815e-08\n",
      "Epoch 235/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 8.7652e-10 - val_accuracy: 1.0000 - val_loss: 2.3842e-08\n",
      "Epoch 236/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 9.2068e-10 - val_accuracy: 1.0000 - val_loss: 2.7815e-08\n",
      "Epoch 237/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 6.6732e-10 - val_accuracy: 1.0000 - val_loss: 2.3842e-08\n",
      "Epoch 238/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 4.7391e-10 - val_accuracy: 1.0000 - val_loss: 2.7815e-08\n",
      "Epoch 239/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 5.7530e-10 - val_accuracy: 1.0000 - val_loss: 2.3842e-08\n",
      "Epoch 240/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 3.1781e-10 - val_accuracy: 1.0000 - val_loss: 2.3842e-08\n",
      "Epoch 241/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 3.2320e-10 - val_accuracy: 1.0000 - val_loss: 2.3842e-08\n",
      "Epoch 242/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 4.5068e-10 - val_accuracy: 1.0000 - val_loss: 2.3842e-08\n",
      "Epoch 243/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 3.1436e-10 - val_accuracy: 1.0000 - val_loss: 1.9868e-08\n",
      "Epoch 244/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 6.2227e-11 - val_accuracy: 1.0000 - val_loss: 1.9868e-08\n",
      "Epoch 245/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 2.0416e-10 - val_accuracy: 1.0000 - val_loss: 1.9868e-08\n",
      "Epoch 246/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 2.6873e-10 - val_accuracy: 1.0000 - val_loss: 1.9868e-08\n",
      "Epoch 247/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 2.6666e-10 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 248/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 1.2924e-10 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 249/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.1689e-10 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 250/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 1.5215e-10 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 251/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 2.6652e-10 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 252/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.3383e-10 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 253/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 1.4453e-10 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 254/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 4.5138e-11 - val_accuracy: 1.0000 - val_loss: 1.9868e-08\n",
      "Epoch 255/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 5.6193e-11 - val_accuracy: 1.0000 - val_loss: 2.3842e-08\n",
      "Epoch 256/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.2184e-10 - val_accuracy: 1.0000 - val_loss: 2.3842e-08\n",
      "Epoch 257/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.3918e-10 - val_accuracy: 1.0000 - val_loss: 2.3842e-08\n",
      "Epoch 258/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 1.4224e-10 - val_accuracy: 1.0000 - val_loss: 1.9868e-08\n",
      "Epoch 259/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 6.5626e-11 - val_accuracy: 1.0000 - val_loss: 2.7815e-08\n",
      "Epoch 260/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.7704e-10 - val_accuracy: 1.0000 - val_loss: 2.7815e-08\n",
      "Epoch 261/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 2.0310e-10 - val_accuracy: 1.0000 - val_loss: 2.7815e-08\n",
      "Epoch 262/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 5.1641e-11 - val_accuracy: 1.0000 - val_loss: 3.9736e-08\n",
      "Epoch 263/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 2.5422e-10 - val_accuracy: 1.0000 - val_loss: 3.5763e-08\n",
      "Epoch 264/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 3.4858e-10 - val_accuracy: 1.0000 - val_loss: 3.9736e-08\n",
      "Epoch 265/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 4.2241e-10 - val_accuracy: 1.0000 - val_loss: 3.5763e-08\n",
      "Epoch 266/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 1.3782e-10 - val_accuracy: 1.0000 - val_loss: 3.9736e-08\n",
      "Epoch 267/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 6.5132e-10 - val_accuracy: 1.0000 - val_loss: 3.5763e-08\n",
      "Epoch 268/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 4.7167e-10 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 269/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 4.5815e-10 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 270/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 4.2017e-10 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 271/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 8.4304e-10 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 272/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 7.6468e-10 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 273/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 6.0613e-10 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 274/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.9739 - loss: 0.1261 - val_accuracy: 1.0000 - val_loss: 1.5702e-05\n",
      "Epoch 275/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9717 - loss: 0.1232 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 276/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.9941 - loss: 0.0266 - val_accuracy: 1.0000 - val_loss: 1.8159e-06\n",
      "Epoch 277/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9984 - loss: 0.0073 - val_accuracy: 1.0000 - val_loss: 2.1855e-07\n",
      "Epoch 278/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 6.6354e-04 - val_accuracy: 1.0000 - val_loss: 8.3446e-08\n",
      "Epoch 279/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 1.7963e-04 - val_accuracy: 1.0000 - val_loss: 5.1657e-08\n",
      "Epoch 280/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.0814e-04 - val_accuracy: 1.0000 - val_loss: 4.7684e-08\n",
      "Epoch 281/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 9.3927e-05 - val_accuracy: 1.0000 - val_loss: 3.9736e-08\n",
      "Epoch 282/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 8.9833e-05 - val_accuracy: 1.0000 - val_loss: 3.9736e-08\n",
      "Epoch 283/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 8.1736e-05 - val_accuracy: 1.0000 - val_loss: 3.1789e-08\n",
      "Epoch 284/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 6.6240e-05 - val_accuracy: 1.0000 - val_loss: 3.1789e-08\n",
      "Epoch 285/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.6122e-05 - val_accuracy: 1.0000 - val_loss: 2.7815e-08\n",
      "Epoch 286/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 5.1297e-05 - val_accuracy: 1.0000 - val_loss: 2.3842e-08\n",
      "Epoch 287/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 4.1529e-05 - val_accuracy: 1.0000 - val_loss: 2.3842e-08\n",
      "Epoch 288/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 4.0766e-05 - val_accuracy: 1.0000 - val_loss: 2.3842e-08\n",
      "Epoch 289/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 3.3879e-05 - val_accuracy: 1.0000 - val_loss: 2.3842e-08\n",
      "Epoch 290/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 3.4987e-05 - val_accuracy: 1.0000 - val_loss: 2.7815e-08\n",
      "Epoch 291/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 3.0633e-05 - val_accuracy: 1.0000 - val_loss: 1.9868e-08\n",
      "Epoch 292/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 2.5534e-05 - val_accuracy: 1.0000 - val_loss: 1.9868e-08\n",
      "Epoch 293/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 3.4400e-05 - val_accuracy: 1.0000 - val_loss: 1.9868e-08\n",
      "Epoch 294/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 2.5283e-05 - val_accuracy: 1.0000 - val_loss: 1.9868e-08\n",
      "Epoch 295/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 2.1864e-05 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 296/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 2.3269e-05 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 297/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.9679e-05 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 298/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.1648e-05 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 299/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.7539e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 300/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.6741e-05 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Restoring model weights from the end of the best epoch: 271.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\n",
      "Training fold 5\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "2970 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({np.int64(6): 270, np.int64(7): 270, np.int64(4): 270, np.int64(3): 270, np.int64(5): 270, np.int64(8): 270, np.int64(9): 270, np.int64(2): 270, np.int64(10): 270, np.int64(1): 270, np.int64(0): 270})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - accuracy: 0.9351 - loss: 0.3389 - val_accuracy: 1.0000 - val_loss: 0.0109\n",
      "Epoch 2/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9817 - loss: 0.0671 - val_accuracy: 1.0000 - val_loss: 1.7636e-05\n",
      "Epoch 3/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9959 - loss: 0.0113 - val_accuracy: 1.0000 - val_loss: 1.3073e-06\n",
      "Epoch 4/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 5.1921e-04 - val_accuracy: 1.0000 - val_loss: 7.6691e-07\n",
      "Epoch 5/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.7151e-04 - val_accuracy: 1.0000 - val_loss: 5.4439e-07\n",
      "Epoch 6/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.3734e-04 - val_accuracy: 1.0000 - val_loss: 4.2915e-07\n",
      "Epoch 7/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 1.1284e-04 - val_accuracy: 1.0000 - val_loss: 3.5365e-07\n",
      "Epoch 8/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 9.3159e-05 - val_accuracy: 1.0000 - val_loss: 3.0994e-07\n",
      "Epoch 9/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 8.4289e-05 - val_accuracy: 1.0000 - val_loss: 2.7815e-07\n",
      "Epoch 10/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 6.5998e-05 - val_accuracy: 1.0000 - val_loss: 2.4637e-07\n",
      "Epoch 11/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 5.4097e-05 - val_accuracy: 1.0000 - val_loss: 2.1855e-07\n",
      "Epoch 12/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 2.8094e-05 - val_accuracy: 1.0000 - val_loss: 1.7087e-07\n",
      "Epoch 13/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.0275e-05 - val_accuracy: 1.0000 - val_loss: 1.2716e-07\n",
      "Epoch 14/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 3.7895e-06 - val_accuracy: 1.0000 - val_loss: 9.1394e-08\n",
      "Epoch 15/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 2.3969e-06 - val_accuracy: 1.0000 - val_loss: 5.9605e-08\n",
      "Epoch 16/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.9909e-06 - val_accuracy: 1.0000 - val_loss: 4.7684e-08\n",
      "Epoch 17/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 1.9115e-06 - val_accuracy: 1.0000 - val_loss: 1.0729e-07\n",
      "Epoch 18/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 1.0415e-06 - val_accuracy: 1.0000 - val_loss: 5.5631e-08\n",
      "Epoch 19/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 8.3105e-07 - val_accuracy: 1.0000 - val_loss: 5.1657e-08\n",
      "Epoch 20/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 7.0972e-07 - val_accuracy: 1.0000 - val_loss: 3.5763e-08\n",
      "Epoch 21/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 5.7448e-07 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 22/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 5.0553e-07 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 23/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 4.4990e-07 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 24/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 3.8368e-07 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 25/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 3.5017e-07 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 26/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 3.0685e-07 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 27/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 2.8969e-07 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 28/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 2.3718e-07 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 29/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.4376e-07 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 30/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 2.0912e-07 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 31/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 2.0672e-07 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 32/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 1.9608e-07 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 33/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.8017e-07 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 34/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.6225e-07 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 35/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.6419e-07 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 36/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 1.3786e-07 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 37/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.3491e-07 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 38/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.2005e-07 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 39/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 1.1502e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 40/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 1.1500e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 41/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 1.1038e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 42/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.0283e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 43/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 9.5860e-08 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 44/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 9.2906e-08 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 45/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 8.6111e-08 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 46/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 8.4610e-08 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 47/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 8.2858e-08 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 48/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 7.3459e-08 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 49/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 7.2028e-08 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 50/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 6.8103e-08 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 51/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 6.5412e-08 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 52/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 6.4267e-08 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 53/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 6.1312e-08 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 54/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 5.8326e-08 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 55/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 5.5253e-08 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 56/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 5.3241e-08 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 57/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 5.5110e-08 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 58/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.7197e-08 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 59/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 4.7932e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 60/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 4.4812e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 61/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 4.2882e-08 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 62/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 4.2158e-08 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 63/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 3.9510e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 64/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 3.9806e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 65/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 3.6590e-08 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 66/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 3.6729e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 67/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 3.3446e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 68/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 3.3132e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 69/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 3.3139e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 70/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 3.2137e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 71/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 3.2435e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 72/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 3.0476e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 73/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 2.7369e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 74/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 2.7966e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 75/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 2.5097e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 76/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 2.5069e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 77/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 2.4288e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 78/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 2.3085e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 79/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 2.1271e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 80/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 2.1190e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 81/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 2.0180e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 82/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.8754e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 83/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 1.8735e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 84/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 2.0393e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 85/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.9089e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 86/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.7466e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 87/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.6804e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 88/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.6784e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 89/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.5437e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 90/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.6003e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 91/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.5049e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 92/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.3607e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 93/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 1.4601e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 94/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.3309e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 95/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.3309e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 96/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 1.3326e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 97/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 1.1030e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 98/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.3363e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 99/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.1281e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 100/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 1.1560e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 101/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 1.1927e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 102/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.0098e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 103/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.0768e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 104/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.1210e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 105/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 9.4709e-09 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 106/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 9.2838e-09 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 107/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 9.6920e-09 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 108/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 9.9724e-09 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 109/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 9.2774e-09 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 110/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 9.3709e-09 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 110: early stopping\n",
      "Restoring model weights from the end of the best epoch: 80.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\n",
      "Training fold 6\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "2970 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({np.int64(6): 270, np.int64(7): 270, np.int64(4): 270, np.int64(3): 270, np.int64(5): 270, np.int64(8): 270, np.int64(9): 270, np.int64(2): 270, np.int64(10): 270, np.int64(1): 270, np.int64(0): 270})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 0.9234 - loss: 0.3106 - val_accuracy: 1.0000 - val_loss: 0.0629\n",
      "Epoch 2/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 0.9778 - loss: 0.0760 - val_accuracy: 1.0000 - val_loss: 0.0014\n",
      "Epoch 3/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9927 - loss: 0.0177 - val_accuracy: 1.0000 - val_loss: 2.3386e-05\n",
      "Epoch 4/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.9992 - loss: 0.0080 - val_accuracy: 1.0000 - val_loss: 7.2079e-06\n",
      "Epoch 5/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 3.0487e-04 - val_accuracy: 1.0000 - val_loss: 3.7471e-06\n",
      "Epoch 6/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.2720e-04 - val_accuracy: 1.0000 - val_loss: 2.3563e-06\n",
      "Epoch 7/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 9.4380e-05 - val_accuracy: 1.0000 - val_loss: 1.6411e-06\n",
      "Epoch 8/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 6.0526e-05 - val_accuracy: 1.0000 - val_loss: 1.2477e-06\n",
      "Epoch 9/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 4.9888e-05 - val_accuracy: 1.0000 - val_loss: 9.6957e-07\n",
      "Epoch 10/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 4.2815e-05 - val_accuracy: 1.0000 - val_loss: 7.6691e-07\n",
      "Epoch 11/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 3.4820e-05 - val_accuracy: 1.0000 - val_loss: 6.3578e-07\n",
      "Epoch 12/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 3.3635e-05 - val_accuracy: 1.0000 - val_loss: 5.5234e-07\n",
      "Epoch 13/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 2.7075e-05 - val_accuracy: 1.0000 - val_loss: 4.6492e-07\n",
      "Epoch 14/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 2.1351e-05 - val_accuracy: 1.0000 - val_loss: 4.0928e-07\n",
      "Epoch 15/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 2.1415e-05 - val_accuracy: 1.0000 - val_loss: 3.6557e-07\n",
      "Epoch 16/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.9868e-05 - val_accuracy: 1.0000 - val_loss: 3.2584e-07\n",
      "Epoch 17/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.6358e-05 - val_accuracy: 1.0000 - val_loss: 2.8213e-07\n",
      "Epoch 18/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 2.0056e-05 - val_accuracy: 1.0000 - val_loss: 2.6623e-07\n",
      "Epoch 19/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 1.5719e-05 - val_accuracy: 1.0000 - val_loss: 2.3444e-07\n",
      "Epoch 20/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.3757e-05 - val_accuracy: 1.0000 - val_loss: 2.1458e-07\n",
      "Epoch 21/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.1173e-05 - val_accuracy: 1.0000 - val_loss: 2.0663e-07\n",
      "Epoch 22/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.1004e-05 - val_accuracy: 1.0000 - val_loss: 1.8676e-07\n",
      "Epoch 23/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.0573e-05 - val_accuracy: 1.0000 - val_loss: 1.7087e-07\n",
      "Epoch 24/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 9.5321e-06 - val_accuracy: 1.0000 - val_loss: 1.7087e-07\n",
      "Epoch 25/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 1.0012e-05 - val_accuracy: 1.0000 - val_loss: 1.5497e-07\n",
      "Epoch 26/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 8.4900e-06 - val_accuracy: 1.0000 - val_loss: 1.3908e-07\n",
      "Epoch 27/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 7.8016e-06 - val_accuracy: 1.0000 - val_loss: 1.3908e-07\n",
      "Epoch 28/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 6.8784e-06 - val_accuracy: 1.0000 - val_loss: 1.3510e-07\n",
      "Epoch 29/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 6.4332e-06 - val_accuracy: 1.0000 - val_loss: 1.2716e-07\n",
      "Epoch 30/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 6.2730e-06 - val_accuracy: 1.0000 - val_loss: 1.2318e-07\n",
      "Epoch 31/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 5.4458e-06 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 32/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 4.9601e-06 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 33/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 5.1405e-06 - val_accuracy: 1.0000 - val_loss: 1.2318e-07\n",
      "Epoch 34/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 4.7245e-06 - val_accuracy: 1.0000 - val_loss: 1.2716e-07\n",
      "Epoch 35/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 4.2710e-06 - val_accuracy: 1.0000 - val_loss: 1.1126e-07\n",
      "Epoch 36/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 4.0034e-06 - val_accuracy: 1.0000 - val_loss: 1.0729e-07\n",
      "Epoch 37/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 4.2955e-06 - val_accuracy: 1.0000 - val_loss: 1.0729e-07\n",
      "Epoch 38/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 4.1226e-06 - val_accuracy: 1.0000 - val_loss: 1.0331e-07\n",
      "Epoch 39/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 3.2756e-06 - val_accuracy: 1.0000 - val_loss: 9.5367e-08\n",
      "Epoch 40/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 3.3037e-06 - val_accuracy: 1.0000 - val_loss: 8.3446e-08\n",
      "Epoch 41/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 3.2791e-06 - val_accuracy: 1.0000 - val_loss: 8.7420e-08\n",
      "Epoch 42/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 3.0684e-06 - val_accuracy: 1.0000 - val_loss: 8.3446e-08\n",
      "Epoch 43/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 2.9503e-06 - val_accuracy: 1.0000 - val_loss: 7.9473e-08\n",
      "Epoch 44/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 2.5883e-06 - val_accuracy: 1.0000 - val_loss: 7.9473e-08\n",
      "Epoch 45/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 2.5354e-06 - val_accuracy: 1.0000 - val_loss: 7.5499e-08\n",
      "Epoch 46/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 2.1385e-06 - val_accuracy: 1.0000 - val_loss: 7.9473e-08\n",
      "Epoch 47/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.9076e-06 - val_accuracy: 1.0000 - val_loss: 6.7552e-08\n",
      "Epoch 48/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 1.8681e-06 - val_accuracy: 1.0000 - val_loss: 6.3578e-08\n",
      "Epoch 49/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.8532e-06 - val_accuracy: 1.0000 - val_loss: 5.9605e-08\n",
      "Epoch 50/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.8968e-06 - val_accuracy: 1.0000 - val_loss: 5.9605e-08\n",
      "Epoch 51/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 1.4877e-06 - val_accuracy: 1.0000 - val_loss: 5.9605e-08\n",
      "Epoch 52/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.7391e-06 - val_accuracy: 1.0000 - val_loss: 5.5631e-08\n",
      "Epoch 53/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.5357e-06 - val_accuracy: 1.0000 - val_loss: 5.5631e-08\n",
      "Epoch 54/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.2516e-06 - val_accuracy: 1.0000 - val_loss: 5.5631e-08\n",
      "Epoch 55/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.2210e-06 - val_accuracy: 1.0000 - val_loss: 5.1657e-08\n",
      "Epoch 56/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.3363e-06 - val_accuracy: 1.0000 - val_loss: 5.1657e-08\n",
      "Epoch 57/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 1.1831e-06 - val_accuracy: 1.0000 - val_loss: 4.7684e-08\n",
      "Epoch 58/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.1585e-06 - val_accuracy: 1.0000 - val_loss: 4.3710e-08\n",
      "Epoch 59/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.0625e-06 - val_accuracy: 1.0000 - val_loss: 4.3710e-08\n",
      "Epoch 60/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 9.4062e-07 - val_accuracy: 1.0000 - val_loss: 3.9736e-08\n",
      "Epoch 61/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 9.2508e-07 - val_accuracy: 1.0000 - val_loss: 4.3710e-08\n",
      "Epoch 62/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 8.6402e-07 - val_accuracy: 1.0000 - val_loss: 4.3710e-08\n",
      "Epoch 63/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 8.5034e-07 - val_accuracy: 1.0000 - val_loss: 4.3710e-08\n",
      "Epoch 64/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 7.2971e-07 - val_accuracy: 1.0000 - val_loss: 4.3710e-08\n",
      "Epoch 65/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 7.9355e-07 - val_accuracy: 1.0000 - val_loss: 4.7684e-08\n",
      "Epoch 66/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 6.6423e-07 - val_accuracy: 1.0000 - val_loss: 3.9736e-08\n",
      "Epoch 67/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 6.9499e-07 - val_accuracy: 1.0000 - val_loss: 4.7684e-08\n",
      "Epoch 68/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 6.2069e-07 - val_accuracy: 1.0000 - val_loss: 3.9736e-08\n",
      "Epoch 69/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 5.3480e-07 - val_accuracy: 1.0000 - val_loss: 4.3710e-08\n",
      "Epoch 70/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 5.4974e-07 - val_accuracy: 1.0000 - val_loss: 3.9736e-08\n",
      "Epoch 71/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 5.2382e-07 - val_accuracy: 1.0000 - val_loss: 3.9736e-08\n",
      "Epoch 72/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 4.9457e-07 - val_accuracy: 1.0000 - val_loss: 3.5763e-08\n",
      "Epoch 73/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 4.0750e-07 - val_accuracy: 1.0000 - val_loss: 3.5763e-08\n",
      "Epoch 74/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 4.8507e-07 - val_accuracy: 1.0000 - val_loss: 3.5763e-08\n",
      "Epoch 75/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 4.2346e-07 - val_accuracy: 1.0000 - val_loss: 3.5763e-08\n",
      "Epoch 76/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 3.7435e-07 - val_accuracy: 1.0000 - val_loss: 3.5763e-08\n",
      "Epoch 77/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 3.3721e-07 - val_accuracy: 1.0000 - val_loss: 3.5763e-08\n",
      "Epoch 78/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 4.0256e-07 - val_accuracy: 1.0000 - val_loss: 3.1789e-08\n",
      "Epoch 79/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 2.9422e-07 - val_accuracy: 1.0000 - val_loss: 3.1789e-08\n",
      "Epoch 80/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 3.2921e-07 - val_accuracy: 1.0000 - val_loss: 3.1789e-08\n",
      "Epoch 81/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 2.7954e-07 - val_accuracy: 1.0000 - val_loss: 3.1789e-08\n",
      "Epoch 82/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 2.7631e-07 - val_accuracy: 1.0000 - val_loss: 2.7815e-08\n",
      "Epoch 83/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 2.8890e-07 - val_accuracy: 1.0000 - val_loss: 3.1789e-08\n",
      "Epoch 84/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 2.9276e-07 - val_accuracy: 1.0000 - val_loss: 2.3842e-08\n",
      "Epoch 85/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 2.8676e-07 - val_accuracy: 1.0000 - val_loss: 1.9868e-08\n",
      "Epoch 86/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 2.3572e-07 - val_accuracy: 1.0000 - val_loss: 1.9868e-08\n",
      "Epoch 87/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 2.1049e-07 - val_accuracy: 1.0000 - val_loss: 1.9868e-08\n",
      "Epoch 88/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 2.3415e-07 - val_accuracy: 1.0000 - val_loss: 1.9868e-08\n",
      "Epoch 89/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 2.0350e-07 - val_accuracy: 1.0000 - val_loss: 1.9868e-08\n",
      "Epoch 90/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 2.1483e-07 - val_accuracy: 1.0000 - val_loss: 1.9868e-08\n",
      "Epoch 91/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 2.2701e-07 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 92/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 2.0251e-07 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 93/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 1.6497e-07 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 94/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.7547e-07 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 95/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.5787e-07 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 96/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.7800e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 97/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.3532e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 98/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.5142e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 99/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 1.2549e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 100/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 1.4905e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 101/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.3623e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 102/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.1678e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 103/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.1447e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 104/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.2681e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 105/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 9.6794e-08 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 106/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.0435e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 107/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 9.9380e-08 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 108/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 9.2020e-08 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 109/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 9.1051e-08 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 110/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 8.8328e-08 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 111/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 7.0129e-08 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 112/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 7.8843e-08 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 113/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 7.7899e-08 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 114/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 6.9815e-08 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 115/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 7.4146e-08 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 116/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 6.1975e-08 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 117/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 6.1466e-08 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 118/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 6.4558e-08 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 119/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 6.2028e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 120/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 5.4743e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 121/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 5.1536e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 122/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 4.8420e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 123/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 4.7274e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 124/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 5.0908e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 125/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 4.0476e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 126/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 4.0773e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 127/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 3.9300e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 128/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 3.4721e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 129/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 3.6981e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 130/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 3.4864e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 131/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 3.1478e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 132/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 3.1447e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 133/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 2.9958e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 134/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 3.0340e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 135/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 2.8093e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 136/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 2.7150e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 137/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 2.4392e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 138/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 2.3682e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 139/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 2.6856e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 140/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 2.3945e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 141/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 2.1874e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 142/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 2.0143e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 143/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 2.1209e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 144/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 1.9061e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 145/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.9943e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 146/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.8029e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 147/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.7757e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 148/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.7708e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 149/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.5598e-08 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 149: early stopping\n",
      "Restoring model weights from the end of the best epoch: 119.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\n",
      "Training fold 7\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "2970 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({np.int64(6): 270, np.int64(7): 270, np.int64(4): 270, np.int64(3): 270, np.int64(5): 270, np.int64(8): 270, np.int64(9): 270, np.int64(2): 270, np.int64(10): 270, np.int64(1): 270, np.int64(0): 270})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.9402 - loss: 0.2169 - val_accuracy: 1.0000 - val_loss: 7.6172e-06\n",
      "Epoch 2/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 0.9876 - loss: 0.0547 - val_accuracy: 1.0000 - val_loss: 4.8809e-05\n",
      "Epoch 3/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9974 - loss: 0.0166 - val_accuracy: 1.0000 - val_loss: 1.9550e-06\n",
      "Epoch 4/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 9.7778e-05\n",
      "Epoch 5/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 2.0478e-04 - val_accuracy: 1.0000 - val_loss: 1.9863e-05\n",
      "Epoch 6/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.4453e-04 - val_accuracy: 1.0000 - val_loss: 9.2663e-06\n",
      "Epoch 7/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 1.0251e-04 - val_accuracy: 1.0000 - val_loss: 5.9762e-06\n",
      "Epoch 8/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.0035e-04 - val_accuracy: 1.0000 - val_loss: 4.3312e-06\n",
      "Epoch 9/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 6.8373e-05 - val_accuracy: 1.0000 - val_loss: 3.1670e-06\n",
      "Epoch 10/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 6.3736e-05 - val_accuracy: 1.0000 - val_loss: 2.5391e-06\n",
      "Epoch 11/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 4.6969e-05 - val_accuracy: 1.0000 - val_loss: 2.0742e-06\n",
      "Epoch 12/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.1601e-05 - val_accuracy: 1.0000 - val_loss: 1.7404e-06\n",
      "Epoch 13/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.1874e-05 - val_accuracy: 1.0000 - val_loss: 1.5060e-06\n",
      "Epoch 14/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 3.6964e-05 - val_accuracy: 1.0000 - val_loss: 1.3113e-06\n",
      "Epoch 15/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 3.6208e-05 - val_accuracy: 1.0000 - val_loss: 1.1404e-06\n",
      "Epoch 16/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 3.1014e-05 - val_accuracy: 1.0000 - val_loss: 9.7354e-07\n",
      "Epoch 17/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 3.2148e-05 - val_accuracy: 1.0000 - val_loss: 8.4638e-07\n",
      "Epoch 18/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 2.6484e-05 - val_accuracy: 1.0000 - val_loss: 7.7089e-07\n",
      "Epoch 19/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 2.5853e-05 - val_accuracy: 1.0000 - val_loss: 6.7949e-07\n",
      "Epoch 20/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 2.4499e-05 - val_accuracy: 1.0000 - val_loss: 6.1989e-07\n",
      "Epoch 21/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 2.1565e-05 - val_accuracy: 1.0000 - val_loss: 5.6426e-07\n",
      "Epoch 22/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 2.0460e-05 - val_accuracy: 1.0000 - val_loss: 5.1657e-07\n",
      "Epoch 23/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.8745e-05 - val_accuracy: 1.0000 - val_loss: 4.7684e-07\n",
      "Epoch 24/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.5219e-05 - val_accuracy: 1.0000 - val_loss: 4.4505e-07\n",
      "Epoch 25/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.4989e-05 - val_accuracy: 1.0000 - val_loss: 4.0531e-07\n",
      "Epoch 26/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.3222e-05 - val_accuracy: 1.0000 - val_loss: 3.7750e-07\n",
      "Epoch 27/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.3265e-05 - val_accuracy: 1.0000 - val_loss: 3.5365e-07\n",
      "Epoch 28/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.3497e-05 - val_accuracy: 1.0000 - val_loss: 3.2981e-07\n",
      "Epoch 29/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 1.2088e-05 - val_accuracy: 1.0000 - val_loss: 3.1392e-07\n",
      "Epoch 30/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 1.2012e-05 - val_accuracy: 1.0000 - val_loss: 2.9008e-07\n",
      "Epoch 31/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 1.1739e-05 - val_accuracy: 1.0000 - val_loss: 2.7418e-07\n",
      "Epoch 32/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.0466e-05 - val_accuracy: 1.0000 - val_loss: 2.6226e-07\n",
      "Epoch 33/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.0040e-05 - val_accuracy: 1.0000 - val_loss: 2.4239e-07\n",
      "Epoch 34/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 9.2261e-06 - val_accuracy: 1.0000 - val_loss: 2.3047e-07\n",
      "Epoch 35/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 8.5125e-06 - val_accuracy: 1.0000 - val_loss: 2.1855e-07\n",
      "Epoch 36/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 7.3004e-06 - val_accuracy: 1.0000 - val_loss: 2.1458e-07\n",
      "Epoch 37/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 7.4825e-06 - val_accuracy: 1.0000 - val_loss: 1.9471e-07\n",
      "Epoch 38/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 7.5131e-06 - val_accuracy: 1.0000 - val_loss: 1.9073e-07\n",
      "Epoch 39/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 7.4459e-06 - val_accuracy: 1.0000 - val_loss: 1.6689e-07\n",
      "Epoch 40/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 7.3420e-06 - val_accuracy: 1.0000 - val_loss: 1.6292e-07\n",
      "Epoch 41/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 6.7782e-06 - val_accuracy: 1.0000 - val_loss: 1.5100e-07\n",
      "Epoch 42/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 5.6449e-06 - val_accuracy: 1.0000 - val_loss: 1.3908e-07\n",
      "Epoch 43/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 6.4541e-06 - val_accuracy: 1.0000 - val_loss: 1.2716e-07\n",
      "Epoch 44/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 4.9303e-06 - val_accuracy: 1.0000 - val_loss: 1.2318e-07\n",
      "Epoch 45/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 6.4479e-06 - val_accuracy: 1.0000 - val_loss: 1.1524e-07\n",
      "Epoch 46/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 4.6291e-06 - val_accuracy: 1.0000 - val_loss: 1.1126e-07\n",
      "Epoch 47/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 4.1495e-06 - val_accuracy: 1.0000 - val_loss: 1.0729e-07\n",
      "Epoch 48/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 4.1382e-06 - val_accuracy: 1.0000 - val_loss: 9.9341e-08\n",
      "Epoch 49/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 3.9252e-06 - val_accuracy: 1.0000 - val_loss: 9.9341e-08\n",
      "Epoch 50/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 4.1354e-06 - val_accuracy: 1.0000 - val_loss: 8.7420e-08\n",
      "Epoch 51/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 4.0645e-06 - val_accuracy: 1.0000 - val_loss: 8.7420e-08\n",
      "Epoch 52/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 4.3466e-06 - val_accuracy: 1.0000 - val_loss: 7.9473e-08\n",
      "Epoch 53/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 3.8403e-06 - val_accuracy: 1.0000 - val_loss: 7.5499e-08\n",
      "Epoch 54/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 3.3955e-06 - val_accuracy: 1.0000 - val_loss: 7.1526e-08\n",
      "Epoch 55/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 3.6387e-06 - val_accuracy: 1.0000 - val_loss: 7.1526e-08\n",
      "Epoch 56/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 3.0895e-06 - val_accuracy: 1.0000 - val_loss: 6.3578e-08\n",
      "Epoch 57/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 2.8660e-06 - val_accuracy: 1.0000 - val_loss: 5.9605e-08\n",
      "Epoch 58/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 2.7615e-06 - val_accuracy: 1.0000 - val_loss: 5.9605e-08\n",
      "Epoch 59/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 2.5812e-06 - val_accuracy: 1.0000 - val_loss: 5.1657e-08\n",
      "Epoch 60/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 2.7724e-06 - val_accuracy: 1.0000 - val_loss: 5.1657e-08\n",
      "Epoch 61/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 2.3799e-06 - val_accuracy: 1.0000 - val_loss: 4.3710e-08\n",
      "Epoch 62/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 2.1735e-06 - val_accuracy: 1.0000 - val_loss: 3.5763e-08\n",
      "Epoch 63/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 2.0134e-06 - val_accuracy: 1.0000 - val_loss: 3.5763e-08\n",
      "Epoch 64/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 2.1536e-06 - val_accuracy: 1.0000 - val_loss: 3.5763e-08\n",
      "Epoch 65/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 1.6799e-06 - val_accuracy: 1.0000 - val_loss: 3.1789e-08\n",
      "Epoch 66/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.7465e-06 - val_accuracy: 1.0000 - val_loss: 3.1789e-08\n",
      "Epoch 67/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.6916e-06 - val_accuracy: 1.0000 - val_loss: 2.7815e-08\n",
      "Epoch 68/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 1.6161e-06 - val_accuracy: 1.0000 - val_loss: 2.7815e-08\n",
      "Epoch 69/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 1.7983e-06 - val_accuracy: 1.0000 - val_loss: 2.7815e-08\n",
      "Epoch 70/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 1.3566e-06 - val_accuracy: 1.0000 - val_loss: 2.7815e-08\n",
      "Epoch 71/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.4610e-06 - val_accuracy: 1.0000 - val_loss: 2.7815e-08\n",
      "Epoch 72/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.4856e-06 - val_accuracy: 1.0000 - val_loss: 2.7815e-08\n",
      "Epoch 73/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.3317e-06 - val_accuracy: 1.0000 - val_loss: 2.3842e-08\n",
      "Epoch 74/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.2733e-06 - val_accuracy: 1.0000 - val_loss: 2.3842e-08\n",
      "Epoch 75/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.2071e-06 - val_accuracy: 1.0000 - val_loss: 2.3842e-08\n",
      "Epoch 76/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.1392e-06 - val_accuracy: 1.0000 - val_loss: 1.9868e-08\n",
      "Epoch 77/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 1.1400e-06 - val_accuracy: 1.0000 - val_loss: 1.9868e-08\n",
      "Epoch 78/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.1424e-06 - val_accuracy: 1.0000 - val_loss: 1.9868e-08\n",
      "Epoch 79/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 9.8550e-07 - val_accuracy: 1.0000 - val_loss: 1.9868e-08\n",
      "Epoch 80/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.0346e-06 - val_accuracy: 1.0000 - val_loss: 1.9868e-08\n",
      "Epoch 81/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 7.2560e-07 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 82/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 8.5653e-07 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 83/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 7.9924e-07 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 84/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 8.3144e-07 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 85/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 7.7266e-07 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 86/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 7.0820e-07 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 87/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 6.9568e-07 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 88/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 5.7936e-07 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 89/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 6.0924e-07 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 90/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 5.6084e-07 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 91/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 4.8274e-07 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 92/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 4.6151e-07 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 93/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 5.1151e-07 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 94/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 4.7257e-07 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 95/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 4.3982e-07 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 96/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 4.5118e-07 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 97/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 3.8361e-07 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 98/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 3.7990e-07 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 99/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 3.9984e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 100/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 3.6153e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 101/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 3.5218e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 102/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 2.9419e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 103/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 2.6859e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 104/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 2.6993e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 105/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 2.7843e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 106/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 2.4187e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 107/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 2.4692e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 108/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 2.2105e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 109/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 2.2990e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 110/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 2.0209e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 111/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.9003e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 112/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.9685e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 113/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.8452e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 114/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.7571e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 115/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 1.7792e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 116/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.6319e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 117/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 1.3802e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 118/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.4652e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 119/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.2482e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 120/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.3666e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 121/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.1964e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 122/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.1704e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 123/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.0431e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 124/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.1597e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 125/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 1.0107e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 126/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 9.5488e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 127/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 8.2633e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 128/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 8.5510e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 129/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 7.8971e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 129: early stopping\n",
      "Restoring model weights from the end of the best epoch: 99.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\n",
      "Training fold 8\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "2970 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({np.int64(6): 270, np.int64(7): 270, np.int64(4): 270, np.int64(3): 270, np.int64(5): 270, np.int64(8): 270, np.int64(9): 270, np.int64(2): 270, np.int64(10): 270, np.int64(1): 270, np.int64(0): 270})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 0.9558 - loss: 0.2030 - val_accuracy: 1.0000 - val_loss: 6.2170e-05\n",
      "Epoch 2/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9885 - loss: 0.0321 - val_accuracy: 1.0000 - val_loss: 6.2817e-04\n",
      "Epoch 3/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 0.9971 - loss: 0.0086 - val_accuracy: 1.0000 - val_loss: 1.2898e-05\n",
      "Epoch 4/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.9988 - loss: 0.0075 - val_accuracy: 1.0000 - val_loss: 3.0358e-06\n",
      "Epoch 5/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.9943e-04 - val_accuracy: 1.0000 - val_loss: 8.3446e-07\n",
      "Epoch 6/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 7.0218e-05 - val_accuracy: 1.0000 - val_loss: 4.6889e-07\n",
      "Epoch 7/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 4.4435e-05 - val_accuracy: 1.0000 - val_loss: 3.0200e-07\n",
      "Epoch 8/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 3.5046e-05 - val_accuracy: 1.0000 - val_loss: 2.2650e-07\n",
      "Epoch 9/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 3.0163e-05 - val_accuracy: 1.0000 - val_loss: 1.7087e-07\n",
      "Epoch 10/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 2.5340e-05 - val_accuracy: 1.0000 - val_loss: 1.3908e-07\n",
      "Epoch 11/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 2.3625e-05 - val_accuracy: 1.0000 - val_loss: 1.1524e-07\n",
      "Epoch 12/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.7062e-05 - val_accuracy: 1.0000 - val_loss: 9.5367e-08\n",
      "Epoch 13/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.5727e-05 - val_accuracy: 1.0000 - val_loss: 7.5499e-08\n",
      "Epoch 14/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.5384e-05 - val_accuracy: 1.0000 - val_loss: 5.9605e-08\n",
      "Epoch 15/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.4299e-05 - val_accuracy: 1.0000 - val_loss: 5.5631e-08\n",
      "Epoch 16/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.3159e-05 - val_accuracy: 1.0000 - val_loss: 4.7684e-08\n",
      "Epoch 17/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 1.1883e-05 - val_accuracy: 1.0000 - val_loss: 4.3710e-08\n",
      "Epoch 18/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.0227e-05 - val_accuracy: 1.0000 - val_loss: 4.3710e-08\n",
      "Epoch 19/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 8.5322e-06 - val_accuracy: 1.0000 - val_loss: 3.9736e-08\n",
      "Epoch 20/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 9.9302e-06 - val_accuracy: 1.0000 - val_loss: 3.5763e-08\n",
      "Epoch 21/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 8.4930e-06 - val_accuracy: 1.0000 - val_loss: 3.5763e-08\n",
      "Epoch 22/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 7.0399e-06 - val_accuracy: 1.0000 - val_loss: 3.5763e-08\n",
      "Epoch 23/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 6.9294e-06 - val_accuracy: 1.0000 - val_loss: 3.1789e-08\n",
      "Epoch 24/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 6.3987e-06 - val_accuracy: 1.0000 - val_loss: 3.1789e-08\n",
      "Epoch 25/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 7.0537e-06 - val_accuracy: 1.0000 - val_loss: 3.1789e-08\n",
      "Epoch 26/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 5.1380e-06 - val_accuracy: 1.0000 - val_loss: 3.1789e-08\n",
      "Epoch 27/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 5.6203e-06 - val_accuracy: 1.0000 - val_loss: 3.1789e-08\n",
      "Epoch 28/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 5.9294e-06 - val_accuracy: 1.0000 - val_loss: 2.3842e-08\n",
      "Epoch 29/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 4.8745e-06 - val_accuracy: 1.0000 - val_loss: 2.3842e-08\n",
      "Epoch 30/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 4.5297e-06 - val_accuracy: 1.0000 - val_loss: 2.3842e-08\n",
      "Epoch 31/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 4.1137e-06 - val_accuracy: 1.0000 - val_loss: 2.3842e-08\n",
      "Epoch 32/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 4.1557e-06 - val_accuracy: 1.0000 - val_loss: 2.3842e-08\n",
      "Epoch 33/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 3.4955e-06 - val_accuracy: 1.0000 - val_loss: 1.9868e-08\n",
      "Epoch 34/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 3.3605e-06 - val_accuracy: 1.0000 - val_loss: 1.9868e-08\n",
      "Epoch 35/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 3.4694e-06 - val_accuracy: 1.0000 - val_loss: 1.9868e-08\n",
      "Epoch 36/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 3.1419e-06 - val_accuracy: 1.0000 - val_loss: 1.9868e-08\n",
      "Epoch 37/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 2.3683e-06 - val_accuracy: 1.0000 - val_loss: 1.9868e-08\n",
      "Epoch 38/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 2.4171e-06 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 39/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 2.3087e-06 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 40/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 2.4967e-06 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 41/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 2.0721e-06 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 42/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 2.1053e-06 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 43/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.8640e-06 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 44/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.8237e-06 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 45/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.6530e-06 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 46/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.6660e-06 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 47/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.4206e-06 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 48/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.5529e-06 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 49/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.1680e-06 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 50/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.5059e-06 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 51/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.4056e-06 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 52/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.2611e-06 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 53/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 1.0464e-06 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 54/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 1.0288e-06 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 55/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 9.7170e-07 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 56/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.0054e-06 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 57/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 9.1507e-07 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 58/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 7.7482e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 59/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 8.7239e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 60/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 7.1029e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 61/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 8.1333e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 62/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 6.9677e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 63/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 6.6086e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 64/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 6.5318e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 65/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 7.2001e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 66/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 5.6118e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 67/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 6.0811e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 68/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 6.7826e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 69/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 5.3578e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 70/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 5.3718e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 71/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 4.5609e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 72/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 4.8823e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 73/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 4.8740e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 74/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 4.1918e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 75/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 4.4025e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 76/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 4.3176e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 77/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 4.1319e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 78/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 3.5464e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 79/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 3.5407e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 80/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 3.5886e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 81/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 3.0893e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 82/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 2.9181e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 83/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 2.9538e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 84/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 2.7718e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 85/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 2.7094e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 86/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 2.5873e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 87/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.6330e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 88/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 2.4230e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 88: early stopping\n",
      "Restoring model weights from the end of the best epoch: 58.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\n",
      "Training fold 9\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "2970 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({np.int64(6): 270, np.int64(7): 270, np.int64(4): 270, np.int64(3): 270, np.int64(5): 270, np.int64(8): 270, np.int64(9): 270, np.int64(2): 270, np.int64(10): 270, np.int64(1): 270, np.int64(0): 270})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9546 - loss: 0.1713 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 2/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9872 - loss: 0.0533 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 3/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - accuracy: 0.9880 - loss: 0.0338 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 4/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9980 - loss: 0.0067 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 5/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.9980 - loss: 0.0107 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 6/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 2.1783e-04 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 7/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.2841e-04 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 8/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 9.7903e-05 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 9/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 6.8271e-05 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 10/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 6.6409e-05 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 11/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 5.0715e-05 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 12/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 4.8299e-05 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 13/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 4.4384e-05 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 14/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 3.9726e-05 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 15/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 3.4641e-05 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 16/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 2.8324e-05 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 17/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 2.7608e-05 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 18/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 2.7223e-05 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 19/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 2.7251e-05 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 20/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 2.2852e-05 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 21/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 1.8732e-05 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 22/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.8789e-05 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 23/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.7252e-05 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 24/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.6666e-05 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 25/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.6581e-05 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 26/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.5172e-05 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 27/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 1.4621e-05 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 28/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 1.3304e-05 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 29/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 1.4601e-05 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 30/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.2351e-05 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 31/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.1381e-05 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\n",
      "Training fold 10\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "2970 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({np.int64(6): 270, np.int64(7): 270, np.int64(4): 270, np.int64(3): 270, np.int64(5): 270, np.int64(8): 270, np.int64(9): 270, np.int64(2): 270, np.int64(10): 270, np.int64(1): 270, np.int64(0): 270})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9724 - loss: 0.1113 - val_accuracy: 1.0000 - val_loss: 4.3785e-05\n",
      "Epoch 2/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9825 - loss: 0.0483 - val_accuracy: 1.0000 - val_loss: 6.9623e-05\n",
      "Epoch 3/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 0.9959 - loss: 0.0139 - val_accuracy: 1.0000 - val_loss: 2.2567e-05\n",
      "Epoch 4/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9959 - loss: 0.0294 - val_accuracy: 1.0000 - val_loss: 5.7140e-06\n",
      "Epoch 5/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.9976 - loss: 0.0049 - val_accuracy: 1.0000 - val_loss: 3.5365e-07\n",
      "Epoch 6/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 3.2936e-04 - val_accuracy: 1.0000 - val_loss: 3.5763e-07\n",
      "Epoch 7/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 1.0156e-04 - val_accuracy: 1.0000 - val_loss: 2.9008e-07\n",
      "Epoch 8/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 6.3553e-05 - val_accuracy: 1.0000 - val_loss: 2.3444e-07\n",
      "Epoch 9/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 5.9709e-05 - val_accuracy: 1.0000 - val_loss: 2.0663e-07\n",
      "Epoch 10/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 4.7207e-05 - val_accuracy: 1.0000 - val_loss: 1.8676e-07\n",
      "Epoch 11/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 4.3821e-05 - val_accuracy: 1.0000 - val_loss: 1.6292e-07\n",
      "Epoch 12/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 3.9569e-05 - val_accuracy: 1.0000 - val_loss: 1.5100e-07\n",
      "Epoch 13/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 3.2447e-05 - val_accuracy: 1.0000 - val_loss: 1.4305e-07\n",
      "Epoch 14/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 3.4607e-05 - val_accuracy: 1.0000 - val_loss: 1.2716e-07\n",
      "Epoch 15/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 2.4522e-05 - val_accuracy: 1.0000 - val_loss: 1.0729e-07\n",
      "Epoch 16/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 2.2060e-05 - val_accuracy: 1.0000 - val_loss: 9.5367e-08\n",
      "Epoch 17/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 2.5356e-05 - val_accuracy: 1.0000 - val_loss: 8.7420e-08\n",
      "Epoch 18/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 2.5205e-05 - val_accuracy: 1.0000 - val_loss: 8.7420e-08\n",
      "Epoch 19/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.7997e-05 - val_accuracy: 1.0000 - val_loss: 7.1526e-08\n",
      "Epoch 20/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 2.1451e-05 - val_accuracy: 1.0000 - val_loss: 6.7552e-08\n",
      "Epoch 21/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.7022e-05 - val_accuracy: 1.0000 - val_loss: 5.9605e-08\n",
      "Epoch 22/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.5531e-05 - val_accuracy: 1.0000 - val_loss: 5.9605e-08\n",
      "Epoch 23/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.5084e-05 - val_accuracy: 1.0000 - val_loss: 5.5631e-08\n",
      "Epoch 24/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 1.2595e-05 - val_accuracy: 1.0000 - val_loss: 5.1657e-08\n",
      "Epoch 25/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 1.3249e-05 - val_accuracy: 1.0000 - val_loss: 5.1657e-08\n",
      "Epoch 26/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.1526e-05 - val_accuracy: 1.0000 - val_loss: 5.1657e-08\n",
      "Epoch 27/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 1.1692e-05 - val_accuracy: 1.0000 - val_loss: 4.3710e-08\n",
      "Epoch 28/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.2040e-05 - val_accuracy: 1.0000 - val_loss: 4.3710e-08\n",
      "Epoch 29/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 9.3358e-06 - val_accuracy: 1.0000 - val_loss: 3.9736e-08\n",
      "Epoch 30/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 9.9073e-06 - val_accuracy: 1.0000 - val_loss: 3.9736e-08\n",
      "Epoch 31/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 9.5604e-06 - val_accuracy: 1.0000 - val_loss: 3.9736e-08\n",
      "Epoch 32/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 8.6294e-06 - val_accuracy: 1.0000 - val_loss: 3.1789e-08\n",
      "Epoch 33/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 7.6372e-06 - val_accuracy: 1.0000 - val_loss: 3.1789e-08\n",
      "Epoch 34/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 7.4604e-06 - val_accuracy: 1.0000 - val_loss: 3.1789e-08\n",
      "Epoch 35/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 7.4708e-06 - val_accuracy: 1.0000 - val_loss: 3.1789e-08\n",
      "Epoch 36/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 7.5962e-06 - val_accuracy: 1.0000 - val_loss: 3.1789e-08\n",
      "Epoch 37/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 7.0629e-06 - val_accuracy: 1.0000 - val_loss: 2.7815e-08\n",
      "Epoch 38/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 6.0251e-06 - val_accuracy: 1.0000 - val_loss: 2.7815e-08\n",
      "Epoch 39/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 5.3867e-06 - val_accuracy: 1.0000 - val_loss: 2.7815e-08\n",
      "Epoch 40/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 5.5239e-06 - val_accuracy: 1.0000 - val_loss: 2.3842e-08\n",
      "Epoch 41/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 5.5174e-06 - val_accuracy: 1.0000 - val_loss: 2.3842e-08\n",
      "Epoch 42/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 5.0127e-06 - val_accuracy: 1.0000 - val_loss: 2.3842e-08\n",
      "Epoch 43/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 4.7246e-06 - val_accuracy: 1.0000 - val_loss: 2.3842e-08\n",
      "Epoch 44/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 5.3789e-06 - val_accuracy: 1.0000 - val_loss: 2.3842e-08\n",
      "Epoch 45/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 4.3840e-06 - val_accuracy: 1.0000 - val_loss: 2.3842e-08\n",
      "Epoch 46/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 4.4315e-06 - val_accuracy: 1.0000 - val_loss: 2.3842e-08\n",
      "Epoch 47/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 3.9249e-06 - val_accuracy: 1.0000 - val_loss: 2.3842e-08\n",
      "Epoch 48/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 3.7548e-06 - val_accuracy: 1.0000 - val_loss: 2.3842e-08\n",
      "Epoch 49/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 3.6360e-06 - val_accuracy: 1.0000 - val_loss: 2.3842e-08\n",
      "Epoch 50/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 3.4346e-06 - val_accuracy: 1.0000 - val_loss: 2.3842e-08\n",
      "Epoch 51/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 3.2256e-06 - val_accuracy: 1.0000 - val_loss: 1.9868e-08\n",
      "Epoch 52/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 3.0178e-06 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 53/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 2.9337e-06 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 54/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 2.6293e-06 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 55/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 2.5644e-06 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 56/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 2.4224e-06 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 57/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 2.6198e-06 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 58/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 2.3040e-06 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 59/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 2.4669e-06 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 60/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 2.1375e-06 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 61/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 2.2435e-06 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 62/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.7782e-06 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 63/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 2.0448e-06 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 64/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.8757e-06 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 65/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.9280e-06 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 66/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.6517e-06 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 67/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.5940e-06 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 68/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.4733e-06 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 69/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.4370e-06 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 70/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.4164e-06 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 71/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.2571e-06 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 72/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.2578e-06 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 73/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.1247e-06 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 74/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.1423e-06 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 75/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 1.0805e-06 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 76/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.0668e-06 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 77/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 9.6180e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 78/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 8.0586e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 79/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 9.2391e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 80/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 7.3797e-07 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 81/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 8.8823e-07 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 82/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 7.2738e-07 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 83/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 7.3459e-07 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 84/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 7.0866e-07 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 85/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 6.4162e-07 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 86/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 6.3011e-07 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 87/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 6.0223e-07 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 88/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 6.4130e-07 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 89/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 5.2001e-07 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 90/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 5.2514e-07 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 91/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 5.2197e-07 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 92/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 5.0871e-07 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 93/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 4.4266e-07 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 94/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 4.1323e-07 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 95/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 3.7946e-07 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 96/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 4.1256e-07 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 97/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 3.9185e-07 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 98/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 3.3093e-07 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 99/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 3.5232e-07 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 100/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 3.0328e-07 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 101/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 2.7975e-07 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 102/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 3.1987e-07 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 103/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 2.4812e-07 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 104/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 2.6527e-07 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 105/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 2.7547e-07 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 106/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 2.3605e-07 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 107/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 2.1274e-07 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 108/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 2.1619e-07 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 109/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.7796e-07 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 110/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.9269e-07 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 111/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.8788e-07 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 112/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.5941e-07 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 113/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.6076e-07 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 114/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.7825e-07 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 115/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.6885e-07 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 116/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 1.3677e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 117/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 1.3551e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 118/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 1.2428e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 119/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.3240e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 120/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.0659e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 121/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 1.2059e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 122/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.0651e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 123/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 9.0883e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 124/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 9.9830e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 125/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 9.1421e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 126/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 8.5560e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 127/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 8.4306e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 128/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 8.3878e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 129/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 6.7199e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 130/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 6.6134e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 131/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 6.3684e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 132/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 6.4660e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 133/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 5.9138e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 134/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 6.6806e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 135/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 5.2627e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 136/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 4.7856e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 137/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 4.5347e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 138/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 4.5422e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 139/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 4.1737e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 140/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 4.4048e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 141/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 3.8107e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 142/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 3.5566e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 143/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 3.9106e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 144/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 3.2668e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 145/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 3.6216e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 146/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 2.8868e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 146: early stopping\n",
      "Restoring model weights from the end of the best epoch: 116.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "Time taken for training:  01:34:43\n",
      "\n",
      "\n",
      "Fold 1 - Train Accuracy 1.0000 - Test Accuracy 0.2250\n",
      "Fold 2 - Train Accuracy 1.0000 - Test Accuracy 0.4083\n",
      "Fold 3 - Train Accuracy 1.0000 - Test Accuracy 0.7417\n",
      "Fold 4 - Train Accuracy 1.0000 - Test Accuracy 0.7333\n",
      "Fold 5 - Train Accuracy 1.0000 - Test Accuracy 0.8333\n",
      "Fold 6 - Train Accuracy 1.0000 - Test Accuracy 0.8750\n",
      "Fold 7 - Train Accuracy 1.0000 - Test Accuracy 0.9250\n",
      "Fold 8 - Train Accuracy 1.0000 - Test Accuracy 0.9583\n",
      "Fold 9 - Train Accuracy 0.9906 - Test Accuracy 0.9917\n",
      "Fold 10 - Train Accuracy 1.0000 - Test Accuracy 0.9917\n",
      "\n",
      "Mean Train Accuracy: 0.9991 \n",
      "Mean Test Accuracy: 0.7683 \n",
      "\n",
      "Evaluate other metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.86      0.80       300\n",
      "           1       0.90      0.76      0.83        50\n",
      "           2       0.87      0.70      0.78        57\n",
      "           3       0.77      0.70      0.74       145\n",
      "           4       0.75      0.73      0.74       132\n",
      "           5       0.73      0.80      0.76       191\n",
      "           6       0.77      0.75      0.76       150\n",
      "           7       0.86      0.70      0.77        79\n",
      "           8       0.76      0.72      0.74        61\n",
      "           9       1.00      0.68      0.81        25\n",
      "          10       1.00      0.60      0.75        10\n",
      "\n",
      "    accuracy                           0.77      1200\n",
      "   macro avg       0.83      0.73      0.77      1200\n",
      "weighted avg       0.78      0.77      0.77      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def create_v1():\n",
    "    act_function = \"relu\"\n",
    "    kernel_init = \"he_uniform\"\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(number_of_steps, number_of_features)))\n",
    "    model.add(Conv1D(filters = 64, kernel_size = 3, activation = act_function,\n",
    "                     kernel_initializer = kernel_init))\n",
    "    model.add(Conv1D(filters = 32, kernel_size = 3, activation = act_function,\n",
    "                     kernel_initializer = kernel_init))\n",
    "    model.add(Conv1D(filters = 16, kernel_size = 3, activation = act_function,\n",
    "                     kernel_initializer = kernel_init))\n",
    "    model.add(MaxPooling1D(pool_size = 2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(32, activation = act_function, kernel_initializer = kernel_init))\n",
    "    model.add(Dense(32, activation = act_function, kernel_initializer = kernel_init))\n",
    "    model.add(Dense(32, activation = act_function, kernel_initializer = kernel_init))\n",
    "    model.add(Dense(11, activation = 'softmax'))\n",
    "    opt = AdamW(learning_rate = 0.001)\n",
    "    model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = opt, metrics = [\"accuracy\"])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "X_list, y_list = build_time_window_structure(df)\n",
    "X_arr = np.array(X_list)\n",
    "y_arr = np.array(y_list)\n",
    "\n",
    "model = create_v1()\n",
    "history_by_fold = train_cnn_model(model, X_arr, y_arr, apply_smote = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67529328",
   "metadata": {},
   "source": [
    "#### Train a Convolutional Neural Network model and evaluate the metrics.\n",
    "- Layer architecture => Conv1D (64) + Conv1D (32) + Conv1D (16) + MaxPooling1D + Dense (128) + Dense (11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a180bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting build_time_window_structure function...\n",
      "Quantity of samples (features) =>  1200\n",
      "Quantity os samples (labels) =>  1200\n",
      "Finishing build_time_window_structure function.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1278</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1276</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,176</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1274</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,552</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">637</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10192</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,304,704</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,419</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1278\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │         \u001b[38;5;34m6,208\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1276\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │         \u001b[38;5;34m6,176\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1274\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │         \u001b[38;5;34m1,552\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m637\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10192\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │     \u001b[38;5;34m1,304,704\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m)             │         \u001b[38;5;34m1,419\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,320,059</span> (5.04 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,320,059\u001b[0m (5.04 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,320,059</span> (5.04 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,320,059\u001b[0m (5.04 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training...\n",
      "\n",
      "Training fold 1\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "2970 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({np.int64(6): 270, np.int64(7): 270, np.int64(4): 270, np.int64(3): 270, np.int64(5): 270, np.int64(8): 270, np.int64(9): 270, np.int64(2): 270, np.int64(10): 270, np.int64(1): 270, np.int64(0): 270})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 37ms/step - accuracy: 0.2166 - loss: 3.2210 - val_accuracy: 1.0000 - val_loss: 0.0499\n",
      "Epoch 2/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.7348 - loss: 0.8651 - val_accuracy: 1.0000 - val_loss: 0.0051\n",
      "Epoch 3/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.9186 - loss: 0.2951 - val_accuracy: 1.0000 - val_loss: 1.8083e-04\n",
      "Epoch 4/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.9596 - loss: 0.1366 - val_accuracy: 1.0000 - val_loss: 1.5622e-04\n",
      "Epoch 5/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9799 - loss: 0.0718 - val_accuracy: 1.0000 - val_loss: 2.6109e-05\n",
      "Epoch 6/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.9758 - loss: 0.0742 - val_accuracy: 1.0000 - val_loss: 4.9828e-06\n",
      "Epoch 7/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9867 - loss: 0.0458 - val_accuracy: 1.0000 - val_loss: 4.6014e-06\n",
      "Epoch 8/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9862 - loss: 0.0416 - val_accuracy: 1.0000 - val_loss: 3.3497e-06\n",
      "Epoch 9/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9878 - loss: 0.0449 - val_accuracy: 1.0000 - val_loss: 9.6957e-07\n",
      "Epoch 10/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.9869 - loss: 0.0391 - val_accuracy: 1.0000 - val_loss: 1.7563e-06\n",
      "Epoch 11/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.9893 - loss: 0.0335 - val_accuracy: 1.0000 - val_loss: 1.3153e-06\n",
      "Epoch 12/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9827 - loss: 0.0494 - val_accuracy: 1.0000 - val_loss: 1.3510e-07\n",
      "Epoch 13/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.9892 - loss: 0.0291 - val_accuracy: 1.0000 - val_loss: 1.5100e-07\n",
      "Epoch 14/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.9891 - loss: 0.0346 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 15/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.9940 - loss: 0.0226 - val_accuracy: 1.0000 - val_loss: 3.1789e-08\n",
      "Epoch 16/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.9904 - loss: 0.0295 - val_accuracy: 1.0000 - val_loss: 2.3842e-07\n",
      "Epoch 17/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.9905 - loss: 0.0266 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 18/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.9938 - loss: 0.0263 - val_accuracy: 1.0000 - val_loss: 1.9868e-08\n",
      "Epoch 19/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9885 - loss: 0.0276 - val_accuracy: 1.0000 - val_loss: 2.3842e-07\n",
      "Epoch 20/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9933 - loss: 0.0354 - val_accuracy: 1.0000 - val_loss: 9.2982e-07\n",
      "Epoch 21/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9940 - loss: 0.0221 - val_accuracy: 1.0000 - val_loss: 1.0729e-07\n",
      "Epoch 22/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9952 - loss: 0.0172 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 23/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.9955 - loss: 0.0144 - val_accuracy: 1.0000 - val_loss: 2.7815e-08\n",
      "Epoch 24/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9895 - loss: 0.0286 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 25/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9932 - loss: 0.0223 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 26/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9924 - loss: 0.0238 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 27/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9930 - loss: 0.0169 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 28/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9915 - loss: 0.0243 - val_accuracy: 1.0000 - val_loss: 7.1526e-08\n",
      "Epoch 29/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9927 - loss: 0.0267 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 30/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9958 - loss: 0.0197 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 31/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.9952 - loss: 0.0160 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 32/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9952 - loss: 0.0160 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 33/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9914 - loss: 0.0194 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 34/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9945 - loss: 0.0179 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 35/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9951 - loss: 0.0185 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 36/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9963 - loss: 0.0129 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 37/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9964 - loss: 0.0102 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 38/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9957 - loss: 0.0106 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 39/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9886 - loss: 0.0296 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 40/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.9899 - loss: 0.0288 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 41/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.9923 - loss: 0.0217 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 42/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.9953 - loss: 0.0140 - val_accuracy: 1.0000 - val_loss: 1.3113e-07\n",
      "Epoch 43/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.9925 - loss: 0.0158 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 44/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.9938 - loss: 0.0208 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 45/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9948 - loss: 0.0156 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 46/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9863 - loss: 0.0433 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 47/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9907 - loss: 0.0387 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\n",
      "Training fold 2\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "2970 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({np.int64(6): 270, np.int64(7): 270, np.int64(4): 270, np.int64(3): 270, np.int64(5): 270, np.int64(8): 270, np.int64(9): 270, np.int64(2): 270, np.int64(10): 270, np.int64(1): 270, np.int64(0): 270})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9095 - loss: 0.4364 - val_accuracy: 1.0000 - val_loss: 2.4943e-04\n",
      "Epoch 2/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9532 - loss: 0.1420 - val_accuracy: 1.0000 - val_loss: 6.8346e-07\n",
      "Epoch 3/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.9684 - loss: 0.0866 - val_accuracy: 1.0000 - val_loss: 1.3510e-07\n",
      "Epoch 4/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.9911 - loss: 0.0303 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 5/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9907 - loss: 0.0310 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 6/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9903 - loss: 0.0273 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 7/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9946 - loss: 0.0151 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 8/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9968 - loss: 0.0091 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 9/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.9942 - loss: 0.0204 - val_accuracy: 1.0000 - val_loss: 1.2318e-07\n",
      "Epoch 10/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9933 - loss: 0.0224 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 11/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9931 - loss: 0.0265 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 12/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9943 - loss: 0.0151 - val_accuracy: 1.0000 - val_loss: 4.0134e-07\n",
      "Epoch 13/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9878 - loss: 0.0371 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 14/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9961 - loss: 0.0180 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 15/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9919 - loss: 0.0178 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 16/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9951 - loss: 0.0202 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 17/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9937 - loss: 0.0188 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 18/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9901 - loss: 0.0335 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 19/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.9939 - loss: 0.0134 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 20/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.9940 - loss: 0.0199 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 21/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.9890 - loss: 0.0324 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 22/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.9939 - loss: 0.0336 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 23/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.9963 - loss: 0.0136 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 24/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9914 - loss: 0.0254 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 25/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.9954 - loss: 0.0130 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 26/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.9938 - loss: 0.0170 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 27/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.9977 - loss: 0.0069 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 28/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.9940 - loss: 0.0130 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 29/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.9938 - loss: 0.0159 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 30/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.9931 - loss: 0.0303 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 31/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.9936 - loss: 0.0221 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 32/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.9927 - loss: 0.0234 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 33/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.9923 - loss: 0.0214 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 34/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9969 - loss: 0.0087 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\n",
      "Training fold 3\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "2970 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({np.int64(6): 270, np.int64(7): 270, np.int64(4): 270, np.int64(3): 270, np.int64(5): 270, np.int64(8): 270, np.int64(9): 270, np.int64(2): 270, np.int64(10): 270, np.int64(1): 270, np.int64(0): 270})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.9875 - loss: 0.0377 - val_accuracy: 1.0000 - val_loss: 8.3446e-08\n",
      "Epoch 2/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.9727 - loss: 0.0784 - val_accuracy: 1.0000 - val_loss: 7.9473e-08\n",
      "Epoch 3/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9861 - loss: 0.0595 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 4/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9917 - loss: 0.0250 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 5/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.9924 - loss: 0.0322 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 6/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9914 - loss: 0.0245 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 7/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - accuracy: 0.9921 - loss: 0.0321 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 8/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9951 - loss: 0.0240 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 9/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.9950 - loss: 0.0162 - val_accuracy: 1.0000 - val_loss: 8.2254e-07\n",
      "Epoch 10/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.9914 - loss: 0.0256 - val_accuracy: 1.0000 - val_loss: 6.1194e-07\n",
      "Epoch 11/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9946 - loss: 0.0179 - val_accuracy: 1.0000 - val_loss: 1.5497e-07\n",
      "Epoch 12/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9924 - loss: 0.0215 - val_accuracy: 1.0000 - val_loss: 1.2716e-07\n",
      "Epoch 13/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.9937 - loss: 0.0202 - val_accuracy: 1.0000 - val_loss: 3.4252e-06\n",
      "Epoch 14/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.9951 - loss: 0.0148 - val_accuracy: 1.0000 - val_loss: 1.5537e-06\n",
      "Epoch 15/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9938 - loss: 0.0244 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 16/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9932 - loss: 0.0230 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 17/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9946 - loss: 0.0120 - val_accuracy: 1.0000 - val_loss: 5.1657e-08\n",
      "Epoch 18/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.9913 - loss: 0.0251 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 19/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.9956 - loss: 0.0142 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 20/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9965 - loss: 0.0149 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 21/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.9956 - loss: 0.0136 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 22/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.9961 - loss: 0.0121 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 23/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9966 - loss: 0.0100 - val_accuracy: 1.0000 - val_loss: 5.5631e-08\n",
      "Epoch 24/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9947 - loss: 0.0143 - val_accuracy: 1.0000 - val_loss: 3.0597e-07\n",
      "Epoch 25/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9931 - loss: 0.0236 - val_accuracy: 1.0000 - val_loss: 3.1789e-08\n",
      "Epoch 26/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.9910 - loss: 0.0208 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 27/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9893 - loss: 0.0300 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 28/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 0.9901 - loss: 0.0247 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 29/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9935 - loss: 0.0262 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 30/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9964 - loss: 0.0105 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 31/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9952 - loss: 0.0106 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 32/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9921 - loss: 0.0206 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 33/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9973 - loss: 0.0059 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\n",
      "Training fold 4\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "2970 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({np.int64(6): 270, np.int64(7): 270, np.int64(4): 270, np.int64(3): 270, np.int64(5): 270, np.int64(8): 270, np.int64(9): 270, np.int64(2): 270, np.int64(10): 270, np.int64(1): 270, np.int64(0): 270})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9848 - loss: 0.0489 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 2/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9761 - loss: 0.0707 - val_accuracy: 1.0000 - val_loss: 3.5763e-08\n",
      "Epoch 3/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9874 - loss: 0.0406 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 4/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9846 - loss: 0.0408 - val_accuracy: 1.0000 - val_loss: 8.9009e-07\n",
      "Epoch 5/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9903 - loss: 0.0296 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 6/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9939 - loss: 0.0230 - val_accuracy: 1.0000 - val_loss: 1.5895e-08\n",
      "Epoch 7/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9932 - loss: 0.0229 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 8/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9958 - loss: 0.0156 - val_accuracy: 1.0000 - val_loss: 1.9868e-08\n",
      "Epoch 9/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.9937 - loss: 0.0190 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 10/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.9937 - loss: 0.0243 - val_accuracy: 1.0000 - val_loss: 3.7352e-07\n",
      "Epoch 11/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9956 - loss: 0.0147 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 12/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9985 - loss: 0.0083 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 13/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9938 - loss: 0.0164 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 14/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9934 - loss: 0.0218 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 15/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.9916 - loss: 0.0248 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 16/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9970 - loss: 0.0109 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 17/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.9933 - loss: 0.0165 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 18/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.9966 - loss: 0.0092 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 19/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9961 - loss: 0.0073 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 20/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.9944 - loss: 0.0150 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 21/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.9962 - loss: 0.0109 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 22/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9982 - loss: 0.0060 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 23/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9961 - loss: 0.0110 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 24/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.9931 - loss: 0.0203 - val_accuracy: 1.0000 - val_loss: 5.6425e-07\n",
      "Epoch 25/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.9917 - loss: 0.0220 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 26/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9949 - loss: 0.0127 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 27/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.9917 - loss: 0.0249 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 28/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9949 - loss: 0.0139 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 29/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9956 - loss: 0.0112 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 30/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.9944 - loss: 0.0255 - val_accuracy: 1.0000 - val_loss: 2.2768e-06\n",
      "Epoch 31/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9922 - loss: 0.0209 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 32/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9952 - loss: 0.0157 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 33/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9922 - loss: 0.0348 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 34/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9900 - loss: 0.0265 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 35/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9965 - loss: 0.0085 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\n",
      "Training fold 5\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "2970 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({np.int64(6): 270, np.int64(7): 270, np.int64(4): 270, np.int64(3): 270, np.int64(5): 270, np.int64(8): 270, np.int64(9): 270, np.int64(2): 270, np.int64(10): 270, np.int64(1): 270, np.int64(0): 270})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9944 - loss: 0.0206 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 2/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9906 - loss: 0.0276 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 3/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9892 - loss: 0.0405 - val_accuracy: 1.0000 - val_loss: 5.5631e-08\n",
      "Epoch 4/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9900 - loss: 0.0303 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 5/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9911 - loss: 0.0287 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 6/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9944 - loss: 0.0212 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 7/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9983 - loss: 0.0097 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 8/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9965 - loss: 0.0114 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 9/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9984 - loss: 0.0071 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 10/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9972 - loss: 0.0083 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 11/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9945 - loss: 0.0184 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 12/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9959 - loss: 0.0127 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 13/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9947 - loss: 0.0133 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 14/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9955 - loss: 0.0165 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 15/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9929 - loss: 0.0241 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 16/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9937 - loss: 0.0358 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 17/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9983 - loss: 0.0099 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 18/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9913 - loss: 0.0310 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 19/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.9932 - loss: 0.0331 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 20/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9968 - loss: 0.0133 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 21/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9954 - loss: 0.0136 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 22/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9972 - loss: 0.0096 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 23/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9967 - loss: 0.0130 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 24/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9953 - loss: 0.0154 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 25/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9958 - loss: 0.0130 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 26/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9952 - loss: 0.0159 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 27/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9925 - loss: 0.0219 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 28/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9963 - loss: 0.0082 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 29/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9963 - loss: 0.0119 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 30/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9965 - loss: 0.0129 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 31/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9958 - loss: 0.0095 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 32/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9894 - loss: 0.0362 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\n",
      "Training fold 6\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "2970 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({np.int64(6): 270, np.int64(7): 270, np.int64(4): 270, np.int64(3): 270, np.int64(5): 270, np.int64(8): 270, np.int64(9): 270, np.int64(2): 270, np.int64(10): 270, np.int64(1): 270, np.int64(0): 270})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9872 - loss: 0.0423 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 2/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9896 - loss: 0.0331 - val_accuracy: 1.0000 - val_loss: 5.1657e-08\n",
      "Epoch 3/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9855 - loss: 0.0382 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 4/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9890 - loss: 0.0400 - val_accuracy: 1.0000 - val_loss: 1.6689e-07\n",
      "Epoch 5/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.9939 - loss: 0.0250 - val_accuracy: 1.0000 - val_loss: 4.7684e-08\n",
      "Epoch 6/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9921 - loss: 0.0275 - val_accuracy: 1.0000 - val_loss: 1.3272e-06\n",
      "Epoch 7/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9959 - loss: 0.0197 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 8/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9932 - loss: 0.0211 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 9/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9935 - loss: 0.0202 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 10/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9970 - loss: 0.0111 - val_accuracy: 1.0000 - val_loss: 3.6557e-07\n",
      "Epoch 11/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9930 - loss: 0.0202 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 12/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9958 - loss: 0.0094 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 13/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9953 - loss: 0.0140 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 14/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9921 - loss: 0.0182 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 15/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9956 - loss: 0.0113 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 16/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9920 - loss: 0.0218 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 17/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9956 - loss: 0.0129 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 18/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9963 - loss: 0.0133 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 19/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9991 - loss: 0.0050 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 20/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9938 - loss: 0.0185 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 21/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9945 - loss: 0.0130 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 22/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9933 - loss: 0.0406 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 23/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9914 - loss: 0.0226 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 24/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9953 - loss: 0.0118 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 25/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - accuracy: 0.9949 - loss: 0.0145 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 26/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9967 - loss: 0.0111 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 27/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - accuracy: 0.9959 - loss: 0.0152 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 28/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9966 - loss: 0.0115 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 29/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9978 - loss: 0.0107 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 30/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9985 - loss: 0.0062 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 31/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9950 - loss: 0.0117 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 32/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9964 - loss: 0.0161 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 33/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9930 - loss: 0.0241 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Training fold 7\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "2970 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({np.int64(6): 270, np.int64(7): 270, np.int64(4): 270, np.int64(3): 270, np.int64(5): 270, np.int64(8): 270, np.int64(9): 270, np.int64(2): 270, np.int64(10): 270, np.int64(1): 270, np.int64(0): 270})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9904 - loss: 0.0287 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 2/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9924 - loss: 0.0168 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 3/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9869 - loss: 0.0531 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 4/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9946 - loss: 0.0166 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 5/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9918 - loss: 0.0380 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 6/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9919 - loss: 0.0242 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 7/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9954 - loss: 0.0127 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 8/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9931 - loss: 0.0374 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 9/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9885 - loss: 0.0262 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 10/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9913 - loss: 0.0356 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 11/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9926 - loss: 0.0174 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 12/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9947 - loss: 0.0166 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 13/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9953 - loss: 0.0156 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 14/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9971 - loss: 0.0123 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 15/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9921 - loss: 0.0245 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 16/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9969 - loss: 0.0093 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 17/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9927 - loss: 0.0248 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 18/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9941 - loss: 0.0207 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 19/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.9962 - loss: 0.0162 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 20/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9964 - loss: 0.0117 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 21/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9960 - loss: 0.0300 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 22/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9936 - loss: 0.0176 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 23/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9957 - loss: 0.0193 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 24/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9964 - loss: 0.0092 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 25/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9968 - loss: 0.0079 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 26/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9955 - loss: 0.0131 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 27/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9968 - loss: 0.0150 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 28/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9979 - loss: 0.0079 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 29/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9964 - loss: 0.0142 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 30/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9980 - loss: 0.0069 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 31/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9972 - loss: 0.0080 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\n",
      "Training fold 8\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "2970 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({np.int64(6): 270, np.int64(7): 270, np.int64(4): 270, np.int64(3): 270, np.int64(5): 270, np.int64(8): 270, np.int64(9): 270, np.int64(2): 270, np.int64(10): 270, np.int64(1): 270, np.int64(0): 270})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9856 - loss: 0.0448 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 2/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9787 - loss: 0.0630 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 3/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9918 - loss: 0.0255 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 4/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9931 - loss: 0.0221 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 5/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9952 - loss: 0.0203 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 6/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9911 - loss: 0.0214 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 7/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9936 - loss: 0.0161 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 8/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9965 - loss: 0.0159 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 9/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9967 - loss: 0.0107 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 10/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9953 - loss: 0.0091 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 11/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9970 - loss: 0.0162 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 12/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9943 - loss: 0.0105 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 13/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9958 - loss: 0.0178 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 14/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9975 - loss: 0.0058 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 15/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9935 - loss: 0.0174 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 16/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9961 - loss: 0.0196 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 17/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9952 - loss: 0.0181 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 18/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9957 - loss: 0.0109 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 19/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - accuracy: 0.9937 - loss: 0.0268 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 20/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9976 - loss: 0.0114 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 21/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9980 - loss: 0.0071 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 22/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9961 - loss: 0.0105 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 23/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9971 - loss: 0.0081 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 24/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9950 - loss: 0.0135 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 25/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9958 - loss: 0.0166 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 26/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9933 - loss: 0.0139 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 27/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9943 - loss: 0.0203 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 28/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9926 - loss: 0.0203 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 29/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9970 - loss: 0.0078 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 30/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9947 - loss: 0.0249 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 31/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9968 - loss: 0.0100 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 32/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9977 - loss: 0.0052 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\n",
      "Training fold 9\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "2970 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({np.int64(6): 270, np.int64(7): 270, np.int64(4): 270, np.int64(3): 270, np.int64(5): 270, np.int64(8): 270, np.int64(9): 270, np.int64(2): 270, np.int64(10): 270, np.int64(1): 270, np.int64(0): 270})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9922 - loss: 0.0246 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 2/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9927 - loss: 0.0209 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 3/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9795 - loss: 0.0500 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 4/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9884 - loss: 0.0387 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 5/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9878 - loss: 0.0422 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 6/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9963 - loss: 0.0121 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 7/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9965 - loss: 0.0162 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 8/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9927 - loss: 0.0539 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 9/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9979 - loss: 0.0069 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 10/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9954 - loss: 0.0122 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 11/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9966 - loss: 0.0092 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 12/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9945 - loss: 0.0183 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 13/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9953 - loss: 0.0145 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 14/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9953 - loss: 0.0112 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 15/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9940 - loss: 0.0178 - val_accuracy: 1.0000 - val_loss: 3.9736e-09\n",
      "Epoch 16/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9939 - loss: 0.0127 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 17/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9961 - loss: 0.0069 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 18/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - accuracy: 0.9939 - loss: 0.0127 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 19/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9950 - loss: 0.0177 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 20/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9978 - loss: 0.0110 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 21/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9947 - loss: 0.0215 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 22/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9968 - loss: 0.0064 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 23/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9939 - loss: 0.0147 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 24/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9972 - loss: 0.0044 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 25/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9967 - loss: 0.0080 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 26/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9989 - loss: 0.0038 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 27/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9982 - loss: 0.0051 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 28/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9959 - loss: 0.0123 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 29/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9931 - loss: 0.0166 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 30/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9975 - loss: 0.0071 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 31/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9914 - loss: 0.0233 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 32/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9987 - loss: 0.0060 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\n",
      "Training fold 10\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "2970 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({np.int64(6): 270, np.int64(7): 270, np.int64(4): 270, np.int64(3): 270, np.int64(5): 270, np.int64(8): 270, np.int64(9): 270, np.int64(2): 270, np.int64(10): 270, np.int64(1): 270, np.int64(0): 270})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9871 - loss: 0.0403 - val_accuracy: 1.0000 - val_loss: 7.9473e-09\n",
      "Epoch 2/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9810 - loss: 0.0502 - val_accuracy: 1.0000 - val_loss: 1.4305e-07\n",
      "Epoch 3/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9899 - loss: 0.0418 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 4/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9892 - loss: 0.0222 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 5/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9986 - loss: 0.0053 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 6/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9958 - loss: 0.0110 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 7/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.9950 - loss: 0.0227 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 8/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9941 - loss: 0.0261 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 9/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9968 - loss: 0.0091 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 10/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9909 - loss: 0.0237 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 11/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9943 - loss: 0.0186 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 12/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9967 - loss: 0.0080 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 13/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9976 - loss: 0.0125 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 14/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9971 - loss: 0.0089 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 15/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9987 - loss: 0.0071 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 16/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9963 - loss: 0.0085 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 17/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9952 - loss: 0.0087 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 18/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9956 - loss: 0.0139 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 19/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9963 - loss: 0.0061 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 20/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9951 - loss: 0.0146 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 21/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9962 - loss: 0.0136 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 22/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9950 - loss: 0.0126 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 23/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9959 - loss: 0.0113 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 24/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9950 - loss: 0.0144 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 25/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9944 - loss: 0.0225 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 26/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9924 - loss: 0.0342 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 27/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9957 - loss: 0.0135 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 28/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.9950 - loss: 0.0175 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 29/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.9950 - loss: 0.0084 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 30/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9959 - loss: 0.0092 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 31/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9983 - loss: 0.0102 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 32/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9938 - loss: 0.0136 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 33/300\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9956 - loss: 0.0096 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\n",
      "Time taken for training:  00:20:32\n",
      "\n",
      "\n",
      "Fold 1 - Train Accuracy 1.0000 - Test Accuracy 0.2000\n",
      "Fold 2 - Train Accuracy 1.0000 - Test Accuracy 0.9583\n",
      "Fold 3 - Train Accuracy 0.9997 - Test Accuracy 1.0000\n",
      "Fold 4 - Train Accuracy 1.0000 - Test Accuracy 0.9917\n",
      "Fold 5 - Train Accuracy 0.9997 - Test Accuracy 1.0000\n",
      "Fold 6 - Train Accuracy 1.0000 - Test Accuracy 0.9917\n",
      "Fold 7 - Train Accuracy 1.0000 - Test Accuracy 1.0000\n",
      "Fold 8 - Train Accuracy 0.9990 - Test Accuracy 1.0000\n",
      "Fold 9 - Train Accuracy 0.9976 - Test Accuracy 0.9833\n",
      "Fold 10 - Train Accuracy 0.9997 - Test Accuracy 0.9917\n",
      "\n",
      "Mean Train Accuracy: 0.9996 \n",
      "Mean Test Accuracy: 0.9117 \n",
      "\n",
      "Evaluate other metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90       300\n",
      "           1       0.96      0.88      0.92        50\n",
      "           2       0.88      0.89      0.89        57\n",
      "           3       0.94      0.90      0.92       145\n",
      "           4       0.95      0.92      0.93       132\n",
      "           5       0.88      0.92      0.90       191\n",
      "           6       0.94      0.90      0.92       150\n",
      "           7       0.92      0.91      0.92        79\n",
      "           8       0.93      0.92      0.93        61\n",
      "           9       1.00      0.88      0.94        25\n",
      "          10       1.00      0.90      0.95        10\n",
      "\n",
      "    accuracy                           0.91      1200\n",
      "   macro avg       0.93      0.90      0.92      1200\n",
      "weighted avg       0.91      0.91      0.91      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def create_v2():\n",
    "    act_function = \"relu\"\n",
    "    kernel_init = \"he_uniform\"\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(number_of_steps, number_of_features)))\n",
    "    model.add(Conv1D(filters = 64, kernel_size = 3, activation = act_function,\n",
    "                     kernel_initializer = kernel_init))\n",
    "    model.add(Conv1D(filters = 32, kernel_size = 3, activation = act_function,\n",
    "                     kernel_initializer = kernel_init))\n",
    "    model.add(Conv1D(filters = 16, kernel_size = 3, activation = act_function,\n",
    "                     kernel_initializer = kernel_init))\n",
    "    model.add(MaxPooling1D(pool_size = 2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation = act_function, kernel_initializer = kernel_init))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(11, activation = 'softmax'))\n",
    "    opt = AdamW(learning_rate = 0.001)\n",
    "    model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = opt, metrics = [\"accuracy\"])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "X_list, y_list = build_time_window_structure(df)\n",
    "X_arr = np.array(X_list)\n",
    "y_arr = np.array(y_list)\n",
    "\n",
    "model = create_v2()\n",
    "history_by_fold = train_cnn_model(model, X_arr, y_arr, apply_smote = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48119eaf",
   "metadata": {},
   "source": [
    "#### Show loss history by epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89a10b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Plot loss history\n",
    "for i in range(len(history_by_fold)):\n",
    "    plt.plot(history_by_fold[i].history[\"val_loss\"], label = \"Fold {}\".format(i + 1))\n",
    "plt.title(\"Validation Loss vs Number of epochs\", fontsize = 12)\n",
    "plt.xlabel(\"Epochs\", fontsize = 12)\n",
    "plt.ylabel(\"Loss\", fontsize = 12)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26847b22",
   "metadata": {},
   "source": [
    "#### Show accuracy history by epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a7e0aca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Plot accuracy history\n",
    "for i in range(len(history_by_fold)):\n",
    "    plt.plot(history_by_fold[i].history[\"val_accuracy\"], label = \"Fold {}\".format(i + 1))\n",
    "plt.title(\"Validation Accuracy vs Number of epochs\", fontsize = 12)\n",
    "plt.xlabel('Epochs', fontsize = 12)\n",
    "plt.ylabel('Accuracy', fontsize = 12)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
